{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"datasets.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"0ggR9AVFCdqx"},"source":["# Datasets\n","\n","We published four datasets for training and evaluating extraction of performance results from machine learning papers. In this notebook we describe the format and show how to use our python API to conveniently work with the datasets. Due to the licensing the datasets consists of metadata and annotations, but do not include papers and data extracted from them. However, we made special effort in our extraction pipeline to get reproducible results."]},{"cell_type":"markdown","metadata":{"id":"77AKIP3ZCdq4"},"source":["Simple functions to load the datasets"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnJ89fEqChw3","executionInfo":{"status":"ok","timestamp":1636685218865,"user_tz":300,"elapsed":18879,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"cb66b533-f459-4f19-d2a8-177782cf480b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","metadata":{"id":"jQEv6A7SCm-Z","executionInfo":{"status":"ok","timestamp":1636685303018,"user_tz":300,"elapsed":140,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}}},"source":["import os\n","import sys\n","dir_path = '/content/gdrive/My Drive/axcell-master/axcell-master'\n","sys.path.append(dir_path)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-xuEuzdESLA","executionInfo":{"status":"ok","timestamp":1636685671564,"user_tz":300,"elapsed":16247,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"cdcf208c-28c5-4c7e-b3e3-e546aa950df4"},"source":["!sudo apt-get install python3-docker"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  golang-docker-credential-helpers libsecret-1-0 libsecret-common\n","  python3-certifi python3-chardet python3-dockerpycreds python3-idna\n","  python3-pkg-resources python3-requests python3-six python3-urllib3\n","  python3-websocket\n","Suggested packages:\n","  python3-setuptools python3-cryptography python3-openssl python3-socks\n","The following NEW packages will be installed:\n","  golang-docker-credential-helpers libsecret-1-0 libsecret-common\n","  python3-certifi python3-chardet python3-docker python3-dockerpycreds\n","  python3-idna python3-pkg-resources python3-requests python3-six\n","  python3-urllib3 python3-websocket\n","0 upgraded, 13 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 1,192 kB of archives.\n","After this operation, 4,861 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsecret-common all 0.18.6-1 [4,452 B]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsecret-1-0 amd64 0.18.6-1 [94.6 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-certifi all 2018.1.18-2 [144 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-chardet all 3.0.4-1 [80.3 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 golang-docker-credential-helpers amd64 0.5.0-2ubuntu0.1 [477 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-dockerpycreds all 0.2.1-1 [4,206 B]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-urllib3 all 1.22-1ubuntu0.18.04.2 [86.2 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-requests all 2.18.4-2ubuntu0.1 [58.3 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-websocket all 0.44.0-0ubuntu2 [30.7 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-docker all 2.5.1-1 [69.0 kB]\n","Fetched 1,192 kB in 1s (867 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 13.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libsecret-common.\n","(Reading database ... 155219 files and directories currently installed.)\n","Preparing to unpack .../00-libsecret-common_0.18.6-1_all.deb ...\n","Unpacking libsecret-common (0.18.6-1) ...\n","Selecting previously unselected package libsecret-1-0:amd64.\n","Preparing to unpack .../01-libsecret-1-0_0.18.6-1_amd64.deb ...\n","Unpacking libsecret-1-0:amd64 (0.18.6-1) ...\n","Selecting previously unselected package python3-certifi.\n","Preparing to unpack .../02-python3-certifi_2018.1.18-2_all.deb ...\n","Unpacking python3-certifi (2018.1.18-2) ...\n","Selecting previously unselected package python3-pkg-resources.\n","Preparing to unpack .../03-python3-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python3-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python3-chardet.\n","Preparing to unpack .../04-python3-chardet_3.0.4-1_all.deb ...\n","Unpacking python3-chardet (3.0.4-1) ...\n","Selecting previously unselected package python3-six.\n","Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n","Unpacking python3-six (1.11.0-2) ...\n","Selecting previously unselected package golang-docker-credential-helpers.\n","Preparing to unpack .../06-golang-docker-credential-helpers_0.5.0-2ubuntu0.1_amd64.deb ...\n","Unpacking golang-docker-credential-helpers (0.5.0-2ubuntu0.1) ...\n","Selecting previously unselected package python3-dockerpycreds.\n","Preparing to unpack .../07-python3-dockerpycreds_0.2.1-1_all.deb ...\n","Unpacking python3-dockerpycreds (0.2.1-1) ...\n","Selecting previously unselected package python3-idna.\n","Preparing to unpack .../08-python3-idna_2.6-1_all.deb ...\n","Unpacking python3-idna (2.6-1) ...\n","Selecting previously unselected package python3-urllib3.\n","Preparing to unpack .../09-python3-urllib3_1.22-1ubuntu0.18.04.2_all.deb ...\n","Unpacking python3-urllib3 (1.22-1ubuntu0.18.04.2) ...\n","Selecting previously unselected package python3-requests.\n","Preparing to unpack .../10-python3-requests_2.18.4-2ubuntu0.1_all.deb ...\n","Unpacking python3-requests (2.18.4-2ubuntu0.1) ...\n","Selecting previously unselected package python3-websocket.\n","Preparing to unpack .../11-python3-websocket_0.44.0-0ubuntu2_all.deb ...\n","Unpacking python3-websocket (0.44.0-0ubuntu2) ...\n","Selecting previously unselected package python3-docker.\n","Preparing to unpack .../12-python3-docker_2.5.1-1_all.deb ...\n","Unpacking python3-docker (2.5.1-1) ...\n","Setting up libsecret-common (0.18.6-1) ...\n","Setting up python3-idna (2.6-1) ...\n","Setting up python3-six (1.11.0-2) ...\n","Setting up python3-certifi (2018.1.18-2) ...\n","Setting up python3-pkg-resources (39.0.1-2) ...\n","Setting up python3-chardet (3.0.4-1) ...\n","Setting up python3-websocket (0.44.0-0ubuntu2) ...\n","update-alternatives: using /usr/bin/python3-wsdump to provide /usr/bin/wsdump (wsdump) in auto mode\n","Setting up python3-urllib3 (1.22-1ubuntu0.18.04.2) ...\n","Setting up libsecret-1-0:amd64 (0.18.6-1) ...\n","Setting up golang-docker-credential-helpers (0.5.0-2ubuntu0.1) ...\n","Setting up python3-requests (2.18.4-2ubuntu0.1) ...\n","Setting up python3-dockerpycreds (0.2.1-1) ...\n","Setting up python3-docker (2.5.1-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbnaT38BDTeI","executionInfo":{"status":"ok","timestamp":1636685676980,"user_tz":300,"elapsed":164,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"b4c97b71-f1f3-4a7f-b71a-282c3039c458"},"source":["#!/bin/bash\n","\n","#  Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n","\n","!docker pull arxivvanity/engrafo:b3db888fefa118eacf4f13566204b68ce100b3a6"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: docker: command not found\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506},"id":"ibYl9gevCdq5","executionInfo":{"status":"error","timestamp":1636685454520,"user_tz":300,"elapsed":131,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"f924f45d-763b-4b53-de70-5df442b8eeb8"},"source":["from axcell.helpers.datasets import read_arxiv_papers\n","from pathlib import Path\n","\n","V1_URL = 'https://github.com/paperswithcode/axcell/releases/download/v1.0/'\n","ARXIV_PAPERS_URL = V1_URL + 'arxiv-papers.csv.xz'\n","SEGMENTED_TABLES_URL = V1_URL + 'segmented-tables.json.xz'\n","PWC_LEADERBOARDS_URL = V1_URL + 'pwc-leaderboards.json.xz'"],"execution_count":7,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-da3bd72dd3be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maxcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_arxiv_papers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mV1_URL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/paperswithcode/axcell/releases/download/v1.0/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mARXIV_PAPERS_URL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV1_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'arxiv-papers.csv.xz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/axcell-master/axcell-master/axcell/helpers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlatex_converter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatexConverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/axcell-master/axcell-master/axcell/helpers/latex_converter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdocker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdocker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContainerError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageNotFound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docker'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","metadata":{"id":"LxJl1DAyCdq6"},"source":["## ArxivPapers\n","\n","**ArxivPapers** dataset is a corpus of over 100,000 scientific papers related to machine learning. In our work we use the corpus for self-supervised training of ULMFiT langauge model (see the lm_training notebook) and for extraction of common abbreviations. The dataset is a CSV file with one row per paper and the following fields:\n","* arxiv_id - arXiv identifier with version\n","* archive_size - the file size in bytes of the e-print archive\n","* sha256 - SHA-256 hash of the e-print archive\n","* title - paper's title\n","* status - the text and tables extraction status for this paper, one of:\n","  + success,\n","  + no-tex - LaTeX source is unavailable,\n","  + processing-error - extraction issues,\n","  + withdrawn - the paper is withdrawn from arXiv\n","* sections - number of extracted sections and subsections\n","* tables - number of extracted tables"]},{"cell_type":"code","metadata":{"id":"2X-k8rRpCdq7","outputId":"e6f60016-40d9-46f9-e3ce-790e4b3b4000"},"source":["arxiv_papers = read_arxiv_papers(ARXIV_PAPERS_URL)\n","\n","print(f'Number of papers:           {len(arxiv_papers):8}')\n","print(f'└── with LaTeX source:      {(~arxiv_papers.status.isin([\"no-tex\", \"withdrawn\"])).sum():8}')\n","print(f'Number of extracted tables: {arxiv_papers.tables.sum():8}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of papers:             104710\n","└── with LaTeX source:         93811\n","Number of extracted tables:   277946\n"]}]},{"cell_type":"markdown","metadata":{"id":"cs4oZJhJCdq8"},"source":["The arXiv id can be used to generate links to e-prints. Please read https://arxiv.org/help/bulk_data and play nice."]},{"cell_type":"code","metadata":{"id":"loL4XJZjCdq9","outputId":"065b4f55-5e81-43ec-cbb5-e64dc35d8e71"},"source":["def get_eprint_link(paper):\n","    return f'http://export.arxiv.org/e-print/{paper.arxiv_id}'\n","\n","links = arxiv_papers.apply(get_eprint_link, axis=1)\n","links.tail()"],"execution_count":null,"outputs":[{"data":{"text/plain":["104705    http://export.arxiv.org/e-print/2002.08204v1\n","104706    http://export.arxiv.org/e-print/2002.08253v1\n","104707    http://export.arxiv.org/e-print/2002.08264v1\n","104708    http://export.arxiv.org/e-print/2002.08301v1\n","104709    http://export.arxiv.org/e-print/2002.08325v1\n","dtype: object"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"Hv6i5OTMCdq-"},"source":["## SegmentedTables & LinkedResults\n","\n","The **SegmentedTables** dataset contains annotations of almost 2,000 tables. The dataset is a JSON array with one item per paper and the following fields:\n","* arxiv_id - arXiv identifier with version. The version can be different than in **ArxivTables**,\n","* sha256 - SHA-256 hash of the e-print archive\n","* fold - one of 11 folds, f.e., img_class or speech_rec. Each paper has exactly one fold, even if it's related to more than one task,\n","* tables - array of tables annotations\n","  + index - 0-based index of tables extracted from paper,\n","  + leaderboard - a boolean denoting if this table is a leaderboard table,\n","  + ablation - a boolean denoting if this table is an ablation table (a table can be both a leaderboard and an ablation table),\n","  + dataset_text - datasets mentioned in table's caption, not normalized\n","  + segmentation - for leaderboard tables, a 2D array (list of lists) with one label per cell\n","\n","Additionally we annotated part of the tables with performance results, called simply the **LinkedResults** dataset. Each table contains a 'records' array with items containing:\n","* task, dataset, metric - task, dataset and metric names normalized across all papers from the **LinkedResults** dataset,\n","* value - normalized metric value,\n","* model - model name,\n","* row, column - 0-based cell location with this result."]},{"cell_type":"code","metadata":{"id":"Iv2LHVM3Cdq_","outputId":"ca330bce-df30-46fa-ff29-d58920058a10"},"source":["from axcell.helpers.datasets import read_tables_annotations\n","\n","segmented_tables_annotations = read_tables_annotations(SEGMENTED_TABLES_URL)\n","\n","leaderboards = (segmented_tables_annotations.tables.apply(\n","    lambda tables: len([t for t in tables if t['leaderboard']])\n",").sum())\n","ablations = (segmented_tables_annotations.tables.apply(\n","    lambda tables: len([t for t in tables if t['ablation']])\n",").sum())\n","records = (segmented_tables_annotations.tables.apply(\n","    lambda tables: sum([len(t['records']) for t in tables])\n",").sum())\n","\n","print(f'Number of papers: {len(segmented_tables_annotations):8}')\n","print(f'Number of tables: {segmented_tables_annotations.tables.apply(len).sum():8}')\n","print(f'├── leaderboards: {leaderboards:8}')\n","print(f'└── ablations:    {ablations:8}')\n","print(f'Linked results:   {records:8}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of papers:      352\n","Number of tables:     1994\n","├── leaderboards:      796\n","└── ablations:         468\n","Linked results:       1591\n"]}]},{"cell_type":"markdown","metadata":{"id":"wLZV6UxHCdrA"},"source":["## PWCLeaderboards\n","\n","The **PWCLeaderboards** dataset is similar in structure to the **LinkedResults** dataset. It's a JSON array with one item per paper, containing:\n","* arxiv_id - arXiv identifier with version. The version corresponds to the version in **ArxivTables**,\n","* tables\n","  + index - 0-based table index\n","  + records - as in **LinkedResults**"]},{"cell_type":"code","metadata":{"id":"oAzgf-EKCdrB","outputId":"e13efc7a-7908-460f-87e6-173e21604a48"},"source":["pwc_leaderboards = read_tables_annotations(PWC_LEADERBOARDS_URL)\n","\n","records = (pwc_leaderboards.tables.apply(\n","    lambda tables: sum([len(t['records']) for t in tables])\n",").sum())\n","\n","print(f'Number of papers: {len(pwc_leaderboards):8}')\n","print(f'Number of tables: {pwc_leaderboards.tables.apply(len).sum():8}')\n","print(f'Linked results:   {records:8}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of papers:      731\n","Number of tables:     1278\n","Linked results:       5393\n"]}]}]}