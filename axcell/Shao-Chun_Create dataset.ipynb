{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"Shao-Chun_Create dataset.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwFpV17jq6GK","executionInfo":{"status":"ok","timestamp":1638309430445,"user_tz":300,"elapsed":21747,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"f0cc21fb-35fb-4e88-82b2-5b55490612d8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"jJZ7TlzTrC69","executionInfo":{"status":"ok","timestamp":1638309432948,"user_tz":300,"elapsed":134,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}}},"source":["import sys\n","# modify \"customized_path_to_homework\", path of folder in drive, where you uploaded your homework\n","customized_path_to_homework = '/content/drive/My Drive/axcell/'\n","sys.path.append(customized_path_to_homework)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNiW7WbLGp7Z","executionInfo":{"status":"ok","timestamp":1638309434717,"user_tz":300,"elapsed":310,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"fcf63e56-bc62-4216-d97e-9f0316149f79"},"source":["!pwd"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"Bt1rUfCApvxG","executionInfo":{"status":"ok","timestamp":1638309435717,"user_tz":300,"elapsed":139,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}}},"source":["import pandas as pd\n","\n","\n","def read_arxiv_papers(path):\n","    return pd.read_csv(path)\n","\n","\n","def read_tables_annotations(path):\n","    return pd.read_json(path)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"bspVfjxgpvxM","executionInfo":{"status":"ok","timestamp":1638309443023,"user_tz":300,"elapsed":110,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}}},"source":["ARXIV_PAPERS_URL = '/content/drive/My Drive/axcell/arxiv/arxiv-papers.csv.xz'\n","SEGMENTED_TABLES_URL = '/content/drive/My Drive/axcell/segmented-tables.json.xz'\n","PWC_LEADERBOARDS_URL = '/content/drive/My Drive/axcell/pwc-leaderboards.json.xz'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"g_1TVqx9HG33","executionInfo":{"status":"error","timestamp":1638309444281,"user_tz":300,"elapsed":128,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"315444c6-3092-4042-a1ee-1a11b9f42634"},"source":["arxiv_papers = read_arxiv_papers(ARXIV_PAPERS_URL)\n","\n","print(f'Number of papers:           {len(arxiv_papers):8}')\n","print(f'└── with LaTeX source:      {(~arxiv_papers.status.isin([\"no-tex\", \"withdrawn\"])).sum():8}')\n","print(f'Number of extracted tables: {arxiv_papers.tables.sum():8}')"],"execution_count":9,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-410a52eae63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marxiv_papers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_arxiv_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARXIV_PAPERS_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of papers:           {len(arxiv_papers):8}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'└── with LaTeX source:      {(~arxiv_papers.status.isin([\"no-tex\", \"withdrawn\"])).sum():8}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of extracted tables: {arxiv_papers.tables.sum():8}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-3d31b1fb4d24>\u001b[0m in \u001b[0;36mread_arxiv_papers\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_arxiv_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/lzma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, format, check, preset, filters)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/axcell/arxiv/arxiv-papers.csv.xz'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"2OC4vjsxHZSK","executionInfo":{"status":"ok","timestamp":1637936402834,"user_tz":300,"elapsed":137,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"820eef59-aa28-4889-d740-b61de9d073d4"},"source":["import matplotlib.pyplot as plt\n","df = arxiv_papers['status'].value_counts().rename_axis('status_class').reset_index(name='counts')\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>status_class</th>\n","      <th>counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>success</td>\n","      <td>89785</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>no-tex</td>\n","      <td>10312</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>processing-error</td>\n","      <td>4026</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>withdrawn</td>\n","      <td>587</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       status_class  counts\n","0           success   89785\n","1            no-tex   10312\n","2  processing-error    4026\n","3         withdrawn     587"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"dWaAzYIFHu_U","executionInfo":{"status":"ok","timestamp":1637936405497,"user_tz":300,"elapsed":338,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"ba2c2a19-9943-42fe-ee8a-f35c00022975"},"source":["import matplotlib.pyplot as plt\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","ax.bar(df.status_class, df.counts)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bI-cMmguKbrZ","executionInfo":{"status":"ok","timestamp":1637936407861,"user_tz":300,"elapsed":131,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"ad10567c-a39b-4710-93c2-95a7e9b59eaf"},"source":["arxiv_papers.sections.max()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["174"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95B93-GBLl3h","executionInfo":{"status":"ok","timestamp":1637936408536,"user_tz":300,"elapsed":8,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"ead639f0-29d1-4c1b-9046-1ae7745c3cb0"},"source":["ranges = [0,20,40,60,80,100,120,140,160,180,200]\n","a = arxiv_papers.groupby(pd.cut(arxiv_papers.sections, ranges)).count()\n","a.sections"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sections\n","(0, 20]       70516\n","(20, 40]      18593\n","(40, 60]        578\n","(60, 80]         37\n","(80, 100]         8\n","(100, 120]        3\n","(120, 140]        3\n","(140, 160]        1\n","(160, 180]        2\n","(180, 200]        0\n","Name: sections, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DR2NelwKJvtC","executionInfo":{"status":"ok","timestamp":1637936409649,"user_tz":300,"elapsed":175,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"4160f723-e37f-4580-90dd-bf310e482291"},"source":["ranges = [0,10,20,30,40,50,60,70,80,90,1015]\n","a = arxiv_papers.groupby(pd.cut(arxiv_papers.tables, ranges)).count()\n","a.tables"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tables\n","(0, 10]       65333\n","(10, 20]       2492\n","(20, 30]        264\n","(30, 40]         64\n","(40, 50]         31\n","(50, 60]         15\n","(60, 70]          5\n","(70, 80]          9\n","(80, 90]          2\n","(90, 1015]       16\n","Name: tables, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"gWvRu3czHSTF","executionInfo":{"status":"ok","timestamp":1637936411072,"user_tz":300,"elapsed":6,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"2a7305da-bd3d-4bd3-c724-3b7a96881944"},"source":["arxiv_papers"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>archive_size</th>\n","      <th>sha256</th>\n","      <th>title</th>\n","      <th>sections</th>\n","      <th>tables</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0704.0004v1</td>\n","      <td>9486</td>\n","      <td>83b5c83d0963d796ed61fae5ed47cac55d2c942d41e03f...</td>\n","      <td>A determinant of Stirling cycle numbers counts...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>success</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0704.0010v1</td>\n","      <td>45695</td>\n","      <td>6dd40a2af3e336e0a8e94a5a20a1075819af829f1fcef7...</td>\n","      <td>Partial cubes: structures, characterizations, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>no-tex</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0704.0012v1</td>\n","      <td>9560</td>\n","      <td>7f7997eee4e571f22551c06bf25e2315ac27fc663273c1...</td>\n","      <td>Distribution of integral Fourier Coefficients ...</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>success</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0704.0858v1</td>\n","      <td>355195</td>\n","      <td>723ba50cc7a5d0d2454df543d6aaacd5948a1bb4690459...</td>\n","      <td>Lessons Learned from the deployment of a high-...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>no-tex</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0704.0861v1</td>\n","      <td>693752</td>\n","      <td>05f2ae4019a2740a8ef53074656ea9de50324150042fd9...</td>\n","      <td>Empirical analysis and statistical modeling of...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>no-tex</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>104705</th>\n","      <td>2002.08204v1</td>\n","      <td>346382</td>\n","      <td>f8908756ae6fd29e8df962048b6b8efca4a040f8df16b0...</td>\n","      <td>SYMOG: learning symmetric mixture of Gaussian ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>no-tex</td>\n","    </tr>\n","    <tr>\n","      <th>104706</th>\n","      <td>2002.08253v1</td>\n","      <td>89874</td>\n","      <td>467cad121914a28dfb485dcdad079d73ca8b89add2ae53...</td>\n","      <td>Distance-Based Regularisation of Deep Networks...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>processing-error</td>\n","    </tr>\n","    <tr>\n","      <th>104707</th>\n","      <td>2002.08264v1</td>\n","      <td>293953</td>\n","      <td>89ce55f66b8888cdeeca7083a7eb8e9cab48b21c38d7f8...</td>\n","      <td>Molecule Attention Transformer</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>success</td>\n","    </tr>\n","    <tr>\n","      <th>104708</th>\n","      <td>2002.08301v1</td>\n","      <td>2000723</td>\n","      <td>63389dbd67c1078133db730e6e5941b431c58c9ad7f1a8...</td>\n","      <td>Multi-wavelet residual dense convolutional neu...</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>success</td>\n","    </tr>\n","    <tr>\n","      <th>104709</th>\n","      <td>2002.08325v1</td>\n","      <td>6564329</td>\n","      <td>d82a6529c29c1e540e3ee1453e2898af6f4cf08c63c37a...</td>\n","      <td>VQA-LOL: Visual Question Answering under the L...</td>\n","      <td>29</td>\n","      <td>15</td>\n","      <td>success</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>104710 rows × 7 columns</p>\n","</div>"],"text/plain":["            arxiv_id  archive_size  ... tables            status\n","0        0704.0004v1          9486  ...      0           success\n","1        0704.0010v1         45695  ...      0            no-tex\n","2        0704.0012v1          9560  ...      0           success\n","3        0704.0858v1        355195  ...      0            no-tex\n","4        0704.0861v1        693752  ...      0            no-tex\n","...              ...           ...  ...    ...               ...\n","104705  2002.08204v1        346382  ...      0            no-tex\n","104706  2002.08253v1         89874  ...      0  processing-error\n","104707  2002.08264v1        293953  ...     20           success\n","104708  2002.08301v1       2000723  ...      3           success\n","104709  2002.08325v1       6564329  ...     15           success\n","\n","[104710 rows x 7 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"YB5bV3LypvxN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637936425848,"user_tz":300,"elapsed":327,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"70d38cfc-39d0-4aaf-f60c-bea6ca739927"},"source":["segmented_tables_annotations = read_tables_annotations(SEGMENTED_TABLES_URL)\n","\n","leaderboards = (segmented_tables_annotations.tables.apply(\n","    lambda tables: len([t for t in tables if t['leaderboard']])\n",").sum())\n","ablations = (segmented_tables_annotations.tables.apply(\n","    lambda tables: len([t for t in tables if t['ablation']])\n",").sum())\n","records = (segmented_tables_annotations.tables.apply(\n","    lambda tables: sum([len(t['records']) for t in tables])\n",").sum())\n","\n","print(f'Number of papers: {len(segmented_tables_annotations):8}')\n","print(f'Number of tables: {segmented_tables_annotations.tables.apply(len).sum():8}')\n","print(f'├── leaderboards: {leaderboards:8}')\n","print(f'└── ablations:    {ablations:8}')\n","print(f'Linked results:   {records:8}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of papers:      352\n","Number of tables:     1994\n","├── leaderboards:      796\n","└── ablations:         468\n","Linked results:       1591\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"M4DN_mt3i7lo","executionInfo":{"status":"ok","timestamp":1637936433839,"user_tz":300,"elapsed":140,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"17dcb95c-45a7-4d1b-b68e-c9c0e63bc2cb"},"source":["arxiv_papers.loc[arxiv_papers.arxiv_id == '1312.6173v4']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>archive_size</th>\n","      <th>sha256</th>\n","      <th>title</th>\n","      <th>sections</th>\n","      <th>tables</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4849</th>\n","      <td>1312.6173v4</td>\n","      <td>124563</td>\n","      <td>520421f7c1055e034d6cb7e91a8d28e7e39b5759aa2d62...</td>\n","      <td>Multilingual Distributed Representations witho...</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>success</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         arxiv_id  archive_size  ... tables   status\n","4849  1312.6173v4        124563  ...      1  success\n","\n","[1 rows x 7 columns]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50},"id":"qgaSTRUTh6Gt","executionInfo":{"status":"ok","timestamp":1637936443034,"user_tz":300,"elapsed":129,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"a8b6013c-1f1c-466f-df6e-99b406437072"},"source":["pd.set_option('display.max_colwidth', None)\n","segmented_tables_annotations.loc[segmented_tables_annotations.arxiv_id == '2001.07793v1']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>fold</th>\n","      <th>sha256</th>\n","      <th>tables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [arxiv_id, fold, sha256, tables]\n","Index: []"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DCSMZz0reAz7","executionInfo":{"status":"ok","timestamp":1637936446830,"user_tz":300,"elapsed":420,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"cfb82910-9240-4ed7-94a8-c9f113097dcf"},"source":["segmented_tables_annotations.head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>fold</th>\n","      <th>sha256</th>\n","      <th>tables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1202.2745v1</td>\n","      <td>img_class</td>\n","      <td>b72ff435bb75f56c58e593d1b13f51c881a3aa80d2c2de91e66afd7bfd3896b9</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': True, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['dataset-metric', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'table-meta', 'dataset-metric'], ['model-competing', 'model-competing', ''], ['model-competing', 'model-competing', ''], ['model-competing', 'model-competing', ''], ['model-competing', 'model-competing', ''], ['model-best', 'model-best', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'table-meta', 'dataset-metric'], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['table-meta', 'model-paper', 'dataset-metric', 'dataset-metric'], ['table-meta', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': 'CIFAR', 'segmentation': [['table-meta', '', '', '', '', 'dataset-metric'], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': False, 'ablation': True, 'dataset_text': 'NORB', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 6, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-competing', 'model-paper', 'dataset-metric'], ['', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['dataset', '', '', ''], ['dataset', 'table-meta', 'table-meta', ''], ['dataset', '', '', ''], ['dataset', '', '', ''], ['dataset', '', '', ''], ['dataset', '', '', ''], ['dataset', '', '', '']], 'records': []}, {'index': 7, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params'], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 8, 'leaderboard': False, 'ablation': False, 'dataset_text': 'CIFAR 10', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params'], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1207.4708v2</td>\n","      <td>misc</td>\n","      <td>b0a7f50787ad3550c90ddd06aaec6bc84f7798bb9fff2f578509948a4da1feaa</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Asterix, Seaquest', 'segmentation': [['table-meta', 'model-competing', 'model-paper', 'model-paper', 'model-paper', 'model-paper', 'model-competing', 'model-competing', 'model-competing', 'model-competing'], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['', 'model-competing', 'model-paper', 'model-paper', 'model-paper', 'model-paper', 'model-competing', 'model-competing', 'model-competing'], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-paper', 'model-paper', 'model-competing', 'model-competing'], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-metric', '', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1301.3557v1</td>\n","      <td>img_class</td>\n","      <td>99519789f02a96e27f64df339781593d60071b4049ad85f457dd87d8569a5915</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['model-competing', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1302.4389v4</td>\n","      <td>img_class</td>\n","      <td>7d987eab7e29f9fa4e51ed364000d5133761d61dafb0b76e917ba2540b36b81c</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params'], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1303.5778v1</td>\n","      <td>speech_rec</td>\n","      <td>30cdaa9f0e1ae198a710d3d5fe9ab9c28b75cb69e984834dc13ec466c3c1e697</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'TIMIT', 'segmentation': [['table-meta', 'model-params', 'model-params', 'dataset-metric'], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-best', '', '', '']], 'records': [{'task': 'Speech Recognition', 'dataset': 'TIMIT', 'metric': 'Percentage error', 'model': 'Bi-LSTM + skip connections w/ CTC', 'value': '17.7', 'row': 9, 'column': 3}]}]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1312.4400v3</td>\n","      <td>img_class</td>\n","      <td>802a93a1c17c5a54700e279e7c5ba4c3262e1c69dc77145fb28bd4df73364a86</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CIFAR-10', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CIFAR-100', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'SVHN', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', ''], ['model-competing', ''], ['model-competing', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1312.6082v4</td>\n","      <td>img_class</td>\n","      <td>940fa12b2e1be4f785f92a889fb4775bba34896a3fc1c651ead9b536cc05b315</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1312.6229v4</td>\n","      <td>object_det</td>\n","      <td>3bca327b0044ac20e4c8b472b4241e5df6ec8efcadef80090ecbb8fff8eef0f6</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['', 'dataset-metric', 'dataset-metric'], ['table-meta', 'dataset-metric', 'dataset-metric'], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params'], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params'], ['model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params'], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1402.5766v1</td>\n","      <td>img_class</td>\n","      <td>989fad2b8f76b377b32794e15abaf14e6c9b913da2e578cb2bc5499a17f71a5c</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'table-meta'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'STL-10', 'segmentation': [['table-meta', 'table-meta', 'table-meta', 'dataset-metric'], ['table-meta', 'table-meta', 'table-meta', 'table-meta'], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['table-meta', 'table-meta', 'table-meta', 'table-meta'], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['', 'model-params', 'model-params', 'model-params'], ['model-best', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1404.3606v2</td>\n","      <td>img_class</td>\n","      <td>cedbdfa24b0a73f4973a824a52a94e23a7d65caa5e47589346450dbd72e089c1</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': True, 'dataset_text': 'MultiPIE cross-illumination', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-paper', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MultiPIE', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Extended Yale B', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-best', '', '', '', '', ''], ['model-best', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'AR', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-best', '', '', '', ''], ['model-best', '', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': 'FERET', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-metric'], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-best', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': True, 'ablation': False, 'dataset_text': 'LFW', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-best', '']], 'records': []}, {'index': 6, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['model-params', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '']], 'records': []}, {'index': 7, 'leaderboard': False, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params'], ['dataset', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', '']], 'records': []}, {'index': 8, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-best', '']], 'records': []}, {'index': 9, 'leaderboard': False, 'ablation': True, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 10, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CUReT', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-best', ''], ['model-paper', ''], ['model-paper', '']], 'records': []}, {'index': 11, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CIFAR10', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-best', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1404.4326v1</td>\n","      <td>qa</td>\n","      <td>5f515ad61bf0dfc4ce905ded4ecb42bf4cf90ff196dd73497d0f2700fec6b0bf</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'WikiAnswers+ReVerb', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-best', '', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': 'WikiAnswers+ReVerb', 'segmentation': [['table-meta', '', 'dataset-metric'], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', 'model-paper', ''], ['model-best', 'model-best', '']], 'records': []}, {'index': 5, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 6, 'leaderboard': True, 'ablation': False, 'dataset_text': 'WebQuestions', 'segmentation': [['table-meta', '', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['model-paper', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-paper', 'model-paper', '', '', ''], ['model-best', 'model-best', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1405.4053v2</td>\n","      <td>qa</td>\n","      <td>4cd98b04d1ac4cf7a4681b8e6a0fa588ab7a68ae5348aaf1ec906b5fe3c97f53</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Stanford Sentiment Treebank', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric'], ['', 'dataset-sub', 'dataset-sub'], ['', 'dataset-sub', 'dataset-sub'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-best', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'IMDB', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1406.1078v3</td>\n","      <td>mt</td>\n","      <td>4d88616f2e5afff9908ea04702138449fedd5ae4a5f76572c9928b91e16fd1be</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric'], ['table-meta', 'dataset-sub', 'dataset-sub'], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-best', '', '']], 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'CSLM + RNN + WP', 'value': '34.54', 'row': 5, 'column': 2}]}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1406.3676v3</td>\n","      <td>qa</td>\n","      <td>1580629fd9cf12f3e049389a870ab4eb944e76ca6e8b44e14e863a41972c1808</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['dataset', '', ''], ['', '', ''], ['', '', ''], ['dataset', '', ''], ['dataset', '', ''], ['dataset', '', ''], ['', '', ''], ['dataset', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': True, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['table-meta', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['table-meta', '', '', ''], ['model-best', '', '', ''], ['model-paper', '', '', ''], ['table-meta', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1406.4729v4</td>\n","      <td>object_det</td>\n","      <td>bc337cc6687d63e98face4aef7b56f498199e40eca4b501ce6e0a8074d61729f</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 6, 'leaderboard': False, 'ablation': True, 'dataset_text': 'PASCAL VOC 2007', 'segmentation': [['table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta'], ['table-meta', 'model-paper', 'model-paper', 'model-paper', 'model-paper', 'model-best'], ['table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta'], ['table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta'], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007 test', 'metric': 'MAP', 'model': 'SPP (Overfeat-7)', 'value': '0.8244', 'row': 8, 'column': 5}]}, {'index': 7, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', '']], 'records': []}, {'index': 8, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Pascal VOC 2007', 'segmentation': [['table-meta', 'dataset', 'dataset'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-best', '', '']], 'records': []}, {'index': 9, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 10, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 11, 'leaderboard': True, 'ablation': False, 'dataset_text': 'PASCAL VOC 2007', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007 test', 'metric': 'MAP', 'model': 'SPP bb', 'value': '0.592', 'row': 10, 'column': 1}]}, {'index': 12, 'leaderboard': True, 'ablation': False, 'dataset_text': 'VOC 2007', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-best', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007 test', 'metric': 'MAP', 'model': 'SPP-net', 'value': '0.592', 'row': 1, 'column': 1}]}, {'index': 13, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1406.7806v2</td>\n","      <td>speech_rec</td>\n","      <td>4b1b87e4ab164b1c1a8e028e596578297bc689682dbf61f4acdda45832bf40ad</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 2000, Switchboard, CallHome', 'segmentation': [['model-params', 'model-params', 'model-params', 'dataset-metric', 'dataset-metric', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset'], ['model-competing', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset'], ['model-competing', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome', 'segmentation': [['table-meta', 'model-params', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset'], ['model-competing', '', '', '', '', ''], ['model-best', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome, RT03 Switchboard', 'segmentation': [['model-params', 'model-params', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset', 'dataset'], ['model-competing', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome, RT03 Switchboard', 'segmentation': [['model-params', 'model-params', 'model-params', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset', 'dataset'], ['model-competing', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']], 'records': [{'task': '', 'dataset': '', 'metric': '', 'model': '', 'value': '', 'row': 13, 'column': 4}, {'task': '', 'dataset': '', 'metric': '', 'model': '', 'value': '', 'row': 6, 'column': 4}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 Average\", 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '19.1', 'row': 14, 'column': 6}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 Switchboard\", 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '15.0', 'row': 14, 'column': 4}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 CallHome\", 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '23.0', 'row': 14, 'column': 5}, {'task': 'Speech Recognition', 'dataset': 'Rich Transcription 2003', 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '35.9', 'row': 14, 'column': 7}]}]</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1409.0473v7</td>\n","      <td>mt</td>\n","      <td>49b62416adc363792c8680202c01608c7608514465cb3330665b70c4be6bb032</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub'], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-best', '', ''], ['model-paper', '', '']], 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'RNN-search50*', 'value': '36.15', 'row': 5, 'column': 2}]}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params', 'model-params', 'dataset-metric', 'dataset-metric'], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1409.2329v5</td>\n","      <td>mt</td>\n","      <td>bf28d89a519708233255c422af4a67077b505de94a9c9f64a3ced16ec57bc5bc</td>\n","      <td>[{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Penn Tree Bank', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub'], ['table-meta', 'table-meta', 'table-meta'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['table-meta', 'table-meta', 'table-meta'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-best', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['table-meta', 'table-meta', 'table-meta'], ['model-competing', '', '']], 'records': [{'task': 'Language Modelling', 'dataset': 'Penn Treebank (Word Level)', 'metric': 'BLEU score', 'model': '2 large regularized LSTMs', 'value': '73.6', 'row': 16, 'column': 2}]}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'English to French', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric'], ['model-paper', '', ''], ['model-paper', '', ''], ['trash', '', '']], 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'Regularized LSTM', 'value': '29.03', 'row': 2, 'column': 2}]}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1409.4842v1</td>\n","      <td>img_class</td>\n","      <td>397cd4251d46f62635ae59413e4fcfef94e531800c4181b524b44296c796c8d5</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params'], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'dataset-metric', 'model-params'], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-best', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['model-params', 'model-params', 'model-params', 'dataset-metric', 'model-params'], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'dataset-metric', 'model-params', 'model-params', 'model-params'], ['model-competing', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'ImageNet Detection', 'metric': 'MAP', 'model': 'Inception V1', 'value': '0.439', 'row': 4, 'column': 3}]}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric', 'model-params', 'model-params'], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-paper', '', '', ''], ['model-competing', '', '', '']], 'records': []}]</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1409.5185v2</td>\n","      <td>img_class</td>\n","      <td>042bcb8571378dad31c65da8f990fb62132c7ed8630979b1feebbb9a1a92dbcd</td>\n","      <td>[{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': 'CIFAR-10, CIFAR-100', 'segmentation': [['', ''], ['', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'SVHN', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       arxiv_id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            tables\n","0   1202.2745v1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [{'index': 0, 'leaderboard': False, 'ablation': True, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['dataset-metric', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'table-meta', 'dataset-metric'], ['model-competing', 'model-competing', ''], ['model-competing', 'model-competing', ''], ['model-competing', 'model-competing', ''], ['model-competing', 'model-competing', ''], ['model-best', 'model-best', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'table-meta', 'dataset-metric'], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['table-meta', 'model-paper', 'dataset-metric', 'dataset-metric'], ['table-meta', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': 'CIFAR', 'segmentation': [['table-meta', '', '', '', '', 'dataset-metric'], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': False, 'ablation': True, 'dataset_text': 'NORB', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 6, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-competing', 'model-paper', 'dataset-metric'], ['', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['dataset', '', '', ''], ['dataset', 'table-meta', 'table-meta', ''], ['dataset', '', '', ''], ['dataset', '', '', ''], ['dataset', '', '', ''], ['dataset', '', '', ''], ['dataset', '', '', '']], 'records': []}, {'index': 7, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params'], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 8, 'leaderboard': False, 'ablation': False, 'dataset_text': 'CIFAR 10', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params'], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}]\n","1   1207.4708v2  ...                                         [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Asterix, Seaquest', 'segmentation': [['table-meta', 'model-competing', 'model-paper', 'model-paper', 'model-paper', 'model-paper', 'model-competing', 'model-competing', 'model-competing', 'model-competing'], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', ''], ['dataset', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['', 'model-competing', 'model-paper', 'model-paper', 'model-paper', 'model-paper', 'model-competing', 'model-competing', 'model-competing'], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', ''], ['dataset', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-paper', 'model-paper', 'model-competing', 'model-competing'], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-sub', '', '', '', ''], ['dataset-metric', '', '', '', '']], 'records': []}]\n","2   1301.3557v1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['model-competing', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}]\n","3   1302.4389v4  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params'], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}]\n","4   1303.5778v1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'TIMIT', 'segmentation': [['table-meta', 'model-params', 'model-params', 'dataset-metric'], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-best', '', '', '']], 'records': [{'task': 'Speech Recognition', 'dataset': 'TIMIT', 'metric': 'Percentage error', 'model': 'Bi-LSTM + skip connections w/ CTC', 'value': '17.7', 'row': 9, 'column': 3}]}]\n","5   1312.4400v3  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CIFAR-10', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CIFAR-100', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'SVHN', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', ''], ['model-competing', ''], ['model-competing', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-competing', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', '']], 'records': []}]\n","6   1312.6082v4  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash'], ['trash', 'trash', 'trash']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash'], ['trash', 'trash', 'trash', 'trash']], 'records': []}]\n","7   1312.6229v4  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['', 'dataset-metric', 'dataset-metric'], ['table-meta', 'dataset-metric', 'dataset-metric'], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash', 'trash'], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['model-params', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params'], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params'], ['model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params'], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}]\n","8   1402.5766v1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'table-meta'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'STL-10', 'segmentation': [['table-meta', 'table-meta', 'table-meta', 'dataset-metric'], ['table-meta', 'table-meta', 'table-meta', 'table-meta'], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['table-meta', 'table-meta', 'table-meta', 'table-meta'], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['model-competing', 'model-competing', 'model-competing', ''], ['', 'model-params', 'model-params', 'model-params'], ['model-best', '', '', '']], 'records': []}]\n","9   1404.3606v2  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [{'index': 0, 'leaderboard': False, 'ablation': True, 'dataset_text': 'MultiPIE cross-illumination', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-paper', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MultiPIE', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Extended Yale B', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-best', '', '', '', '', ''], ['model-best', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'AR', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-best', '', '', '', ''], ['model-best', '', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': 'FERET', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-metric'], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-competing', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-best', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': True, 'ablation': False, 'dataset_text': 'LFW', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-best', '']], 'records': []}, {'index': 6, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['model-params', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '']], 'records': []}, {'index': 7, 'leaderboard': False, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params'], ['dataset', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', ''], ['dataset-sub', '', '', '']], 'records': []}, {'index': 8, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-best', '']], 'records': []}, {'index': 9, 'leaderboard': False, 'ablation': True, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 10, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CUReT', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-paper', ''], ['model-paper', ''], ['model-best', ''], ['model-paper', ''], ['model-paper', '']], 'records': []}, {'index': 11, 'leaderboard': True, 'ablation': False, 'dataset_text': 'CIFAR10', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-paper', ''], ['model-best', '']], 'records': []}]\n","10  1404.4326v1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash'], ['trash']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'WikiAnswers+ReVerb', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-best', '', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': 'WikiAnswers+ReVerb', 'segmentation': [['table-meta', '', 'dataset-metric'], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', 'model-paper', ''], ['model-best', 'model-best', '']], 'records': []}, {'index': 5, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 6, 'leaderboard': True, 'ablation': False, 'dataset_text': 'WebQuestions', 'segmentation': [['table-meta', '', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['model-paper', '', '', '', ''], ['model-paper', '', '', '', ''], ['model-paper', 'model-paper', '', '', ''], ['model-best', 'model-best', '', '', '']], 'records': []}]\n","11  1405.4053v2  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Stanford Sentiment Treebank', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric'], ['', 'dataset-sub', 'dataset-sub'], ['', 'dataset-sub', 'dataset-sub'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-best', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'IMDB', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}]\n","12  1406.1078v3  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric'], ['table-meta', 'dataset-sub', 'dataset-sub'], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-best', '', '']], 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'CSLM + RNN + WP', 'value': '34.54', 'row': 5, 'column': 2}]}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}]\n","13  1406.3676v3  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['dataset', '', ''], ['', '', ''], ['', '', ''], ['dataset', '', ''], ['dataset', '', ''], ['dataset', '', ''], ['', '', ''], ['dataset', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': True, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['', 'dataset-metric', 'dataset-metric', 'dataset-metric'], ['table-meta', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['table-meta', '', '', ''], ['model-best', '', '', ''], ['model-paper', '', '', ''], ['table-meta', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', '']], 'records': []}]\n","14  1406.4729v4  ...  [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 4, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 5, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 6, 'leaderboard': False, 'ablation': True, 'dataset_text': 'PASCAL VOC 2007', 'segmentation': [['table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta'], ['table-meta', 'model-paper', 'model-paper', 'model-paper', 'model-paper', 'model-best'], ['table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta'], ['table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta', 'table-meta'], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', ''], ['model-params', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007 test', 'metric': 'MAP', 'model': 'SPP (Overfeat-7)', 'value': '0.8244', 'row': 8, 'column': 5}]}, {'index': 7, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', '']], 'records': []}, {'index': 8, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Pascal VOC 2007', 'segmentation': [['table-meta', 'dataset', 'dataset'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-competing', '', ''], ['model-best', '', '']], 'records': []}, {'index': 9, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 10, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']], 'records': []}, {'index': 11, 'leaderboard': True, 'ablation': False, 'dataset_text': 'PASCAL VOC 2007', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007 test', 'metric': 'MAP', 'model': 'SPP bb', 'value': '0.592', 'row': 10, 'column': 1}]}, {'index': 12, 'leaderboard': True, 'ablation': False, 'dataset_text': 'VOC 2007', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub', 'dataset-sub'], ['model-best', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007 test', 'metric': 'MAP', 'model': 'SPP-net', 'value': '0.592', 'row': 1, 'column': 1}]}, {'index': 13, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}]\n","15  1406.7806v2  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 2000, Switchboard, CallHome', 'segmentation': [['model-params', 'model-params', 'model-params', 'dataset-metric', 'dataset-metric', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset'], ['model-competing', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset'], ['model-competing', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', ''], ['model-paper', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome', 'segmentation': [['table-meta', 'model-params', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset'], ['model-competing', '', '', '', '', ''], ['model-best', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['model-paper', '', '', '', '', ''], ['', '', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome, RT03 Switchboard', 'segmentation': [['model-params', 'model-params', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset', 'dataset'], ['model-competing', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', ''], ['', '', '', '', '', '', '']], 'records': []}, {'index': 4, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome, RT03 Switchboard', 'segmentation': [['model-params', 'model-params', 'model-params', 'dataset-metric', 'dataset-sub', 'dataset-sub', 'dataset', 'dataset'], ['model-competing', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']], 'records': [{'task': '', 'dataset': '', 'metric': '', 'model': '', 'value': '', 'row': 13, 'column': 4}, {'task': '', 'dataset': '', 'metric': '', 'model': '', 'value': '', 'row': 6, 'column': 4}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 Average\", 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '19.1', 'row': 14, 'column': 6}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 Switchboard\", 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '15.0', 'row': 14, 'column': 4}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 CallHome\", 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '23.0', 'row': 14, 'column': 5}, {'task': 'Speech Recognition', 'dataset': 'Rich Transcription 2003', 'metric': 'Percentage error', 'model': 'DNN + Dropout', 'value': '35.9', 'row': 14, 'column': 7}]}]\n","16  1409.0473v7  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub'], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-best', '', ''], ['model-paper', '', '']], 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'RNN-search50*', 'value': '36.15', 'row': 5, 'column': 2}]}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'model-params', 'model-params', 'dataset-metric', 'dataset-metric'], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', ''], ['model-paper', '', '', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', ''], ['', '']], 'records': []}]\n","17  1409.2329v5  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [{'index': 0, 'leaderboard': True, 'ablation': False, 'dataset_text': 'Penn Tree Bank', 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub'], ['table-meta', 'table-meta', 'table-meta'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['table-meta', 'table-meta', 'table-meta'], ['model-competing', '', ''], ['model-competing', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['model-best', '', ''], ['model-paper', '', ''], ['model-paper', '', ''], ['table-meta', 'table-meta', 'table-meta'], ['model-competing', '', '']], 'records': [{'task': 'Language Modelling', 'dataset': 'Penn Treebank (Word Level)', 'metric': 'BLEU score', 'model': '2 large regularized LSTMs', 'value': '73.6', 'row': 16, 'column': 2}]}, {'index': 1, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', '']], 'records': []}, {'index': 2, 'leaderboard': True, 'ablation': False, 'dataset_text': 'English to French', 'segmentation': [['table-meta', 'dataset-metric', 'dataset-metric'], ['model-paper', '', ''], ['model-paper', '', ''], ['trash', '', '']], 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'Regularized LSTM', 'value': '29.03', 'row': 2, 'column': 2}]}, {'index': 3, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['', '', ''], ['', '', ''], ['', '', ''], ['', '', '']], 'records': []}]\n","18  1409.4842v1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params', 'model-params'], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'dataset-metric', 'model-params'], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-competing', '', '', '', ''], ['model-best', '', '', '', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['model-params', 'model-params', 'model-params', 'dataset-metric', 'model-params'], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', ''], ['', '', '', '', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': '', 'segmentation': [['table-meta', 'model-params', 'model-params', 'dataset-metric', 'model-params', 'model-params', 'model-params'], ['model-competing', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', ''], ['model-competing', '', '', '', '', '', ''], ['model-best', '', '', '', '', '', '']], 'records': [{'task': 'Object Detection', 'dataset': 'ImageNet Detection', 'metric': 'MAP', 'model': 'Inception V1', 'value': '0.439', 'row': 4, 'column': 3}]}, {'index': 4, 'leaderboard': False, 'ablation': True, 'dataset_text': '', 'segmentation': [['table-meta', 'dataset-metric', 'model-params', 'model-params'], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-competing', '', '', ''], ['model-paper', '', '', ''], ['model-competing', '', '', '']], 'records': []}]\n","19  1409.5185v2  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [{'index': 0, 'leaderboard': False, 'ablation': False, 'dataset_text': '', 'segmentation': [['trash', 'trash']], 'records': []}, {'index': 1, 'leaderboard': True, 'ablation': False, 'dataset_text': 'MNIST', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}, {'index': 2, 'leaderboard': False, 'ablation': False, 'dataset_text': 'CIFAR-10, CIFAR-100', 'segmentation': [['', ''], ['', '']], 'records': []}, {'index': 3, 'leaderboard': True, 'ablation': False, 'dataset_text': 'SVHN', 'segmentation': [['table-meta', 'dataset-metric'], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-competing', ''], ['model-best', '']], 'records': []}]\n","\n","[20 rows x 4 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sW9-5Dsg-ty","executionInfo":{"status":"ok","timestamp":1636743510442,"user_tz":300,"elapsed":146,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"e089a52f-d53a-4df2-e688-76b43f27883e"},"source":["leaderboards_withrec"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["514"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"ohIM6yWZpvxR","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"ok","timestamp":1637936519446,"user_tz":300,"elapsed":164,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"6830f7da-75e7-4f27-9139-e913ba70e558"},"source":["import matplotlib.pyplot as plt\n","df = segmented_tables_annotations['fold'].value_counts().rename_axis('fold_class').reset_index(name='counts')\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fold_class</th>\n","      <th>counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>qa</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>object_det</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sem_seg</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nli</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>img_class</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>mt</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>img_gen</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>speech_rec</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>text_class</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>misc</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>pose_estim</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    fold_class  counts\n","0           qa      63\n","1   object_det      57\n","2      sem_seg      32\n","3          nli      32\n","4    img_class      31\n","5           mt      31\n","6      img_gen      27\n","7   speech_rec      24\n","8   text_class      23\n","9         misc      18\n","10  pose_estim      14"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"oFHZLXy5S-x6","executionInfo":{"status":"ok","timestamp":1637936522129,"user_tz":300,"elapsed":341,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"1d5d6d36-e00f-44b8-b9bf-5d446e362a8d"},"source":["import matplotlib.pyplot as plt\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1.3,1.3])\n","ax.bar(df.fold_class, df.counts)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"NeESqjKtpvxS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636663610681,"user_tz":300,"elapsed":108,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"82aa06e7-62c6-48d6-fa03-42999167fe27"},"source":["segmented_tables_annotations.tables[15][1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ablation': False,\n"," 'dataset_text': 'Hub5 Eval2000, Switchboard, CallHome',\n"," 'index': 1,\n"," 'leaderboard': True,\n"," 'records': [],\n"," 'segmentation': [['table-meta', 'dataset-sub', 'dataset-sub', 'dataset'],\n","  ['model-competing', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', ''],\n","  ['model-paper', '', '', '']]}"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","metadata":{"id":"Z9KShpx0pvxU","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1636641607552,"user_tz":300,"elapsed":77,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"9e7d3c9b-dbed-4657-a747-5aaf2148cb00"},"source":["segmented_tables_annotations_with_records = segmented_tables_annotations[segmented_tables_annotations['tables'][]]"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-0253736f2147>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    segmented_tables_annotations_with_records = segmented_tables_annotations[segmented_tables_annotations['tables'][]]\u001b[0m\n\u001b[0m                                                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"uv-VRXZppvxW","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"error","timestamp":1636641610290,"user_tz":300,"elapsed":249,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"ebc80de4-11e3-47d7-e976-d300723f8c5d"},"source":["segmented_tables_annotations_with_records = segmented_tables_annotations.apply(lambda row: sum([len(t['records']) for t in row['tables']]))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-05fd3903cab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msegmented_tables_annotations_with_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmented_tables_annotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-05fd3903cab6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msegmented_tables_annotations_with_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmented_tables_annotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'tables'"]}]},{"cell_type":"code","metadata":{"id":"uN2O_UO6pvxX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636750885852,"user_tz":300,"elapsed":572,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"a02741e2-be9c-4fa6-f579-0377b8612c96"},"source":["pwc_leaderboards = read_tables_annotations(PWC_LEADERBOARDS_URL)\n","\n","records = (pwc_leaderboards.tables.apply(\n","    lambda tables: sum([len(t['records']) for t in tables])\n",").sum())\n","\n","print(f'Number of papers: {len(pwc_leaderboards):8}')\n","print(f'Number of tables: {pwc_leaderboards.tables.apply(len).sum():8}')\n","print(f'Linked results:   {records:8}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of papers:      731\n","Number of tables:     1278\n","Linked results:       5393\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"kaYH-wjlOdWR","executionInfo":{"status":"ok","timestamp":1636750892597,"user_tz":300,"elapsed":193,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"a51484c2-2125-4063-e5b3-7f4be2655fd3"},"source":["pwc_leaderboards.head(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>tables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1207.4708v2</td>\n","      <td>[{'index': 5, 'records': [{'task': 'Atari Game...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      arxiv_id                                             tables\n","0  1207.4708v2  [{'index': 5, 'records': [{'task': 'Atari Game..."]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIDWh8RN9Qfa","executionInfo":{"status":"ok","timestamp":1636743665255,"user_tz":300,"elapsed":830,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"930eb481-2197-40e2-8c7e-11a69739afa6"},"source":["a = (pwc_leaderboards.tables.apply(\n","    lambda tables: len([print(t) for t in tables if t['records']])\n",").sum())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'index': 5, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Best Learner', 'value': '987.3', 'row': 1, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'Best Learner', 'value': '929.4', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Best Learner', 'value': '19.1', 'row': 3, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'Best Learner', 'value': '664.8', 'row': 4, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'Best Learner', 'value': '250.1', 'row': 5, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'Best Learner', 'value': '939.2', 'row': 6, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'Best Learner', 'value': '103.4', 'row': 7, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'Best Learner', 'value': '628', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'Best Learner', 'value': '907.3', 'row': 9, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'Best Learner', 'value': '62687', 'row': 10, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'Best Learner', 'value': '190.8', 'row': 11, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'Best Learner', 'value': '15819.7', 'row': 12, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'Best Learner', 'value': '501.3', 'row': 13, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'Best Learner', 'value': '43.9', 'row': 14, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'Best Learner', 'value': '44', 'row': 15, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'Best Learner', 'value': '5.2', 'row': 16, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Carnival', 'metric': 'Score', 'model': 'Best Learner', 'value': '2323.9', 'row': 17, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'Best Learner', 'value': '8803.8', 'row': 18, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'Best Learner', 'value': '1581.5', 'row': 19, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'Best Learner', 'value': '23410.6', 'row': 20, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'Best Learner', 'value': '520.5', 'row': 21, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'Best Learner', 'value': '-13.1', 'row': 22, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Elevator Action', 'metric': 'Action', 'model': 'Best Learner', 'value': '3220.6', 'row': 23, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'Best Learner', 'value': '129.1', 'row': 24, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'Best Learner', 'value': '-89.5', 'row': 25, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'Best Learner', 'value': '216.9', 'row': 26, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'Best Learner', 'value': '1288.3', 'row': 27, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Best Learner', 'value': '387.7', 'row': 28, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'Best Learner', 'value': '6458.8', 'row': 29, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'Best Learner', 'value': '-9.5', 'row': 30, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Best Learner', 'value': '202.8', 'row': 31, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Journey Escape', 'metric': 'Score', 'model': 'Best Learner', 'value': '-8441', 'row': 32, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'Best Learner', 'value': '1622.1', 'row': 33, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'Best Learner', 'value': '3371.5', 'row': 34, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'Best Learner', 'value': '19544', 'row': 35, 'column': 3}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Best Learner', 'value': '10.7', 'row': 36, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'Best Learner', 'value': '1691.8', 'row': 37, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'Best Learner', 'value': '2500.1', 'row': 38, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pooyan', 'metric': 'Score', 'model': 'Best Learner', 'value': '1225.3', 'row': 39, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'Best Learner', 'value': '-19', 'row': 40, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Best Learner', 'value': '684.3', 'row': 41, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'Best Learner', 'value': '613.5', 'row': 42, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'Best Learner', 'value': '1904.3', 'row': 43, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'Best Learner', 'value': '67.7', 'row': 44, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'Best Learner', 'value': '28.7', 'row': 45, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'Best Learner', 'value': '0', 'row': 46, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'Best Learner', 'value': '1069.5', 'row': 47, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'Best Learner', 'value': '-0.1', 'row': 48, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'Best Learner', 'value': '3741.2', 'row': 49, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'Best Learner', 'value': '114.3', 'row': 50, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'Best Learner', 'value': '3532.7', 'row': 51, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'Best Learner', 'value': '66', 'row': 52, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'Best Learner', 'value': '16871.3', 'row': 53, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'Best Learner', 'value': '1981.3', 'row': 54, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'Best Learner', 'value': '3365.1', 'row': 55, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'model': 'GDL-U', 'value': '0.937', 'row': 1, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'model': 'AGDL', 'value': '0.937', 'row': 1, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'coil-100', 'metric': 'NMI', 'model': 'GDL-U', 'value': '0.929', 'row': 2, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'coil-100', 'metric': 'NMI', 'model': 'AGDL', 'value': '0.933', 'row': 2, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'GDL-U', 'value': '0.824', 'row': 3, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'AGDL', 'value': '0.824', 'row': 3, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'AGDL', 'value': '0.844', 'row': 4, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'Extended Yale-B', 'metric': 'NMI', 'model': 'GDL-U', 'value': '0.91', 'row': 5, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'Extended Yale-B', 'metric': 'NMI', 'model': 'AGDL', 'value': '0.91', 'row': 5, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'model': 'GDL-U', 'value': '0.747', 'row': 6, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'model': 'GDL-U', 'value': '0.746', 'row': 6, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'DQN Best', 'value': '5184', 'row': 8, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'DQN Best', 'value': '225', 'row': 8, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'DQN Best', 'value': '661', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'DQN Best', 'value': '21', 'row': 8, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'DQN Best', 'value': '4500', 'row': 8, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'DQN Best', 'value': '1740', 'row': 8, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'DQN Best', 'value': '1075', 'row': 8, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 English-to-German', 'metric': 'Accuracy', 'model': 'biCVM+', 'value': '86.2', 'row': 6, 'column': 1}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 German-to-English', 'metric': 'Accuracy', 'model': 'biCVM+', 'value': '76.9', 'row': 6, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 English-to-German', 'metric': 'Accuracy', 'model': 'Bi+', 'value': '88.1', 'row': 14, 'column': 1}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 German-to-English', 'metric': 'Accuracy', 'model': 'Bi+', 'value': '79.2', 'row': 14, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Action Classification', 'dataset': 'HMDB51', 'metric': 'Accuracy', 'model': 'Two-stream model (fusion by SVM)', 'value': '88', 'row': 9, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters En-De', 'metric': 'Accuracy', 'model': 'BilBOWA', 'value': '86.5', 'row': 7, 'column': 1}, {'task': 'Document Classification', 'dataset': 'Reuters De-En', 'metric': 'Accuracy', 'model': 'BilBOWA', 'value': '75', 'row': 7, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Microarray Classification', 'dataset': 'ArrayCGH', 'metric': 'Accuracy', 'model': 'Fused Lasso', 'value': '73.6', 'row': 1, 'column': 1}, {'task': 'Microarray Classification', 'dataset': 'Leukemias', 'metric': 'Accuracy', 'model': 'Fused Lasso', 'value': '92', 'row': 2, 'column': 1}, {'task': 'Microarray Classification', 'dataset': 'Colon', 'metric': 'Accuracy', 'model': 'Fused Lasso', 'value': '77.2', 'row': 3, 'column': 1}, {'task': 'Microarray Classification', 'dataset': 'Ovarian', 'metric': 'Accuracy', 'model': 'Fused Lasso', 'value': '88.8', 'row': 4, 'column': 1}, {'task': 'Microarray Classification', 'dataset': 'Rat', 'metric': 'Accuracy', 'model': 'Fused Lasso', 'value': '68.8', 'row': 5, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 English-to-German', 'metric': 'Accuracy', 'model': 'Biinclusion (Euro500kReuters)', 'value': '92.7', 'row': 12, 'column': 2}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 German-to-English', 'metric': 'Accuracy', 'model': 'Biinclusion (Euro500kReuters)', 'value': '84.4', 'row': 12, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'DeepID3', 'value': '99.53', 'row': 8, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Gesture Recognition', 'dataset': 'Montalbano', 'metric': 'Jaccard (Mean)', 'model': 'Temp Conv + LSTM', 'value': '90.6', 'row': 7, 'column': 1}, {'task': 'Gesture Recognition', 'dataset': 'Montalbano', 'metric': 'Precision', 'model': 'Temp Conv + LSTM', 'value': '94.49', 'row': 7, 'column': 2}, {'task': 'Gesture Recognition', 'dataset': 'Montalbano', 'metric': 'Recall', 'model': 'Temp Conv + LSTM', 'value': '94.57', 'row': 7, 'column': 3}, {'task': 'Gesture Recognition', 'dataset': 'Montalbano', 'metric': 'Error rate', 'model': 'Temp Conv + LSTM', 'value': '2.77', 'row': 7, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'Very deep two-stream ConvNet', 'value': '91.4', 'row': 8, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'DDQN (tuned) hs', 'value': '16837.0', 'row': 4, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@1', 'model': 'HolE', 'value': '0.93', 'row': 7, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@3', 'model': 'HolE', 'value': '0.945', 'row': 7, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@10', 'model': 'HolE', 'value': '0.949', 'row': 7, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@1', 'model': 'HolE', 'value': '0.402', 'row': 7, 'column': 8}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@3', 'model': 'HolE', 'value': '0.613', 'row': 7, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@10', 'model': 'HolE', 'value': '0.7390000000000001', 'row': 7, 'column': 10}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-dev', 'metric': 'Accuracy', 'model': 'NMN+LSTM+FT', 'value': '58.6', 'row': 7, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-std', 'metric': 'Accuracy', 'model': 'NMN+LSTM+FT', 'value': '58.7', 'row': 7, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'Prior hs', 'value': '1334.7', 'row': 2, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'Prior hs', 'value': '129.1', 'row': 3, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'Prior hs', 'value': '6548.9', 'row': 4, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Prior hs', 'value': '22484.5', 'row': 5, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'Prior hs', 'value': '1745.1', 'row': 6, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'Prior hs', 'value': '330647.0', 'row': 7, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'Prior hs', 'value': '876.6', 'row': 8, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'Prior hs', 'value': '25520.0', 'row': 9, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'Prior hs', 'value': '31181.3', 'row': 10, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'Prior hs', 'value': '865.9', 'row': 11, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'Prior hs', 'value': '52.0', 'row': 12, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'Prior hs', 'value': '72.3', 'row': 13, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'Prior hs', 'value': '343.0', 'row': 14, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'Prior hs', 'value': '3489.1', 'row': 15, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'Prior hs', 'value': '4635.0', 'row': 16, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'Prior hs', 'value': '127512.0', 'row': 17, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'Prior hs', 'value': '61277.5', 'row': 19, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'Prior hs', 'value': '16.0', 'row': 20, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'Prior hs', 'value': '1831.0', 'row': 21, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'Prior hs', 'value': '9.8', 'row': 22, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Prior hs', 'value': '28.9', 'row': 23, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'Prior hs', 'value': '3510.0', 'row': 24, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'Prior hs', 'value': '34858.8', 'row': 25, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Prior hs', 'value': '269.5', 'row': 26, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'Prior hs', 'value': '20889.9', 'row': 27, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'Prior hs', 'value': '-0.2', 'row': 28, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Prior hs', 'value': '3961.0', 'row': 29, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'Prior hs', 'value': '12185.0', 'row': 30, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'Prior hs', 'value': '6872.8', 'row': 31, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'Prior hs', 'value': '31676.0', 'row': 32, 'column': 7}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Prior hs', 'value': '51.0', 'row': 33, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'Prior hs', 'value': '1865.9', 'row': 34, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'Prior hs', 'value': '10497.6', 'row': 35, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Prior hs', 'value': '670.7', 'row': 39, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'Prior hs', 'value': '9944.0', 'row': 40, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'Prior hs', 'value': '11807.2', 'row': 41, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Prior noop', 'value': '200.0', 'row': 42, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'Prior hs', 'value': '52264.0', 'row': 42, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'Prior hs', 'value': '56.2', 'row': 43, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'Prior hs', 'value': '25463.7', 'row': 44, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'Prior hs', 'value': '3912.1', 'row': 47, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'Prior hs', 'value': '61582.0', 'row': 48, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'Prior hs', 'value': '5963.0', 'row': 51, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'Prior hs', 'value': '56.9', 'row': 52, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'Prior hs', 'value': '12157.4', 'row': 53, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'Prior hs', 'value': '94.0', 'row': 54, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'Prior hs', 'value': '295972.8', 'row': 55, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'Prior hs', 'value': '5727.0', 'row': 56, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'Prior hs', 'value': '9474.0', 'row': 58, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Prior+Duel noop', 'value': '375080.0', 'row': 4, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'Duel noop', 'value': '42214.0', 'row': 17, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Ape-X', 'value': '33.7', 'row': 22, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'Duel noop', 'value': '19220.3', 'row': 39, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'DARQN hard', 'value': '20', 'row': 3, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'DARQN soft', 'value': '7263', 'row': 4, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'DARQN soft', 'value': '650', 'row': 4, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'DARQN soft', 'value': '197', 'row': 4, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'DARQN soft', 'value': '5356', 'row': 4, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'SSD512 (07+12+COCO)', 'value': '81.6', 'row': 11, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2012', 'metric': 'MAP', 'model': 'SSD512 (07+12+COCO)', 'value': '80', 'row': 8, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'SSD512', 'value': '28.8', 'row': 6, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'SSD512', 'value': '48.5', 'row': 6, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'SSD512', 'value': '30.3', 'row': 6, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '12852.08', 'row': 1, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Persistent AL', 'value': '19564.9', 'row': 1, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '10054.58', 'row': 2, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'Persistent AL', 'value': '13145.34', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '19.66', 'row': 3, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'Persistent AL', 'value': '19.76', 'row': 3, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '8670.5', 'row': 4, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'Persistent AL', 'value': '13230.74', 'row': 4, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '3460.79', 'row': 5, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'Persistent AL', 'value': '3277.59', 'row': 5, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '4990.91', 'row': 6, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'Persistent AL', 'value': '5699.81', 'row': 6, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '1557.43', 'row': 7, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'Persistent AL', 'value': '1451.65', 'row': 7, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '3661.51', 'row': 8, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'Persistent AL', 'value': '3304.33', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '1924.42', 'row': 9, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'Persistent AL', 'value': '1673.52', 'row': 9, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '553591.67', 'row': 10, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'Persistent AL', 'value': '1465250', 'row': 10, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '633.63', 'row': 11, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'Persistent AL', 'value': '874.99', 'row': 11, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '28789.29', 'row': 12, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'Persistent AL', 'value': '34583.07', 'row': 12, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '747.26', 'row': 13, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'Persistent AL', 'value': '1328.25', 'row': 13, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '57.41', 'row': 14, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'Persistent AL', 'value': '71.59', 'row': 14, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '93.94', 'row': 15, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'Persistent AL', 'value': '94.3', 'row': 15, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '425.32', 'row': 16, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'Persistent AL', 'value': '431.89', 'row': 16, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '5111.4', 'row': 17, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Persistent AL', 'value': '4679.93', 'row': 17, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '4225.18', 'row': 18, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'Persistent AL', 'value': '4539.55', 'row': 18, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '5431.36', 'row': 19, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'Persistent AL', 'value': '5734.93', 'row': 19, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '123410.71', 'row': 20, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'Persistent AL', 'value': '130002.71', 'row': 20, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '30643.59', 'row': 21, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'Persistent AL', 'value': '32038.93', 'row': 21, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '27153.48', 'row': 22, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'Persistent AL', 'value': '70908.17', 'row': 22, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '-0.15', 'row': 23, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'Persistent AL', 'value': '-2.51', 'row': 23, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Elevator Action', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '27088.89', 'row': 24, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Elevator Action', 'metric': 'Score', 'model': 'Persistent AL', 'value': '29100', 'row': 24, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '1252.7', 'row': 25, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'Persistent AL', 'value': '1343.1', 'row': 25, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '21.32', 'row': 26, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'Persistent AL', 'value': '28.13', 'row': 26, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '31.72', 'row': 27, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Persistent AL', 'value': '32.3', 'row': 27, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '2305.82', 'row': 28, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'Persistent AL', 'value': '3248.96', 'row': 28, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '11912.68', 'row': 29, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'Persistent AL', 'value': '10611.81', 'row': 29, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '417.65', 'row': 30, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Persistent AL', 'value': '446.92', 'row': 30, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '24788.86', 'row': 31, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'Persistent AL', 'value': '24175.79', 'row': 31, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '-1.24', 'row': 32, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'Persistent AL', 'value': '-0.25', 'row': 32, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '848.46', 'row': 33, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Persistent AL', 'value': '772.09', 'row': 33, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '10809.16', 'row': 34, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'Persistent AL', 'value': '11478.46', 'row': 34, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '9548.92', 'row': 35, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'Persistent AL', 'value': '8689.81', 'row': 35, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '32182.99', 'row': 36, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'Persistent AL', 'value': '34650.91', 'row': 36, 'column': 3}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Advantage Learning', 'value': '0.42', 'row': 37, 'column': 2}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Persistent AL', 'value': '1.72', 'row': 37, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '4065.8', 'row': 38, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'Persistent AL', 'value': '3917.55', 'row': 38, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '11025.26', 'row': 39, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'Persistent AL', 'value': '10431.33', 'row': 39, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '22038.27', 'row': 40, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'Persistent AL', 'value': '14495.56', 'row': 40, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '0', 'row': 41, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': '', 'value': '0', 'row': 41, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pooyan', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '4801.27', 'row': 42, 'column': 2}, {'task': 'Anemia Detection', 'dataset': 'Atari 2600 James Bond', 'metric': 'IS', 'model': '', 'value': '5858.84', 'row': 42, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '5276.16', 'row': 43, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '14368.03', 'row': 44, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '10585.12', 'row': 45, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '52351.23', 'row': 46, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '69.31', 'row': 47, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '-13264.51', 'row': 48, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '4785.16', 'row': 49, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '61353.59', 'row': 50, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Surround', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '-4.15', 'row': 51, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '0', 'row': 52, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '8969.12', 'row': 53, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '245.22', 'row': 54, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '13909.74', 'row': 55, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '198.69', 'row': 56, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '543504', 'row': 57, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '9541.14', 'row': 58, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Yars Revenge', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '24240.03', 'row': 59, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'Advantage Learning', 'value': '9129.61', 'row': 60, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'MEXaction2', 'metric': 'mAP', 'model': 'S-CNN', 'value': '7.4', 'row': 2, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'S-CNN', 'value': '47.7', 'row': 4, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': 'S-CNN', 'value': '43.5', 'row': 4, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'S-CNN', 'value': '36.3', 'row': 4, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'S-CNN', 'value': '28.7', 'row': 4, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'S-CNN', 'value': '19', 'row': 4, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '2436.6', 'row': 1, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '1272.5', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '8047.1', 'row': 3, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '19713.2', 'row': 4, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '1032', 'row': 5, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '994500', 'row': 6, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '1208', 'row': 7, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '38666.7', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '23429.8', 'row': 9, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '60.2', 'row': 10, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '93.2', 'row': 11, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '855', 'row': 12, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '4553.5', 'row': 13, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '4100', 'row': 14, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '137925.9', 'row': 15, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '82610', 'row': 16, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '3', 'row': 17, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '1591', 'row': 18, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '26', 'row': 19, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '33.9', 'row': 20, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '2181.4', 'row': 21, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '17438.4', 'row': 22, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '286.1', 'row': 23, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '21021.3', 'row': 24, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '-1.3', 'row': 25, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '1663.5', 'row': 26, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '14862.5', 'row': 27, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '8627.9', 'row': 28, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '36733.3', 'row': 29, 'column': 3}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '100', 'row': 30, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '2983.3', 'row': 31, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '11501.1', 'row': 32, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '20.9', 'row': 33, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '1812.5', 'row': 34, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '15092.7', 'row': 35, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '12845', 'row': 36, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '51500', 'row': 37, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '66.6', 'row': 38, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '9083.1', 'row': 39, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '2893', 'row': 40, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '55725', 'row': 41, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '0', 'row': 42, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '9079.4', 'row': 43, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '214.8', 'row': 44, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '26231', 'row': 45, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '212.5', 'row': 46, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '811610', 'row': 47, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '6804.7', 'row': 48, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '11491.7', 'row': 49, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'AWA - 0-Shot', 'metric': 'Accuracy', 'model': 'Synthesised Classifier', 'value': '72.9%', 'row': 12, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB-200-2011 - 0-Shot', 'metric': 'Top-1 Accuracy', 'model': 'Synthesised Classifier', 'value': '54.7', 'row': 12, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'SUN - 0-Shot', 'metric': 'Accuracy', 'model': 'Synthesised Classifier', 'value': '62.7%', 'row': 12, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'ImageNet - 0-Shot', 'metric': 'Accuracy', 'model': 'Synthesised Classifier', 'value': '1.5%', 'row': 12, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-dev', 'metric': 'Accuracy', 'model': 'DMN+', 'value': '60.3', 'row': 12, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-std', 'metric': 'Accuracy', 'model': 'DMN+', 'value': '60.4', 'row': 12, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Node Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'Planetoid-I', 'value': '64.7', 'row': 4, 'column': 1}, {'task': 'Node Classification', 'dataset': 'Pubmed', 'metric': 'Accuracy', 'model': 'Planetoid-I', 'value': '77.2', 'row': 4, 'column': 3}, {'task': 'Node Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'Planetoid-T', 'value': '75.7', 'row': 9, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Node Classification', 'dataset': 'NELL', 'metric': 'Accuracy', 'model': 'Planetoid*', 'value': '61.9', 'row': 7, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Horizon Line Estimation', 'dataset': 'Horizon Lines in the Wild', 'metric': 'AUC (horizon error)', 'model': 'GoogleNet (Huber Loss, horizon line projection)', 'value': '71.16', 'row': 2, 'column': 1}, {'task': 'Horizon Line Estimation', 'dataset': 'Eurasian Cities Dataset', 'metric': 'AUC (horizon error)', 'model': 'GoogleNet (Huber Loss, horizon line projection)', 'value': '83.6', 'row': 2, 'column': 2}, {'task': 'Horizon Line Estimation', 'dataset': 'York Urban Dataset', 'metric': 'AUC (horizon error)', 'model': 'GoogleNet (Huber Loss, horizon line projection)', 'value': '86.41', 'row': 2, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '1', 'row': 14, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'coil-100', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '0.985', 'row': 14, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '0.913', 'row': 14, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'OURS-RC', 'value': '0.915', 'row': 14, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '0.913', 'row': 14, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'UMist', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '0.877', 'row': 14, 'column': 6}, {'task': 'Image Clustering', 'dataset': 'FRGC', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '0.574', 'row': 14, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'CMU-PIE', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '1.000', 'row': 14, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'YouTube Faces DB', 'metric': 'NMI', 'model': 'JULE-RC', 'value': '0.848', 'row': 14, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'S:VGG-16, T:VGG-16', 'value': '92.5', 'row': 13, 'column': 1}, {'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'S:VGG-16, T:VGG-16', 'value': '65.4', 'row': 13, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Continuous Control', 'dataset': 'Cart-Pole Balancing', 'metric': 'Score', 'model': 'TRPO', 'value': '4869.8', 'row': 1, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Inverted Pendulum', 'metric': 'Score', 'model': 'TRPO', 'value': '247.2', 'row': 2, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Mountain Car', 'metric': 'Score', 'model': 'TRPO', 'value': '-61.7', 'row': 3, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Acrobot', 'metric': 'Score', 'model': 'TRPO', 'value': '-326', 'row': 4, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Double Inverted Pendulum', 'metric': 'Score', 'model': 'TRPO', 'value': '4412.4', 'row': 5, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Swimmer', 'metric': 'Score', 'model': 'TRPO', 'value': '96', 'row': 6, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Hopper', 'metric': 'Score', 'model': 'TRPO', 'value': '1183.3', 'row': 7, 'column': 11}, {'task': 'Continuous Control', 'dataset': '2D Walker', 'metric': 'Score', 'model': 'TRPO', 'value': '1353.8', 'row': 8, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Half-Cheetah', 'metric': 'Score', 'model': 'TRPO', 'value': '1914', 'row': 9, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Ant', 'metric': 'Score', 'model': 'TRPO', 'value': '730.2', 'row': 10, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Simple Humanoid', 'metric': 'Score', 'model': 'TRPO', 'value': '269.7', 'row': 11, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Full Humanoid', 'metric': 'Score', 'model': 'TRPO', 'value': '287', 'row': 12, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Cart-Pole Balancing (limited sensors)', 'metric': 'Score', 'model': 'TRPO', 'value': '960.2', 'row': 13, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Inverted Pendulum (limited sensors)', 'metric': 'Score', 'model': 'TRPO', 'value': '4.5', 'row': 14, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Mountain Car (limited sensors)', 'metric': 'Score', 'model': 'TRPO', 'value': '-64.2', 'row': 15, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Acrobot (limited sensors)', 'metric': 'Score', 'model': 'TRPO', 'value': '-83.3', 'row': 16, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Cart-Pole Balancing (noisy observations)', 'metric': 'Score', 'model': 'TRPO', 'value': '606.2', 'row': 17, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Inverted Pendulum (noisy observations)', 'metric': 'Score', 'model': 'TRPO', 'value': '10.4', 'row': 18, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Mountain Car (noisy observations)', 'metric': 'Score', 'model': 'TRPO', 'value': '-60.2', 'row': 19, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Acrobot (noisy observations)', 'metric': 'Score', 'model': 'TRPO', 'value': '-149.6', 'row': 20, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Cart-Pole Balancing (system identifications)', 'metric': 'Score', 'model': 'TRPO', 'value': '980.3', 'row': 21, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Inverted Pendulum (system identifications)', 'metric': 'Score', 'model': 'TRPO', 'value': '14.1', 'row': 22, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Mountain Car (system identifications)', 'metric': 'Score', 'model': 'TRPO', 'value': '-61.6', 'row': 23, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Acrobot (system identifications)', 'metric': 'Score', 'model': 'TRPO', 'value': '-170.9', 'row': 24, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Swimmer + Gathering', 'metric': 'Score', 'model': 'TRPO', 'value': '0', 'row': 25, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Ant + Gathering', 'metric': 'Score', 'model': 'TRPO', 'value': '-0.4', 'row': 26, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Swimmer + Maze', 'metric': 'Score', 'model': 'TRPO', 'value': '0', 'row': 27, 'column': 11}, {'task': 'Continuous Control', 'dataset': 'Ant + Maze', 'metric': 'Score', 'model': 'TRPO', 'value': '0', 'row': 28, 'column': 11}]}\n","{'index': 1, 'records': [{'task': 'Game of Doom', 'dataset': 'ViZDoom Basic Scenario', 'metric': 'Average Score', 'model': 'DQN', 'value': '82.2', 'row': 6, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CUB-200-2011 - 0-Shot', 'metric': 'Top-1 Accuracy', 'model': 'Word CNN-RNN (DS-SJE Embedding)', 'value': '56.8%', 'row': 10, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB-200-2011 - 0-Shot', 'metric': 'AP50', 'model': 'Word CNN-RNN (DS-SJE Embedding)', 'value': '48.7', 'row': 10, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Flowers-102 - 0-Shot', 'metric': 'Accuracy', 'model': 'Word CNN-RNN (DS-SJE Embedding)', 'value': '65.6%', 'row': 9, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Flowers-102 - 0-Shot', 'metric': 'AP50', 'model': 'Word CNN-RNN (DS-SJE Embedding)', 'value': '59.6', 'row': 9, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'Self-Paced Learning', 'value': '38.11', 'row': 12, 'column': 22}]}\n","{'index': 0, 'records': [{'task': 'Activity Recognition In Videos', 'dataset': 'DogCentric', 'metric': 'Accuracy', 'model': 'Sub-events (temporal filters + LSTM)', 'value': '81.4', 'row': 8, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Video Classification', 'dataset': 'COIN', 'metric': 'Accuracy', 'model': 'Ours (temporal filters) - TDD', 'value': '68.4', 'row': 11, 'column': 1}, {'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'Sub-events', 'value': '68.4', 'row': 11, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'COCO Visual Question Answering (VQA) real images 1.0 open ended', 'metric': 'Percentage correct', 'model': 'HQI+ResNet', 'value': '62.1', 'row': 11, 'column': 5}, {'task': 'Visual Question Answering', 'dataset': 'COCO Visual Question Answering (VQA) real images 1.0 multiple choice', 'metric': 'Percentage correct', 'model': 'HQI+ResNet', 'value': '66.1', 'row': 11, 'column': 10}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'Visual7W', 'metric': 'Percentage correct', 'model': 'MCB+Att.', 'value': '62.2', 'row': 3, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Visual Question Answering', 'dataset': 'COCO Visual Question Answering (VQA) real images 1.0 open ended', 'metric': 'Percentage correct', 'model': 'MCB 7 att.', 'value': '66.5', 'row': 9, 'column': 9}, {'task': 'Visual Question Answering', 'dataset': 'COCO Visual Question Answering (VQA) real images 1.0 multiple choice', 'metric': 'Percentage correct', 'model': 'MCB 7 att.', 'value': '70.1', 'row': 9, 'column': 10}]}\n","{'index': 4, 'records': [{'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'Accuracy', 'model': 'MCB', 'value': '48.69', 'row': 9, 'column': 1}]}\n","{'index': 5, 'records': [{'task': 'Phrase Grounding', 'dataset': 'ReferIt', 'metric': 'Accuracy', 'model': 'MCB', 'value': '28.91', 'row': 6, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Neural Statistician', 'value': '98.1', 'row': 4, 'column': 6}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Neural Statistician', 'value': '99.5', 'row': 5, 'column': 6}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Neural Statistician', 'value': '93.2', 'row': 6, 'column': 6}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Neural Statistician', 'value': '98.1', 'row': 7, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Matching Nets', 'value': '98.1', 'row': 9, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Matching Nets', 'value': '98.9', 'row': 9, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Matching Nets', 'value': '93.8', 'row': 9, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Matching Nets', 'value': '98.5', 'row': 9, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Matching Nets (Cosine Matching Fn)', 'value': '46.6', 'row': 9, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Matching Nets (Cosine Matching Fn)', 'value': '60', 'row': 9, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Question Answering', 'dataset': 'bAbi', 'metric': 'Mean Error Rate', 'model': 'QRN', 'value': '0.3', 'row': 4, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Surgical Skills Evaluation', 'dataset': 'JIGSAWS', 'metric': 'Accuracy', 'model': 'Bidir. LSTM', 'value': '0.833', 'row': 7, 'column': 1}, {'task': 'Surgical Skills Evaluation', 'dataset': 'JIGSAWS', 'metric': 'Edit Distance', 'model': 'Bidir. LSTM', 'value': '14.6', 'row': 7, 'column': 2}, {'task': 'Surgical Skills Evaluation', 'dataset': 'MISTIC-SIL', 'metric': 'Accuracy', 'model': 'Bidir. LSTM', 'value': '0.895', 'row': 7, 'column': 3}, {'task': 'Surgical Skills Evaluation', 'dataset': 'MISTIC-SIL', 'metric': 'Edit Distance', 'model': 'Bidir. LSTM', 'value': '19.5', 'row': 7, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma10', 'metric': 'PSNR', 'model': 'RED30', 'value': '33.63', 'row': 2, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma30', 'metric': 'PSNR', 'model': 'RED30', 'value': '27.95', 'row': 3, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma50', 'metric': 'PSNR', 'model': 'RED30', 'value': '25.75', 'row': 4, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma70', 'metric': 'PSNR', 'model': 'RED30', 'value': '24.37', 'row': 5, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma10', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.9319', 'row': 7, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma30', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.8019', 'row': 8, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma50', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.7167', 'row': 9, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma70', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.6551', 'row': 10, 'column': 9}]}\n","{'index': 3, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '37.66', 'row': 2, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '33.82', 'row': 3, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '31.51', 'row': 4, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.9599', 'row': 6, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.923', 'row': 7, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.8869', 'row': 8, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '32.94', 'row': 2, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '29.61', 'row': 3, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '27.86', 'row': 4, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.9144', 'row': 6, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.8341', 'row': 7, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.7718', 'row': 8, 'column': 9}]}\n","{'index': 5, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '31.99', 'row': 2, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '28.93', 'row': 3, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'RED30', 'value': '27.4', 'row': 4, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.8974', 'row': 6, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.7994', 'row': 7, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'RED30', 'value': '0.729', 'row': 8, 'column': 9}]}\n","{'index': 8, 'records': [{'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 10', 'metric': 'PSNR', 'model': 'RED30', 'value': '29.35', 'row': 1, 'column': 6}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 20', 'metric': 'PSNR', 'model': 'RED30', 'value': '31.73', 'row': 2, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '31.46', 'row': 3, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '29.02', 'row': 4, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '26.1', 'row': 5, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '37.58', 'row': 9, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '33.75', 'row': 10, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '31.4', 'row': 11, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '33.03', 'row': 12, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '29.81', 'row': 13, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '28.04', 'row': 14, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '31.9', 'row': 15, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '28.85', 'row': 16, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '27.29', 'row': 17, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '30.74', 'row': 18, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '27.15', 'row': 19, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '25.2', 'row': 20, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 10', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '29.4', 'row': 24, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 20', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '31.63', 'row': 25, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 30', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '32.91', 'row': 26, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 40', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '33.77', 'row': 27, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 10', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '29.19', 'row': 28, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 20', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '31.59', 'row': 29, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 30', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '32.98', 'row': 30, 'column': 4}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 40', 'metric': 'PSNR', 'model': 'DnCNN-3', 'value': '33.96', 'row': 31, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Horizon Line Estimation', 'dataset': 'York Urban Dataset', 'metric': 'AUC (horizon error)', 'model': 'CNN+FULL', 'value': '94.78', 'row': 6, 'column': 1}, {'task': 'Horizon Line Estimation', 'dataset': 'Eurasian Cities Dataset', 'metric': 'AUC (horizon error)', 'model': 'CNN+FULL', 'value': '90.80', 'row': 6, 'column': 2}, {'task': 'Horizon Line Estimation', 'dataset': 'Horizon Lines in the Wild', 'metric': 'AUC (horizon error)', 'model': 'CNN+FULL', 'value': '58.24', 'row': 6, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'MNIST-to-MNIST-M', 'metric': 'Accuracy', 'model': 'DSN (DANN)', 'value': '83.2', 'row': 7, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'Synth Digits-to-SVHN', 'metric': 'Accuracy', 'model': 'DSN (DANN)', 'value': '91.2', 'row': 7, 'column': 2}, {'task': 'Domain Adaptation', 'dataset': 'SVNH-to-MNIST', 'metric': 'Accuracy', 'model': 'DSN (DANN)', 'value': '82.7', 'row': 7, 'column': 3}, {'task': 'Domain Adaptation', 'dataset': 'Synth Signs-to-GTSRB', 'metric': 'Accuracy', 'model': 'DSN (DANN)', 'value': '93.1', 'row': 7, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Synth Objects-to-LINEMOD', 'metric': 'Classification Accuracy', 'model': 'DSN (DANN)', 'value': '100', 'row': 5, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'Synth Objects-to-LINEMOD', 'metric': 'Mean Angle Error', 'model': 'DSN (DANN)', 'value': '53.27', 'row': 5, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'SVHN', 'metric': 'Percentage error', 'model': 'DenseNet', 'value': '1.59', 'row': 18, 'column': 7}, {'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage error', 'model': 'DenseNet', 'value': '3.46', 'row': 21, 'column': 4}, {'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage error', 'model': 'DenseNet', 'value': '17.18', 'row': 21, 'column': 6}]}\n","{'index': 5, 'records': [{'task': 'Pose Estimation', 'dataset': 'MPII Human Pose', 'metric': 'PCKh-0.5', 'model': 'Part heatmap regression (ResNet-152)', 'value': '89.7', 'row': 1, 'column': 8}]}\n","{'index': 6, 'records': [{'task': 'Pose Estimation', 'dataset': 'Leeds Sports Poses', 'metric': 'PCK', 'model': 'Part heatmap regression (ResNet-152)', 'value': '90.7', 'row': 1, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRResNet', 'value': '32.05', 'row': 2, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRGAN', 'value': '29.4', 'row': 2, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRResNet', 'value': '0.9019', 'row': 3, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRGAN', 'value': '0.8472', 'row': 3, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'MOS', 'model': 'SRResNet', 'value': '3.37', 'row': 4, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'MOS', 'model': 'SRGAN', 'value': '3.58', 'row': 4, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRResNet', 'value': '28.49', 'row': 6, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRGAN', 'value': '26.02', 'row': 6, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRResNet', 'value': '0.8184', 'row': 7, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRGAN', 'value': '0.7397', 'row': 7, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'MOS', 'model': 'SRResNet', 'value': '2.98', 'row': 8, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'nearest neighbors', 'value': '26.26', 'row': 1, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'bicubic', 'value': '28.43', 'row': 1, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'nearest neighbors', 'value': '0.7552', 'row': 2, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'bicubic', 'value': '0.8211', 'row': 2, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'MOS', 'model': 'nearest neighbors', 'value': '1.28', 'row': 3, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'MOS', 'model': 'bicubic', 'value': '1.97', 'row': 3, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'nearest neighbors', 'value': '24.64', 'row': 5, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'bicubic', 'value': '25.99', 'row': 5, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'nearest neighbors', 'value': '0.71', 'row': 6, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'bicubic', 'value': '0.7486', 'row': 6, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'MOS', 'model': 'nearest neighbors', 'value': '1.2', 'row': 7, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'MOS', 'model': 'bicubic', 'value': '1.8', 'row': 7, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'MOS', 'model': 'SRGAN', 'value': '3.72', 'row': 7, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'nearest neighbors', 'value': '25.02', 'row': 9, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'bicubic', 'value': '25.94', 'row': 9, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRResNet', 'value': '27.58', 'row': 9, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRGAN', 'value': '25.16', 'row': 9, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'nearest neighbors', 'value': '0.6606', 'row': 10, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'bicubic', 'value': '0.6935', 'row': 10, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRResNet', 'value': '0.762', 'row': 10, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRGAN', 'value': '0.6688', 'row': 10, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'MOS', 'model': 'nearest neighbors', 'value': '1.11', 'row': 11, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'MOS', 'model': 'bicubic', 'value': '1.47', 'row': 11, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'MOS', 'model': 'SRResNet', 'value': '2.29', 'row': 11, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'MOS', 'model': 'SRGAN', 'value': '3.56', 'row': 11, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Recipe Generation', 'dataset': 'allrecipes.com', 'metric': 'Perplexity', 'model': 'Latent Variable Model', 'value': '4.97', 'row': 6, 'column': 5}, {'task': 'Recipe Generation', 'dataset': 'allrecipes.com', 'metric': 'BLEU', 'model': 'Latent Variable Model', 'value': '15.41', 'row': 6, 'column': 8}]}\n","{'index': 2, 'records': [{'task': 'SNES Games', 'dataset': 'F-Zero', 'metric': 'Score', 'model': 'DQN', 'value': '3116', 'row': 1, 'column': 1}, {'task': 'SNES Games', 'dataset': 'F-Zero', 'metric': 'Score', 'model': 'D-DQN', 'value': '3636', 'row': 1, 'column': 2}, {'task': 'SNES Games', 'dataset': 'F-Zero', 'metric': 'Score', 'model': 'Dueling D-DQN', 'value': '5161', 'row': 1, 'column': 3}, {'task': 'SNES Games', 'dataset': 'Gradius III', 'metric': 'Score', 'model': 'DQN', 'value': '7583', 'row': 2, 'column': 1}, {'task': 'SNES Games', 'dataset': 'Gradius III', 'metric': 'Score', 'model': 'D-DQN', 'value': '12343', 'row': 2, 'column': 2}, {'task': 'SNES Games', 'dataset': 'Gradius III', 'metric': 'Score', 'model': 'Dueling D-DQN', 'value': '16929', 'row': 2, 'column': 3}, {'task': 'SNES Games', 'dataset': 'Mortal Kombat', 'metric': 'Score', 'model': 'DQN', 'value': '83733', 'row': 3, 'column': 1}, {'task': 'SNES Games', 'dataset': 'Mortal Kombat', 'metric': 'Score', 'model': 'D-DQN', 'value': '56200', 'row': 3, 'column': 2}, {'task': 'SNES Games', 'dataset': 'Mortal Kombat', 'metric': 'Score', 'model': 'Dueling D-DQN', 'value': '169300', 'row': 3, 'column': 3}, {'task': 'SNES Games', 'dataset': 'Super Mario', 'metric': 'Score', 'model': 'DQN', 'value': '11765', 'row': 4, 'column': 1}, {'task': 'SNES Games', 'dataset': 'Super Mario', 'metric': 'Score', 'model': 'D-DQN', 'value': '16946', 'row': 4, 'column': 2}, {'task': 'SNES Games', 'dataset': 'Super Mario', 'metric': 'Score', 'model': 'Dueling D-DQN', 'value': '20030', 'row': 4, 'column': 3}, {'task': 'SNES Games', 'dataset': 'Wolfenstein', 'metric': 'Score', 'model': 'DQN', 'value': '100', 'row': 5, 'column': 1}, {'task': 'SNES Games', 'dataset': 'Wolfenstein', 'metric': 'Score', 'model': 'D-DQN', 'value': '83', 'row': 5, 'column': 2}, {'task': 'SNES Games', 'dataset': 'Wolfenstein', 'metric': 'Score', 'model': 'Dueling D-DQN', 'value': '40', 'row': 5, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Visual Question Answering', 'dataset': 'Visual Genome (subjects)', 'metric': 'Percentage correct', 'model': 'CMN', 'value': '44.24', 'row': 4, 'column': 2}, {'task': 'Visual Question Answering', 'dataset': 'Visual Genome (pairs)', 'metric': 'Percentage correct', 'model': 'CMN', 'value': '28.52', 'row': 4, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Visual Question Answering', 'dataset': 'Visual7W', 'metric': 'Percentage correct', 'model': 'CMN', 'value': '72.53', 'row': 4, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'FER2013', 'metric': 'Accuracy', 'model': 'VGG', 'value': '72.7', 'row': 1, 'column': 4}, {'task': 'Facial Expression Recognition', 'dataset': 'FER2013', 'metric': 'Accuracy', 'model': 'Inception', 'value': '71.6', 'row': 2, 'column': 4}, {'task': 'Facial Expression Recognition', 'dataset': 'FER2013', 'metric': 'Accuracy', 'model': 'Res-Net', 'value': '72.4', 'row': 3, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Text-to-Image Generation', 'dataset': 'CUB', 'metric': 'Inception score', 'model': 'StackGAN', 'value': '3.7', 'row': 1, 'column': 4}, {'task': 'Text-to-Image Generation', 'dataset': 'Oxford 102 Flowers', 'metric': 'Inception score', 'model': 'StackGAN', 'value': '3.2', 'row': 2, 'column': 4}, {'task': 'Text-to-Image Generation', 'dataset': 'COCO', 'metric': 'Inception score', 'model': 'StackGAN', 'value': '8.45', 'row': 3, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Action Classification', 'dataset': 'Charades', 'metric': 'MAP', 'model': 'Asyn-TF', 'value': '22.4', 'row': 6, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'CDC', 'value': '40.1', 'row': 13, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'CDC', 'value': '29.4', 'row': 13, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'CDC', 'value': '23.3', 'row': 13, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.6', 'model': 'CDC', 'value': '13.1', 'row': 13, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': 'CDC', 'value': '7.9', 'row': 13, 'column': 5}]}\n","{'index': 7, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'SSN', 'value': '39.12', 'row': 6, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'ConvNet with Memory Module', 'value': '98.4', 'row': 5, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'ConvNet with Memory Module', 'value': '99.6', 'row': 5, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'ConvNet with Memory Module', 'value': '95', 'row': 5, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'ConvNet with Memory Module', 'value': '98.6', 'row': 5, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '98.8', 'row': 5, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '99.7', 'row': 5, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '96', 'row': 5, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '98.9', 'row': 5, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '49.42', 'row': 6, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '68.20', 'row': 6, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 50-way (0-shot)', 'metric': 'Accuracy', 'model': 'Prototypical Networks', 'value': '54.6', 'row': 7, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'TURN-FL-16 + S-CNN', 'value': '54', 'row': 8, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': 'TURN-FL-16 + S-CNN', 'value': '50.9', 'row': 8, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'TURN-FL-16 + S-CNN', 'value': '44.1', 'row': 8, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'TURN-FL-16 + S-CNN', 'value': '34.9', 'row': 8, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'TURN-FL-16 + S-CNN', 'value': '25.6', 'row': 8, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'SegLink', 'value': '73.1', 'row': 8, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'SegLink', 'value': '76.8', 'row': 8, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'SegLink', 'value': '75', 'row': 8, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'SegLink', 'value': '86', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'SegLink', 'value': '70', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'SegLink', 'value': '77', 'row': 7, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'SegLink', 'value': '87.7', 'row': 9, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'SegLink', 'value': '83', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'SegLink', 'value': '85.3', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'R-C3D', 'value': '54.5', 'row': 13, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': 'R-C3D', 'value': '51.5', 'row': 13, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'R-C3D', 'value': '44.8', 'row': 13, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'R-C3D', 'value': '35.6', 'row': 13, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'R-C3D', 'value': '28.9', 'row': 13, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'R-C3D', 'value': '26.8', 'row': 4, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Action Detection', 'dataset': 'Charades', 'metric': 'mAP', 'model': 'R-C3D', 'value': '12.4', 'row': 7, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'Accuracy', 'model': 'DBC', 'value': '0.964', 'row': 1, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'DBC', 'value': '0.917', 'row': 2, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'Accuracy', 'model': 'DBC', 'value': '0.743', 'row': 1, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'DBC', 'value': '0.724', 'row': 2, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'Accuracy', 'model': 'DBC', 'value': '0.793', 'row': 1, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'model': 'DBC', 'value': '0.895', 'row': 2, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Image Clustering', 'dataset': 'coil-100', 'metric': 'Accuracy', 'model': 'DBC', 'value': '0.775', 'row': 1, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'coil-100', 'metric': 'NMI', 'model': 'DBC', 'value': '0.905', 'row': 2, 'column': 4}]}\n","{'index': 8, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'DeNet-101 (skip)', 'value': '77.1', 'row': 11, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'MR', 'model': 'ParTransH', 'value': '215', 'row': 8, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'WN18 (filtered)', 'metric': 'MR', 'model': 'ParTransH', 'value': '203', 'row': 8, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@10', 'model': 'ParTransH', 'value': '0.668', 'row': 8, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'WN18 (filtered)', 'metric': 'Hits@10', 'model': 'ParTransH', 'value': '76.6', 'row': 8, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'MR', 'model': 'ParTransH', 'value': '183', 'row': 8, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'FB15k (filtered)', 'metric': 'MR', 'model': 'ParTransH', 'value': '60', 'row': 8, 'column': 8}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@10', 'model': 'ParTransH', 'value': '46.8', 'row': 8, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'FB15k (filtered)', 'metric': 'Hits@10', 'model': 'ParTransH', 'value': '65.7', 'row': 8, 'column': 10}]}\n","{'index': 4, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'TS-LSTM', 'value': '94.1', 'row': 10, 'column': 1}, {'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'TS-LSTM', 'value': '69', 'row': 10, 'column': 2}]}\n","{'index': 0, 'records': [{'task': '3D Point Cloud Classification', 'dataset': 'Sydney Urban Objects', 'metric': 'F1', 'model': 'ECC', 'value': '78.4', 'row': 7, 'column': 1}]}\n","{'index': 1, 'records': [{'task': '3D Object Classification', 'dataset': 'ModelNet10', 'metric': 'Accuracy', 'model': 'ECC (12 votes)', 'value': '90', 'row': 7, 'column': 1}, {'task': '3D Object Classification', 'dataset': 'ModelNet40', 'metric': 'Accuracy', 'model': 'ECC (12 votes)', 'value': '83.2', 'row': 7, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'ECC (5 scores)', 'value': '83.8', 'row': 9, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'ECC (5 scores)', 'value': '82.14', 'row': 9, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'ECC (5 scores)', 'value': '88.33', 'row': 9, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'ECC (5 scores)', 'value': '52.67', 'row': 9, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'ECC (5 scores)', 'value': '74.1', 'row': 9, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'EAST + PVANET2x RBOX (multi-scale)', 'value': '78.33', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'EAST + PVANET2x RBOX (multi-scale)', 'value': '83.27', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'EAST + PVANET2x RBOX (multi-scale)', 'value': '80.72', 'row': 1, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'EAST + PVANET2x RBOX (single-scale)', 'value': '73.47', 'row': 2, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'EAST + PVANET2x RBOX (single-scale)', 'value': '83.57', 'row': 2, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'EAST + PVANET2x RBOX (single-scale)', 'value': '78.2', 'row': 2, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Recall', 'model': 'EAST + VGG16', 'value': '32.4', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Precision', 'model': 'EAST + VGG16', 'value': '50.39', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'F-Measure', 'model': 'EAST + VGG16', 'value': '39.45', 'row': 1, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'EAST + PVANET2x', 'value': '67.43', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'EAST + PVANET2x', 'value': '87.28', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'EAST + PVANET2x', 'value': '76.08', 'row': 1, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-dev', 'metric': 'Accuracy', 'model': 'SAAA (ResNet)', 'value': '64.5', 'row': 13, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-std', 'metric': 'Accuracy', 'model': 'SAAA (ResNet)', 'value': '64.6', 'row': 13, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '31.63', 'row': 1, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '29.15', 'row': 2, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '26.19', 'row': 3, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma5', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '40.36', 'row': 2, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '33.86', 'row': 2, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '31.16', 'row': 2, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma35', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '29.5', 'row': 2, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '27.86', 'row': 2, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '37.43', 'row': 1, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '35.05', 'row': 2, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '33.39', 'row': 3, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '31.26', 'row': 4, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '33.38', 'row': 5, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '30.92', 'row': 6, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '32.88', 'row': 7, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '30.79', 'row': 8, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '29.61', 'row': 9, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '27.72', 'row': 10, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '29.63', 'row': 11, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'Deep CNN Denoiser', 'value': '27.59', 'row': 12, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'NTU RGB+D', 'metric': 'Accuracy (CS)', 'model': 'TCN', 'value': '74.3', 'row': 7, 'column': 1}, {'task': 'Skeleton Based Action Recognition', 'dataset': 'NTU RGB+D', 'metric': 'Accuracy (CV)', 'model': 'TCN', 'value': '83.1', 'row': 7, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MobileNet-224', 'value': '70.6', 'row': 3, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'N2NMN (ResNet-152, policy search)', 'value': '64.9', 'row': 6, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'THUMOS’14', 'metric': 'mAP@0.1', 'model': 'SSN', 'value': '66.0', 'row': 9, 'column': 1}, {'task': 'Action Recognition In Videos', 'dataset': 'THUMOS’14', 'metric': 'mAP@0.2', 'model': 'SSN', 'value': '59.4', 'row': 9, 'column': 2}, {'task': 'Action Recognition In Videos', 'dataset': 'THUMOS’14', 'metric': 'mAP@0.3', 'model': 'SSN', 'value': '51.9', 'row': 9, 'column': 3}, {'task': 'Action Recognition In Videos', 'dataset': 'THUMOS’14', 'metric': 'mAP@0.4', 'model': 'SSN', 'value': '41.0', 'row': 9, 'column': 4}, {'task': 'Action Recognition In Videos', 'dataset': 'THUMOS’14', 'metric': 'mAP@0.5', 'model': 'SSN', 'value': '29.8', 'row': 9, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'VOT2016', 'metric': 'Expected Average Overlap (EAO)', 'model': 'CFCF', 'value': '0.3903', 'row': 1, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'NTU RGB+D', 'metric': 'Accuracy (CV)', 'model': 'Five Spatial Skeleton Features', 'value': '82.31', 'row': 10, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'CBR-TS', 'value': '60.1', 'row': 6, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': 'CBR-TS', 'value': '56.7', 'row': 6, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'CBR-TS', 'value': '50.1', 'row': 6, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'CBR-TS', 'value': '41.3', 'row': 6, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'CBR-TS', 'value': '31', 'row': 6, 'column': 5}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.6', 'model': 'CBR-TS', 'value': '19.1', 'row': 6, 'column': 6}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': 'CBR-TS', 'value': '9.9', 'row': 6, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'MUTAN', 'value': '67.42', 'row': 12, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'MUTAN', 'value': '67.36', 'row': 12, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Density Estimation', 'dataset': 'UCI POWER', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '0.4', 'row': 3, 'column': 1}, {'task': 'Density Estimation', 'dataset': 'UCI GAS', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '8.47', 'row': 3, 'column': 3}, {'task': 'Density Estimation', 'dataset': 'UCI HEPMASS', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '-15.15', 'row': 3, 'column': 5}, {'task': 'Density Estimation', 'dataset': 'UCI MINIBOONE', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '-12.27', 'row': 3, 'column': 7}, {'task': 'Density Estimation', 'dataset': 'BSDS300', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '153.71', 'row': 3, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Density Estimation', 'dataset': 'MNIST', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '-1038.5', 'row': 4, 'column': 1}, {'task': 'Density Estimation', 'dataset': 'MNIST (Conditional)', 'metric': 'Log-likelihood', 'model': 'MADE MoG', 'value': '-1030.3', 'row': 4, 'column': 3}, {'task': 'Density Estimation', 'dataset': 'CIFAR-10', 'metric': 'Log-likelihood', 'model': 'MAF', 'value': '3049', 'row': 8, 'column': 5}, {'task': 'Density Estimation', 'dataset': 'CIFAR-10 (Conditional)', 'metric': 'Log-likelihood', 'model': 'MAF', 'value': '3058', 'row': 8, 'column': 7}]}\n","{'index': 4, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'Two-stream I3D', 'value': '80.9', 'row': 17, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'WordNet', 'metric': 'Accuracy', 'model': 'Poincare Embeddings (dim=10)', 'value': '68.3', 'row': 10, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'WordNet', 'metric': 'Accuracy', 'model': 'Poincare Embeddings (dim=20)', 'value': '74.3', 'row': 10, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'WordNet', 'metric': 'Accuracy', 'model': 'Poincare Embeddings (dim=50)', 'value': '77.0', 'row': 10, 'column': 8}, {'task': 'Link Prediction', 'dataset': 'WordNet', 'metric': 'Accuracy', 'model': 'Poincare Embeddings (dim=100)', 'value': '77.4', 'row': 10, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Lexical Entailment', 'dataset': 'HyperLex', 'metric': 'Spearman Correlation', 'model': 'Poincare Embeddings', 'value': '0.512', 'row': 1, 'column': 8}]}\n","{'index': 2, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'J-HMDB-21', 'metric': 'Frame-mAP', 'model': 'Faster-RCNN + two-stream I3D conv', 'value': '73.3', 'row': 5, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'UCF101-24', 'metric': 'Frame-mAP', 'model': 'Faster-RCNN + two-stream I3D conv', 'value': '76.3', 'row': 5, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'J-HMDB-21', 'metric': 'Video-mAP 0.5', 'model': 'Faster-RCNN + two-stream I3D conv', 'value': '78.6', 'row': 5, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'UCF101-24', 'metric': 'Video-mAP 0.5', 'model': 'Faster-RCNN + two-stream I3D conv', 'value': '59.9', 'row': 5, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Face Alignment', 'dataset': '300W', 'metric': 'Mean Error Rate private', 'model': 'DAN-Menpo + inter-ocular normalization', 'value': '3.97', 'row': 7, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Category-agnostic mapping WRN', 'value': '59.60', 'row': 7, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Category-agnostic mapping WRN', 'value': '73.74', 'row': 7, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 20M', 'metric': 'AUC', 'model': 'DIN', 'value': '0.7337', 'row': 7, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Amazon', 'metric': 'AUC', 'model': 'DIN', 'value': '0.8818', 'row': 7, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 20M', 'metric': 'AUC', 'model': 'DIN + Dice Activation', 'value': '0.7348', 'row': 8, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Amazon', 'metric': 'AUC', 'model': 'DIN + Dice Activation', 'value': '0.8871', 'row': 8, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '5778', 'row': 1, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '3537', 'row': 2, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '11231', 'row': 3, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '28350', 'row': 4, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '86700', 'row': 5, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '972175', 'row': 6, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '1318', 'row': 7, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '52262', 'row': 8, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '18501', 'row': 9, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '1896', 'row': 10, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '68', 'row': 11, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '100', 'row': 12, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '263', 'row': 13, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '7596', 'row': 14, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '11477', 'row': 15, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '171171', 'row': 16, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '42253', 'row': 17, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '69311', 'row': 18, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '1', 'row': 19, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '2013', 'row': 20, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '57', 'row': 21, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '34', 'row': 22, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '2923', 'row': 23, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '38909', 'row': 24, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '2209', 'row': 25, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '31533', 'row': 26, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '3', 'row': 27, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '4682', 'row': 28, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '15227', 'row': 29, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '10754', 'row': 30, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '41672', 'row': 31, 'column': 8}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '57', 'row': 32, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '5546', 'row': 33, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '12211', 'row': 34, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '10379', 'row': 35, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '0', 'row': 36, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '21', 'row': 37, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '279', 'row': 38, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '27121', 'row': 39, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '23134', 'row': 40, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '234352', 'row': 41, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '64', 'row': 42, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '16754', 'row': 43, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '-7550', 'row': 44, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '6522', 'row': 45, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '5909', 'row': 46, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '75867', 'row': 47, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Surround', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '10', 'row': 48, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '0', 'row': 49, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '17301', 'row': 50, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '269', 'row': 51, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '61326', 'row': 52, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '815', 'row': 53, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '870954', 'row': 54, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '9149', 'row': 55, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Yars Revenge', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '86101', 'row': 56, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'NoisyNet-Dueling', 'value': '14874', 'row': 57, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'Doc2VecC', 'value': '88.3', 'row': 8, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Semantic Similarity', 'dataset': 'SICK', 'metric': 'Pearson Correlation', 'model': 'Doc2VecC', 'value': '0.8381', 'row': 12, 'column': 1}, {'task': 'Semantic Similarity', 'dataset': 'SICK', 'metric': 'Spearman Correlation', 'model': 'Doc2VecC', 'value': '0.7621', 'row': 12, 'column': 2}, {'task': 'Semantic Similarity', 'dataset': 'SICK', 'metric': 'MSE', 'model': 'Doc2VecC', 'value': '0.3053', 'row': 12, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'EDSR', 'value': '32.46', 'row': 3, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'EDSR', 'value': '28.8', 'row': 6, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'EDSR', 'value': '27.71', 'row': 9, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'EDSR', 'value': '26.64', 'row': 12, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'ResNet-101 (JFT-300M Finetuning)', 'value': '79.2', 'row': 3, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'ResNet-101 (JFT-300M Finetuning)', 'value': '94.7', 'row': 3, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2007', 'metric': 'Mean IoU', 'model': 'DeepLabv3 (ImageNet+300M)', 'value': '81.3', 'row': 3, 'column': 21}]}\n","{'index': 12, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '37.4', 'row': 3, 'column': 1}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '58', 'row': 3, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '40.1', 'row': 3, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '17.5', 'row': 3, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '41.1', 'row': 3, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '51.2', 'row': 3, 'column': 6}]}\n","{'index': 13, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'Mean IoU', 'model': 'DeepLabv3 (ImageNet+300M)', 'value': '76.5', 'row': 3, 'column': 1}, {'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'mIoU', 'model': 'DeepLabv3 (ImageNet+300M)', 'value': '76.5', 'row': 3, 'column': 1}]}\n","{'index': 14, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '64.4', 'row': 4, 'column': 1}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '85.7', 'row': 4, 'column': 2}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '70.7', 'row': 4, 'column': 3}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '61.8', 'row': 4, 'column': 4}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Faster R-CNN (ImageNet+300M)', 'value': '69.8', 'row': 4, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'VPN', 'value': '3811', 'row': 2, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'VPN', 'value': '5628', 'row': 2, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'VPN', 'value': '382', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'VPN', 'value': '1429', 'row': 2, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'VPN', 'value': '14517', 'row': 2, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'VPN', 'value': '2689', 'row': 2, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'VPN', 'value': '641', 'row': 2, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'VPN', 'value': '15930', 'row': 2, 'column': 8}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'VPN', 'value': '54119', 'row': 2, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'MGB', 'metric': 'Accuracy', 'model': 'F-BLSTM', 'value': '98.04', 'row': 13, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'BUAA', 'metric': 'Accuracy', 'model': 'F-BGRU', 'value': '99.25', 'row': 9, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'SmartWatch', 'metric': 'Accuracy', 'model': 'F-BGRU', 'value': '97.4', 'row': 21, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '83.15', 'row': 5, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '60.17', 'row': 5, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '73.3', 'row': 5, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '73.22', 'row': 5, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '74.26', 'row': 5, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Malware Detection', 'dataset': 'Android Malware Dataset', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '99.03', 'row': 5, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Malware Clustering', 'dataset': 'Android Malware Dataset', 'metric': 'ARI', 'model': 'Graph2Vec', 'value': '56.28', 'row': 5, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Mean AP', 'model': 'RL', 'value': '57.2', 'row': 13, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'NELL-995', 'metric': 'Mean AP', 'model': 'RL', 'value': '79.6', 'row': 13, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'DDQN (tuned) noop', 'value': '17356.5', 'row': 4, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'DDQN (tuned) noop', 'value': '68.1', 'row': 11, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'Bootstrapped DQN', 'value': '20.9', 'row': 37, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'DDQN (tuned) noop', 'value': '15088.5', 'row': 39, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Hand Pose Estimation', 'dataset': 'ICVL Hands', 'metric': 'Average 3D Error', 'model': 'Tree Region Ensemble Network', 'value': '7.31', 'row': 6, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Hand Pose Estimation', 'dataset': 'NYU Hands', 'metric': 'Average 3D Error', 'model': 'REN', 'value': '15.6', 'row': 6, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Pose Estimation', 'dataset': ' ITOP front-view', 'metric': 'Mean mAP', 'model': 'REN', 'value': '84.9', 'row': 11, 'column': 3}, {'task': 'Pose Estimation', 'dataset': 'ITOP top-view', 'metric': 'Mean mAP', 'model': 'REN', 'value': '75.5', 'row': 11, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'Up-Down', 'value': '70.34', 'row': 8, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Crowd Counting', 'dataset': 'ShanghaiTech A', 'metric': 'MAE', 'model': 'Proposed method', 'value': '101.3', 'row': 5, 'column': 1}, {'task': 'Crowd Counting', 'dataset': 'ShanghaiTech A', 'metric': 'MSE', 'model': 'Proposed method', 'value': '152.4', 'row': 5, 'column': 2}, {'task': 'Crowd Counting', 'dataset': 'ShanghaiTech B', 'metric': 'MAE', 'model': 'Cascaded-MTL', 'value': '20', 'row': 5, 'column': 3}, {'task': 'Crowd Counting', 'dataset': 'ShanghaiTech B', 'metric': 'MSE', 'model': 'Proposed method', 'value': '31.1', 'row': 5, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Crowd Counting', 'dataset': 'UCF CC 50', 'metric': 'MAE', 'model': 'Cascaded-MTL', 'value': '322.8', 'row': 6, 'column': 1}, {'task': 'Crowd Counting', 'dataset': 'UCF CC 50', 'metric': 'MSE', 'model': 'Proposed method', 'value': '397.9', 'row': 6, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'Image features from bottom-up attention (adaptive K, ensemble)', 'value': '69.87', 'row': 16, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'Image features from bottom-up attention (adaptive K, ensemble)', 'value': '70.34', 'row': 16, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'WordSup (VGG16-synth-icdar)', 'value': '87.53', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'WordSup (VGG16-synth-icdar)', 'value': '93.34', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'WordSup (VGG16-synth-icdar)', 'value': '90.34', 'row': 7, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'WordSup (VGG16-synth-icdar)', 'value': '77.03', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'WordSup (VGG16-synth-icdar)', 'value': '79.33', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'WordSup (VGG16-synth-icdar)', 'value': '78.16', 'row': 7, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Recall', 'model': 'WordSup (VGG16-synth-coco)', 'value': '30.9', 'row': 6, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Precision', 'model': 'WordSup (VGG16-synth-coco)', 'value': '45.2', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'F-Measure', 'model': 'WordSup (VGG16-synth-coco)', 'value': '36.8', 'row': 6, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'SSTD', 'value': '86', 'row': 14, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'SSTD', 'value': '88', 'row': 14, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'SSTD', 'value': '87', 'row': 14, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'SSTD', 'value': '73', 'row': 14, 'column': 9}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'SSTD', 'value': '80', 'row': 14, 'column': 10}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'SSTD', 'value': '77', 'row': 14, 'column': 11}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Recall', 'model': 'SSTD', 'value': '31', 'row': 6, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Precision', 'model': 'SSTD', 'value': '46', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'F-Measure', 'model': 'SSTD', 'value': '37', 'row': 6, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Continuous Control', 'dataset': 'Cart Pole (OpenAI Gym)', 'metric': 'Score', 'model': 'MAC', 'value': '178.3', 'row': 5, 'column': 1}, {'task': 'Continuous Control', 'dataset': 'Lunar Lander (OpenAI Gym)', 'metric': 'Score', 'model': 'MAC', 'value': '163.5', 'row': 5, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'MAC', 'value': '6072', 'row': 1, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'MAC', 'value': '372.7', 'row': 2, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'MAC', 'value': '10.6', 'row': 3, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'MAC', 'value': '243.4', 'row': 4, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'MAC', 'value': '1703.4', 'row': 5, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'MAC', 'value': '1173.1', 'row': 6, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'FTSN + MNMS', 'value': '88.6', 'row': 10, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'FTSN + MNMS', 'value': '80', 'row': 10, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'H-Mean', 'model': 'FTSN + MNMS', 'value': '84.1', 'row': 10, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'FTSN + MNMS', 'value': '87.6', 'row': 8, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'FTSN + MNMS', 'value': '77.1', 'row': 8, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'H-Mean', 'model': 'FTSN + MNMS', 'value': '82', 'row': 8, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'FTSN', 'value': '84.7', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'FTSN', 'value': '78', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'H-Mean', 'model': 'FTSN', 'value': '81.3', 'row': 1, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Sketch-Based Image Retrieval', 'dataset': 'Shoes', 'metric': 'R@1', 'model': 'EdgeMAC + whitening', 'value': '54.8', 'row': 13, 'column': 2}, {'task': 'Sketch-Based Image Retrieval', 'dataset': 'Shoes', 'metric': 'R@10', 'model': 'EdgeMAC + whitening', 'value': '92.2', 'row': 13, 'column': 3}, {'task': 'Sketch-Based Image Retrieval', 'dataset': 'Chairs', 'metric': 'R@1', 'model': 'EdgeMAC + whitening', 'value': '85.6', 'row': 13, 'column': 4}, {'task': 'Sketch-Based Image Retrieval', 'dataset': 'Chairs', 'metric': 'R@10', 'model': 'EdgeMAC + whitening', 'value': '97.9', 'row': 13, 'column': 5}, {'task': 'Sketch-Based Image Retrieval', 'dataset': 'Handbags', 'metric': 'R@1', 'model': 'EdgeMAC + whitening', 'value': '51.2', 'row': 13, 'column': 6}, {'task': 'Sketch-Based Image Retrieval', 'dataset': 'Handbags', 'metric': 'R@10', 'model': 'EdgeMAC + whitening', 'value': '85.7', 'row': 13, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Document Classification', 'dataset': 'WOS-5736', 'metric': 'Accuracy', 'model': 'HDLTex', 'value': '90.93', 'row': 18, 'column': 9}, {'task': 'Document Classification', 'dataset': 'WOS-11967', 'metric': 'Accuracy', 'model': 'HDLTex', 'value': '86.07', 'row': 22, 'column': 3}, {'task': 'Document Classification', 'dataset': 'WOS-46985', 'metric': 'Accuracy', 'model': 'HDLTex', 'value': '76.58', 'row': 26, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Head Pose Estimation', 'dataset': 'AFLW2000', 'metric': 'MAE', 'model': 'Multi-Loss ResNet50 (a=2)', 'value': '6.155', 'row': 1, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Head Pose Estimation', 'dataset': 'BIWI', 'metric': 'MAE', 'model': 'Multi-Loss ResNet50', 'value': '4.895', 'row': 2, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma15', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '25.49', 'row': 32, 'column': 13}]}\n","{'index': 2, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '31.63', 'row': 1, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '29.19', 'row': 2, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma35', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '27.73', 'row': 3, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '26.29', 'row': 4, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma75', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '24.79', 'row': 5, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Clip300 sigma15', 'metric': 'PSNR', 'model': 'FFDNet-Clip', 'value': '31.68', 'row': 3, 'column': 1}, {'task': 'Grayscale Image Denoising', 'dataset': 'Clip300 sigma25', 'metric': 'PSNR', 'model': 'FFDNet-Clip', 'value': '29.25', 'row': 3, 'column': 2}, {'task': 'Grayscale Image Denoising', 'dataset': 'Clip300 sigma35', 'metric': 'PSNR', 'model': 'FFDNet-Clip', 'value': '27.75', 'row': 3, 'column': 3}, {'task': 'Grayscale Image Denoising', 'dataset': 'Clip300 sigma50', 'metric': 'PSNR', 'model': 'FFDNet-Clip', 'value': '26.25', 'row': 3, 'column': 4}, {'task': 'Grayscale Image Denoising', 'dataset': 'Clip300 sigma60', 'metric': 'PSNR', 'model': 'FFDNet-Clip', 'value': '25.51', 'row': 3, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma15', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '33.87', 'row': 3, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma25', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '31.21', 'row': 3, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma35', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '29.58', 'row': 3, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma50', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '27.96', 'row': 3, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma75', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '26.24', 'row': 3, 'column': 6}, {'task': 'Color Image Denoising', 'dataset': 'Kodak25 sigma15', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '34.63', 'row': 6, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'Kodak25 sigma25', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '32.13', 'row': 6, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Kodak25 sigma35', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '30.57', 'row': 6, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'Kodak25 sigma50', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '28.98', 'row': 6, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'Kodak25 sigma75', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '27.27', 'row': 6, 'column': 6}, {'task': 'Color Image Denoising', 'dataset': 'McMaster sigma15', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '34.66', 'row': 9, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'McMaster sigma25', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '32.35', 'row': 9, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'McMaster sigma35', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '30.81', 'row': 9, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'McMaster sigma50', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '29.18', 'row': 9, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'McMaster sigma75', 'metric': 'PSNR', 'model': 'FFDNet', 'value': '27.33', 'row': 9, 'column': 6}]}\n","{'index': 5, 'records': [{'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.001', 'model': 'VGGFace2_ft', 'value': '0.921', 'row': 7, 'column': 2}, {'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.01', 'model': 'VGGFace2_ft', 'value': '0.968', 'row': 7, 'column': 3}, {'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.1', 'model': 'VGGFace2_ft', 'value': '0.99', 'row': 7, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Face Verification', 'dataset': 'IJB-B', 'metric': 'TAR @ FAR=0.001', 'model': 'VGGFace2_ft', 'value': '0.908', 'row': 7, 'column': 4}, {'task': 'Face Verification', 'dataset': 'IJB-B', 'metric': 'TAR @ FAR=0.01', 'model': 'VGGFace2_ft', 'value': '0.956', 'row': 7, 'column': 5}]}\n","{'index': 7, 'records': [{'task': 'Face Verification', 'dataset': 'IJB-C', 'metric': 'TAR @ FAR=0.001', 'model': 'VGGFace2_ft', 'value': '92.7', 'row': 5, 'column': 4}, {'task': 'Face Verification', 'dataset': 'IJB-C', 'metric': 'TAR @ FAR=0.01', 'model': 'VGGFace2_ft', 'value': '96.7', 'row': 5, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari-57', 'metric': 'Medium Human-Normalized Score', 'model': 'QR-DQN-1', 'value': '211', 'row': 8, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '4871', 'row': 1, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '1641', 'row': 2, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '22012', 'row': 3, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '261025', 'row': 4, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '4226', 'row': 5, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '971850', 'row': 6, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '1249', 'row': 7, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '39268', 'row': 8, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '34821', 'row': 9, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '3117', 'row': 10, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '77.2', 'row': 11, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '99.9', 'row': 12, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '742', 'row': 13, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '12447', 'row': 14, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '14667', 'row': 15, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '161196', 'row': 16, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '47887', 'row': 17, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '121551', 'row': 18, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '21.9', 'row': 19, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '2355', 'row': 20, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '39', 'row': 21, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '34', 'row': 22, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '4384', 'row': 23, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '113585', 'row': 24, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '995', 'row': 25, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '21395', 'row': 26, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '-1.7', 'row': 27, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '4703', 'row': 28, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '15356', 'row': 29, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '11447', 'row': 30, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '76642', 'row': 31, 'column': 7}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '0', 'row': 32, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '5821', 'row': 33, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '21890', 'row': 34, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '16585', 'row': 35, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '0', 'row': 36, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '21', 'row': 37, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '350', 'row': 38, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '572510', 'row': 39, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '17571', 'row': 40, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '64262', 'row': 41, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '59.4', 'row': 42, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '8268', 'row': 43, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '-9324', 'row': 44, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '6740', 'row': 45, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '20972', 'row': 46, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '77495', 'row': 47, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Surround', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '8.2', 'row': 48, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '23.6', 'row': 49, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '10345', 'row': 50, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '297', 'row': 51, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '71260', 'row': 52, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '43.9', 'row': 53, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '705662', 'row': 54, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '25061', 'row': 55, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Yars Revenge', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '26447', 'row': 56, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'QR-DQN-1', 'value': '13112', 'row': 57, 'column': 7}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'YCB-Video', 'metric': 'Mean ADD', 'model': 'PoseCNN', 'value': '53.7', 'row': 24, 'column': 3}, {'task': '6D Pose Estimation using RGB', 'dataset': 'YCB-Video', 'metric': 'Mean ADD-S', 'model': 'PoseCNN', 'value': '75.9', 'row': 24, 'column': 4}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'YCB-Video', 'metric': 'Mean ADD', 'model': 'PoseCNN (ICP)', 'value': '79.3', 'row': 24, 'column': 9}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'YCB-Video', 'metric': 'Mean ADD-S', 'model': 'ALL PoseCNN+ICP', 'value': '93', 'row': 24, 'column': 10}]}\n","{'index': 2, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'Occlusion LineMOD', 'metric': 'Mean ADD', 'model': 'Ours PoseCNN+ICP', 'value': '78', 'row': 9, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MRR', 'model': 'KBGAN (TransD + ComplEx)', 'value': '0.277', 'row': 11, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@10', 'model': 'KBGAN (TransD + ComplEx)', 'value': '0.458', 'row': 11, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'MRR', 'model': 'KBGAN (TransD + ComplEx)', 'value': '0.779', 'row': 11, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@10', 'model': 'KBGAN (TransD + ComplEx)', 'value': '0.948', 'row': 11, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MRR', 'model': 'KBGAN (TransD + ComplEx)', 'value': '0.215', 'row': 11, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@10', 'model': 'KBGAN (TransD + ComplEx)', 'value': '0.469', 'row': 11, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Relation Net', 'value': '99.6', 'row': 12, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Relation Net', 'value': '99.8', 'row': 12, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Relation Net', 'value': '97.6', 'row': 12, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Relation Net', 'value': '99.1', 'row': 12, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'Relation Net', 'value': '50.44', 'row': 7, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 5-shot', 'metric': 'Accuracy', 'model': 'Relation Net', 'value': '65.32', 'row': 7, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Easy val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '89.6', 'row': 8, 'column': 2}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Moderate val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '84.81', 'row': 8, 'column': 3}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Hard val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '78.57', 'row': 8, 'column': 4}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Pedestrian Easy val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '65.95', 'row': 8, 'column': 5}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Pedestrian Moderate val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '61.05', 'row': 8, 'column': 6}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Pedestrian Hard val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '56.98', 'row': 8, 'column': 7}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclist Easy val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '74.41', 'row': 8, 'column': 8}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclist Moderate val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '52.18', 'row': 8, 'column': 9}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclist Hard val', 'metric': 'AP', 'model': 'VoxelNet', 'value': '50.49', 'row': 8, 'column': 10}]}\n","{'index': 2, 'records': [{'task': '3D Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '77.47', 'row': 1, 'column': 1}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '65.11', 'row': 1, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '57.73', 'row': 1, 'column': 3}, {'task': 'Object Localization', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'VoxelNet', 'value': '89.35', 'row': 2, 'column': 1}, {'task': 'Object Localization', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'VoxelNet', 'value': '79.26', 'row': 2, 'column': 2}, {'task': 'Object Localization', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'VoxelNet', 'value': '77.39', 'row': 2, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Easy', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '39.48', 'row': 3, 'column': 1}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Moderate', 'metric': 'AP', 'model': 'VoxelNet', 'value': '33.69', 'row': 3, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Hard', 'metric': 'AP', 'model': 'VoxelNet', 'value': '31.51', 'row': 3, 'column': 3}, {'task': 'Object Localization', 'dataset': 'KITTI Pedestrians Easy', 'metric': 'AP', 'model': 'VoxelNet', 'value': '46.13', 'row': 4, 'column': 1}, {'task': 'Object Localization', 'dataset': 'KITTI Pedestrians Moderate', 'metric': 'AP', 'model': 'VoxelNet', 'value': '40.74', 'row': 4, 'column': 2}, {'task': 'Object Localization', 'dataset': 'KITTI Pedestrians Hard', 'metric': 'AP', 'model': 'VoxelNet', 'value': '38.11', 'row': 4, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '61.22', 'row': 5, 'column': 1}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '48.36', 'row': 5, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'VoxelNet ', 'value': '44.37', 'row': 5, 'column': 3}, {'task': 'Object Localization', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'VoxelNet', 'value': '66.7', 'row': 6, 'column': 1}, {'task': 'Object Localization', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'VoxelNet', 'value': '54.76', 'row': 6, 'column': 2}, {'task': 'Object Localization', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'VoxelNe', 'value': '50.55', 'row': 6, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'CK+', 'metric': 'Accuracy (10-fold)', 'model': 'MicroExpNet', 'value': '96.9', 'row': 10, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'Oulu-CASIA', 'metric': 'Accuracy (10-fold)', 'model': 'MicroExpNet', 'value': '95.02', 'row': 10, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'AlignedReID (RK)', 'value': '90.7', 'row': 17, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'AlignedReID (RK)', 'value': '94.4', 'row': 17, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-1', 'model': 'AlignedReID (RK)', 'value': '97.8', 'row': 17, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-5', 'model': 'AlignedReID (RK)', 'value': '99.6', 'row': 17, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-10', 'model': 'AlignedReID (RK)', 'value': '99.8', 'row': 17, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK-SYSU', 'metric': 'MAP', 'model': 'AlignedReID', 'value': '94.4', 'row': 4, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'CUHK-SYSU', 'metric': 'Rank-1', 'model': 'AlignedReID', 'value': '95.7', 'row': 4, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Node Classification', 'dataset': 'BlogCatalog', 'metric': 'Macro-F1', 'model': 'GraphGAN', 'value': '0.221', 'row': 6, 'column': 2}, {'task': 'Node Classification', 'dataset': 'Wikipedia', 'metric': 'Accuracy', 'model': 'GraphGAN', 'value': '21.3', 'row': 6, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Ad-Hoc Information Retrieval', 'dataset': 'TREC Robust04', 'metric': 'P@20', 'model': 'DRMM', 'value': '0.382', 'row': 17, 'column': 4}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Accuracy', 'model': 'Single-shot Deep CNN', 'value': '90.37%', 'row': 16, 'column': 3}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'Single-shot Deep CNN', 'value': '55.95', 'row': 16, 'column': 4}]}\n","{'index': 3, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean IoU', 'model': 'Single-shot Deep CNN', 'value': '99.92', 'row': 14, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Node Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'SplineCNN', 'value': '89.48', 'row': 1, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'TSN+TSM', 'value': '94.3', 'row': 18, 'column': 4}]}\n","{'index': 2, 'records': [{'task': '6D Pose Estimation using RGBD', 'dataset': 'Tejani', 'metric': 'IoU-2D', 'model': 'SSD-6D', 'value': '0.988', 'row': 7, 'column': 1}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'Tejani', 'metric': 'IoU-3D', 'model': 'SSD-6D', 'value': '0.963', 'row': 7, 'column': 2}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'Tejani', 'metric': 'VSS-2D', 'model': 'SSD-6D', 'value': '0.724', 'row': 7, 'column': 3}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'Tejani', 'metric': 'VSS-3D', 'model': 'SSD-6D', 'value': '0.854', 'row': 7, 'column': 4}]}\n","{'index': 3, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean IoU', 'model': 'SSD-6D', 'value': '99.4', 'row': 2, 'column': 1}, {'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'SSD-6D', 'value': '76.3', 'row': 3, 'column': 1}]}\n","{'index': 4, 'records': [{'task': '6D Pose Estimation using RGBD', 'dataset': 'LineMOD', 'metric': 'Mean IoU', 'model': 'SSD-6D', 'value': '96.5', 'row': 2, 'column': 1}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'SSD-6D', 'value': '90.9', 'row': 3, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'Sports-1M', 'metric': 'Clip Hit@1', 'model': 'P3D', 'value': '47.9', 'row': 7, 'column': 3}, {'task': 'Action Recognition In Videos', 'dataset': 'Sports-1M', 'metric': 'Video hit@5', 'model': 'P3D', 'value': '87.4', 'row': 7, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'PSE+ ECN (rank-dist)', 'value': '84', 'row': 25, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'PSE+ ECN (rank-dist)', 'value': '90.3', 'row': 25, 'column': 4}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'PSE+ ECN (rank-dist)', 'value': '79.8', 'row': 25, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'PSE+ ECN (rank-dist)', 'value': '85.2', 'row': 25, 'column': 6}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'mAP', 'model': 'PSE+ ECN (rank-dist)', 'value': '71.8', 'row': 25, 'column': 7}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-1', 'model': 'PSE+ ECN (rank-dist)', 'value': '76.7', 'row': 25, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'Optical Flow Guided Feature', 'value': '96', 'row': 15, 'column': 1}, {'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'Optical Flow Guided Feature', 'value': '74.2', 'row': 15, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'MRR', 'model': 'Rule-Guided Embedding', 'value': '0.768', 'row': 9, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@1', 'model': 'Rule-Guided Embedding', 'value': '0.703', 'row': 9, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@3', 'model': 'Rule-Guided Embedding', 'value': '0.815', 'row': 9, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@5', 'model': 'Rule-Guided Embedding', 'value': '0.836', 'row': 9, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@10', 'model': 'Rule-Guided Embedding', 'value': '0.865', 'row': 9, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'YAGO37', 'metric': 'MRR', 'model': 'Rule-Guided Embedding', 'value': '0.431', 'row': 9, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'YAGO37', 'metric': 'Hits@1', 'model': 'Rule-Guided Embedding', 'value': '0.34', 'row': 9, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'YAGO37', 'metric': 'Hits@3', 'model': 'Rule-Guided Embedding', 'value': '0.48200000000000004', 'row': 9, 'column': 10}, {'task': 'Link Prediction', 'dataset': 'YAGO37', 'metric': 'Hits@5', 'model': 'Rule-Guided Embedding', 'value': '0.541', 'row': 9, 'column': 11}, {'task': 'Link Prediction', 'dataset': 'YAGO37', 'metric': 'Hits@10', 'model': 'Rule-Guided Embedding', 'value': '0.603', 'row': 9, 'column': 12}]}\n","{'index': 2, 'records': [{'task': 'Time Series Classification', 'dataset': 'AATLD Gesture Recognition', 'metric': 'Absolute Time (ms)', 'model': 'MUSE', 'value': '133656', 'row': 21, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Action Detection', 'dataset': 'Multi-THUMOS', 'metric': 'mAP', 'model': 'Super-events', 'value': '36.4', 'row': 8, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Action Detection', 'dataset': 'Charades', 'metric': 'mAP', 'model': 'Super-events', 'value': '19.41', 'row': 11, 'column': 1}]}\n","{'index': 1, 'records': [{'task': '3D Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '81.94', 'row': 6, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '71.88', 'row': 6, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '66.38', 'row': 6, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Easy', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '50.8', 'row': 10, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Moderate', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '42.81', 'row': 10, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Hard', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '40.88', 'row': 10, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '64.0', 'row': 14, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '52.18', 'row': 14, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'AVOD + Feature Pyramid', 'value': '46.61', 'row': 14, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '65.43', 'row': 11, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'AIDS', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '65.1', 'row': 11, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '75.1', 'row': 11, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '77.21', 'row': 11, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '68.34', 'row': 11, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Pose Estimation', 'dataset': 'UPenn Action', 'metric': 'Mean PCK@0.2', 'model': 'LSTM PM', 'value': '97.7', 'row': 8, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Pose Estimation', 'dataset': 'J-HMDB', 'metric': 'Mean PCK@0.2', 'model': 'LSTM PM', 'value': '93.6', 'row': 7, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'adaCNN (DF)', 'value': '98.42', 'row': 9, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'adaCNN (DF)', 'value': '99.37', 'row': 9, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'adaCNN (DF)', 'value': '96.12', 'row': 9, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'adaCNN (DF)', 'value': '98.43', 'row': 9, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'adaResNet (DF)', 'value': '56.88', 'row': 10, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'adaResNet (DF)', 'value': '71.94', 'row': 10, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Gesture Recognition', 'dataset': 'Chalearn 2014', 'metric': 'Accuracy', 'model': '3D-CNN + LSTM', 'value': '93.2', 'row': 3, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'PixelLink+VGG16 2s', 'value': '82', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'PixelLink+VGG16 2s', 'value': '85.5', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'PixelLink+VGG16 2s', 'value': '83.7', 'row': 1, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'PixelLink + VGG16 2s', 'value': '73.2', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'PixelLink + VGG16 2s', 'value': '83', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'PixelLink + VGG16 2s', 'value': '77.8', 'row': 1, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'PixelLink+VGG16 2s MS', 'value': '87.5', 'row': 3, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'PixelLink+VGG16 2s MS', 'value': '88.6', 'row': 3, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'PixelLink+VGG16 2s MS', 'value': '88.1', 'row': 3, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'FOTS', 'value': '91', 'row': 11, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'FOTS', 'value': '85.17', 'row': 11, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'FOTS', 'value': '87.99', 'row': 11, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'FOTS MS', 'value': '91.85', 'row': 13, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'FOTS MS', 'value': '87.92', 'row': 13, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'FOTS MS', 'value': '89.84', 'row': 13, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'FOTS', 'value': '80.95', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'FOTS', 'value': '57.51', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'FOTS', 'value': '67.25', 'row': 7, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'FOTS MS', 'value': '81.86', 'row': 8, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'FOTS MS', 'value': '62.3', 'row': 8, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'FOTS MS', 'value': '70.75', 'row': 8, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'Quad_MS', 'value': '78.5', 'row': 5, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'Quad_MS', 'value': '87.8', 'row': 5, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'Quad_MS', 'value': '82.9', 'row': 5, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Recall', 'model': 'TextBoxes++_MS', 'value': '56.7', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Precision', 'model': 'TextBoxes++_MS', 'value': '60.87', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'F-Measure', 'model': 'TextBoxes++_MS', 'value': '58.72', 'row': 7, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'TextBoxes++_MS', 'value': '84', 'row': 19, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'TextBoxes++_MS', 'value': '91', 'row': 19, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'TextBoxes++_MS', 'value': '88%', 'row': 19, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'DDRL A3C', 'value': '14900', 'row': 1, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'DDRL A3C', 'value': '350', 'row': 2, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'DDRL A3C', 'value': '98', 'row': 3, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'DDRL A3C', 'value': '20', 'row': 4, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'DDRL A3C', 'value': '1832', 'row': 5, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'DDRL A3C', 'value': '650', 'row': 6, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Time Series Classification', 'dataset': 'ArabicDigits', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.99', 'row': 1, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'AUSLAN', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.96', 'row': 2, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'CharacterTrajectories', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '1', 'row': 3, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'CMUsubject16', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '1', 'row': 4, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'DigitShapes', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '1', 'row': 5, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'ECG', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.86', 'row': 6, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'JapaneseVowels', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.99', 'row': 7, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'KickvsPunch', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '1', 'row': 8, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'Libras', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.97', 'row': 9, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'LP1', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.82', 'row': 10, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'LP2', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.77', 'row': 11, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'LP3', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.73', 'row': 12, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'LP4', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.93', 'row': 13, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'LP5', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.67', 'row': 14, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'NetFlow', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.95', 'row': 15, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'PenDigits', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.97', 'row': 16, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'Shapes', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '1', 'row': 17, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'UWave', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.98', 'row': 18, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'Wafer', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '0.99', 'row': 19, 'column': 4}, {'task': 'Time Series Classification', 'dataset': 'WalkvsRun', 'metric': 'Accuracy', 'model': 'MALSTM-FCN', 'value': '1', 'row': 20, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'MT-net', 'value': '99.5', 'row': 7, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'MT-net', 'value': '96.2', 'row': 7, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MT-Net', 'value': '51.7', 'row': 11, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'ULMFiT', 'value': '95.4', 'row': 4, 'column': 2}, {'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'ULMFiT', 'value': '3.6', 'row': 4, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Text Classification', 'dataset': 'AG News', 'metric': 'Error', 'model': 'ULMFiT', 'value': '5.01', 'row': 4, 'column': 1}, {'task': 'Text Classification', 'dataset': 'DBpedia', 'metric': 'Error', 'model': 'ULMFiT', 'value': '0.8', 'row': 4, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'Yelp Binary classification', 'metric': 'Error', 'model': 'ULMFiT', 'value': '2.16', 'row': 4, 'column': 3}, {'task': 'Sentiment Analysis', 'dataset': 'Yelp Fine-grained classification', 'metric': 'Error', 'model': 'ULMFiT', 'value': '29.98', 'row': 4, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Pose Estimation', 'dataset': 'MPII Human Pose', 'metric': 'PCKh-0.5', 'model': 'DSNTr ResNet-50@28px', 'value': '89.5', 'row': 7, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'Bing News', 'metric': 'AUC', 'model': 'DKN', 'value': '0.659', 'row': 1, 'column': 2}]}\n","{'index': 1, 'records': [{'task': '3D Facial Landmark Localization', 'dataset': '3DFAW', 'metric': 'CVGTCE', 'model': 'JVCR', 'value': '3.46', 'row': 6, 'column': 1}, {'task': '3D Facial Landmark Localization', 'dataset': '3DFAW', 'metric': 'GTE', 'model': 'JVCR', 'value': '4.35', 'row': 6, 'column': 2}]}\n","{'index': 2, 'records': [{'task': '3D Facial Landmark Localization', 'dataset': 'AFLW2000-3D', 'metric': 'GTE', 'model': 'JVCR', 'value': '7.28', 'row': 2, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'SLPR', 'value': '85.5', 'row': 9, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'SLPR', 'value': '83.6', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'H-Mean', 'model': 'SLPR', 'value': '84.5', 'row': 9, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'SLPR', 'value': '80.1', 'row': 3, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'SLPR', 'value': '70.1', 'row': 3, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'H-Mean', 'model': 'SLPR', 'value': '74.8', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Molecular Graph Generation', 'dataset': 'ZINC', 'metric': 'Reconstruction', 'model': 'JT-VAE', 'value': '76.7%', 'row': 6, 'column': 1}, {'task': 'Molecular Graph Generation', 'dataset': 'ZINC', 'metric': 'Validty', 'model': 'JT-VAE', 'value': '100%', 'row': 6, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AUC', 'model': 'ARGE', 'value': '92.4', 'row': 8, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AP', 'model': 'ARGE', 'value': '93.2', 'row': 8, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AUC', 'model': 'ARGE', 'value': '91.9', 'row': 8, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AP', 'model': 'ARGE', 'value': '93', 'row': 8, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AUC', 'model': 'ARGE', 'value': '96.8', 'row': 8, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AP', 'model': 'ARGE', 'value': '97.1', 'row': 8, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Graph Clustering', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'ARGE', 'value': '64', 'row': 11, 'column': 1}, {'task': 'Graph Clustering', 'dataset': 'Cora', 'metric': 'NMI', 'model': 'ARGE', 'value': '0.449', 'row': 11, 'column': 2}, {'task': 'Graph Clustering', 'dataset': 'Cora', 'metric': 'F1', 'model': 'ARGE', 'value': '61.9', 'row': 11, 'column': 3}, {'task': 'Graph Clustering', 'dataset': 'Cora', 'metric': 'Precision', 'model': 'ARGE', 'value': '64.6', 'row': 11, 'column': 4}, {'task': 'Graph Clustering', 'dataset': 'Cora', 'metric': 'ARI', 'model': 'ARGE', 'value': '35.2', 'row': 11, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Graph Clustering', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'ARGE', 'value': '57.3', 'row': 11, 'column': 1}, {'task': 'Graph Clustering', 'dataset': 'Citeseer', 'metric': 'NMI', 'model': 'ARGE', 'value': '0.35', 'row': 11, 'column': 2}, {'task': 'Graph Clustering', 'dataset': 'Citeseer', 'metric': 'F1', 'model': 'ARGE', 'value': '54.6', 'row': 11, 'column': 3}, {'task': 'Graph Clustering', 'dataset': 'Citeseer', 'metric': 'Precision', 'model': 'ARGE', 'value': '57.3', 'row': 11, 'column': 4}, {'task': 'Graph Clustering', 'dataset': 'Citeseer', 'metric': 'ARI', 'model': 'ARGE', 'value': '34.1', 'row': 11, 'column': 5}]}\n","{'index': 7, 'records': [{'task': 'Natural Language Inference', 'dataset': 'SNLI', 'metric': '% Test Accuracy', 'model': '450D DR-BiLSTM Ensemble', 'value': '89.3', 'row': 8, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'DMN', 'value': '68.09', 'row': 7, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'DMN', 'value': '68.41', 'row': 7, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'RDN', 'value': '32.47', 'row': 4, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'RDN', 'value': '28.81', 'row': 7, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'RDN', 'value': '26.61', 'row': 13, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'RDN', 'value': '31.0', 'row': 16, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'Corner Localization (multi-scale)', 'value': '89.5', 'row': 12, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'Corner Localization (multi-scale)', 'value': '79.7', 'row': 12, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'Corner Localization (multi-scale)', 'value': '84.3', 'row': 12, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'Corner Localization (multi-scale)', 'value': '92', 'row': 16, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'Corner Localization (multi-scale)', 'value': '84.4', 'row': 16, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'Corner Localization (multi-scale)', 'value': '88', 'row': 16, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'Corner Localization', 'value': '87.6', 'row': 10, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'Corner Localization', 'value': '76.2', 'row': 10, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'Corner Localization', 'value': '81.5', 'row': 10, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'Corner Localization (single-scale)', 'value': '83.8', 'row': 6, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'Corner Localization (single-scale)', 'value': '55.6', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'Corner Localization (single-scale)', 'value': '66.8', 'row': 6, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'Corner Localization (multi-scale)', 'value': '74.3', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'Corner Localization (multi-scale)', 'value': '70.6', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'Corner Localization (multi-scale)', 'value': '72.4', 'row': 7, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Multiple Object Tracking', 'dataset': 'KITTI Tracking test', 'metric': 'MOTA', 'model': 'RRC-IIITH', 'value': '84.24', 'row': 7, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari-57', 'metric': 'Medium Human-Normalized Score', 'model': 'Ape-X (DQN)', 'value': '434.1', 'row': 2, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'Ape-X', 'value': '40804.9', 'row': 1, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'Ape-X', 'value': '8659.2', 'row': 2, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'Ape-X', 'value': '24559.4', 'row': 3, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'Ape-X', 'value': '313305', 'row': 4, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'Ape-X', 'value': '155495.1', 'row': 5, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'Ape-X', 'value': '944497.5', 'row': 6, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'Ape-X', 'value': '1716.4', 'row': 7, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'Ape-X', 'value': '98895', 'row': 8, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'Ape-X', 'value': '63305.2', 'row': 9, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'Ape-X', 'value': '57196.7', 'row': 10, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'Ape-X', 'value': '17.6', 'row': 11, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'Ape-X', 'value': '100', 'row': 12, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'Ape-X', 'value': '800.9', 'row': 13, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'Ape-X', 'value': '12974', 'row': 14, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'Ape-X', 'value': '721851', 'row': 15, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'Ape-X', 'value': '320426', 'row': 16, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'Ape-X', 'value': '411943.5', 'row': 17, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'Ape-X', 'value': '133086.4', 'row': 18, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'Ape-X', 'value': '23.5', 'row': 19, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'Ape-X', 'value': '2177.4', 'row': 20, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'Ape-X', 'value': '44.4', 'row': 21, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Ape-X', 'value': '33.7', 'row': 22, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'Ape-X', 'value': '9328.6', 'row': 23, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'Ape-X', 'value': '120500.9', 'row': 24, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Ape-X', 'value': '1598.5', 'row': 25, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'Ape-X', 'value': '31655.9', 'row': 26, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'Ape-X', 'value': '33', 'row': 27, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'Ape-X', 'value': '21322.5', 'row': 28, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'Ape-X', 'value': '1416', 'row': 29, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'Ape-X', 'value': '11741.4', 'row': 30, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'Ape-X', 'value': '97829.5', 'row': 31, 'column': 1}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Ape-X', 'value': '2500', 'row': 32, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'Ape-X', 'value': '11255.2', 'row': 33, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'Ape-X', 'value': '25783.3', 'row': 34, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'Ape-X', 'value': '224491.1', 'row': 35, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'Ape-X', 'value': '-0.6', 'row': 36, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'Ape-X', 'value': '20.9', 'row': 37, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Ape-X', 'value': '49.8', 'row': 38, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'Ape-X', 'value': '302391.3', 'row': 39, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'Ape-X', 'value': '63864.4', 'row': 40, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'Ape-X', 'value': '222234.5', 'row': 41, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'Ape-X', 'value': '73.8', 'row': 42, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'Ape-X', 'value': '392952.3', 'row': 43, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'Ape-X', 'value': '-10789.9', 'row': 44, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'Ape-X', 'value': '2892.9', 'row': 45, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'Ape-X', 'value': '54681', 'row': 46, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'Ape-X', 'value': '434342.5', 'row': 47, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Surround', 'metric': 'Score', 'model': 'Ape-X', 'value': '7.1', 'row': 48, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'Ape-X', 'value': '23.9', 'row': 49, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'Ape-X', 'value': '87085', 'row': 50, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'Ape-X', 'value': '272.6', 'row': 51, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'Ape-X', 'value': '401884.3', 'row': 52, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'Ape-X', 'value': '1813', 'row': 53, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'Ape-X', 'value': '565163.2', 'row': 54, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'Ape-X', 'value': '46204', 'row': 55, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Yars Revenge', 'metric': 'Score', 'model': 'Ape-X', 'value': '148594.8', 'row': 56, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'Ape-X', 'value': '42285.5', 'row': 57, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'D-DBPN', 'value': '32.47', 'row': 21, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'D-DBPN', 'value': '0.898', 'row': 21, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'D-DBPN', 'value': '28.82', 'row': 21, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'D-DBPN', 'value': '27.72', 'row': 21, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'D-DBPN', 'value': '0.74', 'row': 21, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'D-DBPN', 'value': '0.795', 'row': 21, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'D-DBPN', 'value': '0.914', 'row': 21, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Reptile + Transduction', 'value': '49.97', 'row': 4, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Reptile + Transduction', 'value': '65.99', 'row': 4, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Reptile + Transduction', 'value': '97.68', 'row': 4, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Reptile + Transduction', 'value': '99.48', 'row': 4, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Reptile + Transduction', 'value': '89.43', 'row': 4, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Reptile + Transduction', 'value': '97.12', 'row': 4, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'AUC', 'model': 'RippleNet', 'value': '0.921', 'row': 2, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'Accuracy', 'model': 'RippleNet', 'value': '84.4', 'row': 2, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Book-Crossing', 'metric': 'AUC', 'model': 'RippleNet', 'value': '0.729', 'row': 2, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Book-Crossing', 'metric': 'Accuracy', 'model': 'RippleNet', 'value': '66.2', 'row': 2, 'column': 4}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Bing News', 'metric': 'AUC', 'model': 'RippleNet', 'value': '0.678', 'row': 2, 'column': 5}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Bing News', 'metric': 'Accuracy', 'model': 'RippleNet', 'value': '63.2', 'row': 2, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Action Detection', 'dataset': 'Multi-THUMOS', 'metric': 'mAP', 'model': 'TGM', 'value': '46.4', 'row': 10, 'column': 1}]}\n","{'index': 5, 'records': [{'task': 'Action Detection', 'dataset': 'Charades', 'metric': 'mAP', 'model': 'TGM', 'value': '22.3', 'row': 15, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'AKSW-bib', 'metric': 'Hits@1', 'model': 'KG2Vec LSTM', 'value': '0.0384', 'row': 1, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'AKSW-bib', 'metric': 'Hits@3', 'model': 'KG2Vec LSTM', 'value': '0.0979', 'row': 1, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'AKSW-bib', 'metric': 'Hits@10', 'model': 'KG2Vec LSTM', 'value': '0.1923', 'row': 1, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'Clipart1k', 'metric': 'MAP', 'model': 'DT+PL', 'value': '46.0', 'row': 13, 'column': 21}]}\n","{'index': 3, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'Watercolor2k', 'metric': 'MAP', 'model': 'DT+PL', 'value': '54.3', 'row': 11, 'column': 7}]}\n","{'index': 4, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'Comic2k', 'metric': 'MAP', 'model': 'DT+PL', 'value': '37.2', 'row': 11, 'column': 7}]}\n","{'index': 3, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'PoseCNN + DeepIM', 'value': '88.6', 'row': 2, 'column': 6}]}\n","{'index': 5, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'Occlusion LineMOD', 'metric': 'Mean ADD', 'model': 'PoseCNN + DeepIM', 'value': '55.5', 'row': 10, 'column': 4}]}\n","{'index': 7, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'YCB-Video', 'metric': 'Mean ADD', 'model': 'PoseCNN + DeepIM', 'value': '70.1', 'row': 24, 'column': 3}, {'task': '6D Pose Estimation using RGB', 'dataset': 'YCB-Video', 'metric': 'Mean ADI', 'model': 'PoseCNN + DeepIM', 'value': '84.2', 'row': 24, 'column': 4}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'YCB-Video', 'metric': 'Mean ADD', 'model': 'PoseCNN + DeepIM', 'value': '80.6', 'row': 24, 'column': 7}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'YCB-Video', 'metric': 'Mean ADI', 'model': 'PoseCNN + DeepIM', 'value': '92.4', 'row': 24, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Action Classification', 'dataset': 'HMDB51', 'metric': 'Accuracy', 'model': 'TVNet + IDT', 'value': '72.6', 'row': 12, 'column': 1}, {'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': 'Accuracy', 'model': 'TVNet + IDT', 'value': '95.4', 'row': 12, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'mIoU', 'model': 'PRM', 'value': '53.4', 'row': 6, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Face Alignment', 'dataset': 'AFLW', 'metric': 'Mean NME', 'model': '3DDFA', 'value': '4.55', 'row': 18, 'column': 4}, {'task': 'Face Alignment', 'dataset': 'AFLW2000-3D', 'metric': 'Mean NME ', 'model': '3DDFA', 'value': '3.79', 'row': 18, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Face Alignment', 'dataset': '300W', 'metric': 'Fullset (public)', 'model': '3DDFA', 'value': '5.63', 'row': 9, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'Corner-based Region Proposals', 'value': '83.9', 'row': 11, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'Corner-based Region Proposals', 'value': '91.9', 'row': 11, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'Corner-based Region Proposals', 'value': '87.6%', 'row': 11, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'Corner-based Region Proposals', 'value': '80.7', 'row': 12, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'Corner-based Region Proposals', 'value': '88.7', 'row': 12, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'Corner-based Region Proposals', 'value': '84.5', 'row': 12, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Recall', 'model': 'Corner-based Region Proposals', 'value': '63.3', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'Precision', 'model': 'Corner-based Region Proposals', 'value': '55.5', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'COCO-Text', 'metric': 'F-Measure', 'model': 'Corner-based Region Proposals', 'value': '59.1', 'row': 7, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Age Estimation', 'dataset': 'MORPH', 'metric': 'MAE', 'model': 'CMAAE-OR', 'value': '1.48', 'row': 2, 'column': 2}, {'task': 'Age Estimation', 'dataset': 'FGNET', 'metric': 'MAE', 'model': 'CMAAE-OR', 'value': '3.62', 'row': 3, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'VGG + GANFaces', 'value': '94.9', 'row': 6, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.01', 'model': 'VGG + GANFaces', 'value': '0.53507', 'row': 5, 'column': 1}, {'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.001', 'model': 'VGG + GANFaces', 'value': '0.18768', 'row': 5, 'column': 2}]}\n","{'index': 2, 'records': [{'task': '3D Shape Reconstruction', 'dataset': 'Pix3D', 'metric': 'TIoU', 'model': 'MarrNet extension (w/ Pose)', 'value': '0.282', 'row': 8, 'column': 1}, {'task': '3D Shape Reconstruction', 'dataset': 'Pix3D', 'metric': 'EMD', 'model': 'MarrNet extension (w/ Pose)', 'value': '0.118', 'row': 8, 'column': 2}, {'task': '3D Shape Reconstruction', 'dataset': 'Pix3D', 'metric': 'CD', 'model': 'MarrNet extension (w/ Pose)', 'value': '0.119', 'row': 8, 'column': 3}]}\n","{'index': 3, 'records': [{'task': '3D Shape Retrieval', 'dataset': 'Pix3D', 'metric': 'R@1', 'model': 'MarrNet extension (w/o Pose)', 'value': '0.53', 'row': 4, 'column': 1}, {'task': '3D Shape Retrieval', 'dataset': 'Pix3D', 'metric': 'R@2', 'model': 'MarrNet extension (w/o Pose)', 'value': '0.62', 'row': 4, 'column': 2}, {'task': '3D Shape Retrieval', 'dataset': 'Pix3D', 'metric': 'R@4', 'model': 'MarrNet extension (w/o Pose)', 'value': '0.71', 'row': 4, 'column': 3}, {'task': '3D Shape Retrieval', 'dataset': 'Pix3D', 'metric': 'R@8', 'model': 'MarrNet extension (w/o Pose)', 'value': '0.78', 'row': 4, 'column': 4}, {'task': '3D Shape Retrieval', 'dataset': 'Pix3D', 'metric': 'R@16', 'model': 'MarrNet extension (w/o Pose)', 'value': '0.85', 'row': 4, 'column': 5}, {'task': '3D Shape Retrieval', 'dataset': 'Pix3D', 'metric': 'R@32', 'model': 'MarrNet extension (w/o Pose)', 'value': '0.90', 'row': 4, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'Flow-based (ResNet-152)', 'value': '73.7', 'row': 10, 'column': 3}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Flow-based (ResNet-152)', 'value': '91.9', 'row': 10, 'column': 4}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'Flow-based (ResNet-152)', 'value': '81.1', 'row': 10, 'column': 5}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Flow-based (ResNet-152)', 'value': '70.3', 'row': 10, 'column': 6}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Flow-based (ResNet-152)', 'value': '80', 'row': 10, 'column': 7}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'Flow-based (ResNet-152)', 'value': '79', 'row': 10, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'Jester val', 'metric': 'Top 1 Accuracy', 'model': '8-MFFs-3f1c (5 crop)', 'value': '96.33', 'row': 20, 'column': 1}, {'task': 'Hand Gesture Recognition', 'dataset': 'Jester val', 'metric': 'Top 5 Accuracy', 'model': '8-MFFs-3f1c (5 crop)', 'value': '99.86', 'row': 20, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'Jester test', 'metric': 'Top 1 Accuracy', 'model': 'DRX3D', 'value': '96.6', 'row': 9, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'ChaLean test', 'metric': 'Accuracy', 'model': '8-MFFs-3f1c', 'value': '56.7', 'row': 4, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'ChaLearn val', 'metric': 'Accuracy', 'model': '8-MFFs-3f1c (5 crop)', 'value': '57.4', 'row': 12, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'NVGesture', 'metric': 'Accuracy', 'model': '8-MFFs-3f1c', 'value': '84.7', 'row': 14, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Cosine similarity function + C64F feature extractor', 'value': '72.81', 'row': 8, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Cosine similarity function + C64F feature extractor', 'value': '56.20', 'row': 8, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Document Classification', 'dataset': 'WOS-5736', 'metric': 'Accuracy', 'model': 'RMDL (30 RDLs)', 'value': '93.57', 'row': 13, 'column': 2}, {'task': 'Document Classification', 'dataset': 'WOS-11967', 'metric': 'Accuracy', 'model': 'RMDL (30 RDLs)', 'value': '91.59', 'row': 13, 'column': 3}, {'task': 'Document Classification', 'dataset': 'WOS-46985', 'metric': 'Accuracy', 'model': 'RMDL (30 RDLs)', 'value': '82.42', 'row': 13, 'column': 4}, {'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'Accuracy', 'model': 'RMDL (30 RDLs)', 'value': '90.69', 'row': 13, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'MNIST', 'metric': 'Percentage error', 'model': 'RMDL (30 RDLs)', 'value': '0.18', 'row': 9, 'column': 2}, {'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'RMDL (30 RDLs)', 'value': '91.21', 'row': 9, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'RMDL (15 RDLs)', 'value': '90.79', 'row': 10, 'column': 2}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'RMDL (15 RDLs)', 'value': '87.91', 'row': 10, 'column': 3}]}\n","{'index': 0, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Ordinal Depth Supervision', 'value': '115.08', 'row': 3, 'column': 3}]}\n","{'index': 3, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Ours', 'value': '44.7', 'row': 13, 'column': 14}]}\n","{'index': 0, 'records': [{'task': 'Recipe Generation', 'dataset': \"Now You're Cooking!\", 'metric': 'Perplexity', 'model': 'Entity Type Model', 'value': '9.67', 'row': 7, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Code Generation', 'dataset': 'Android Repos', 'metric': 'Perplexity', 'model': 'Entity Type Model', 'value': '2.65', 'row': 10, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'MR', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '86.8', 'row': 13, 'column': 3}, {'task': 'Sentiment Analysis', 'dataset': 'CR', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '90.6', 'row': 13, 'column': 4}, {'task': 'Subjectivity Analysis', 'dataset': 'SUBJ', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '94.7', 'row': 13, 'column': 5}, {'task': 'Sentiment Analysis', 'dataset': 'MPQA', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '88.8', 'row': 13, 'column': 6}, {'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'byte mLSTM7', 'value': '9.6', 'row': 13, 'column': 7}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '91.7', 'row': 13, 'column': 8}, {'task': 'Sentiment Analysis', 'dataset': 'SST-5 Fine-grained classification', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '54.6', 'row': 13, 'column': 9}, {'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'byte mLSTM7', 'value': '92.2', 'row': 13, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma15', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '33.15', 'row': 1, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma25', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '30.79', 'row': 2, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma50', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '27.74', 'row': 3, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '31.86', 'row': 4, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '29.41', 'row': 5, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '26.53', 'row': 6, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma15', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '33.17', 'row': 7, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma25', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '30.66', 'row': 8, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma50', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '27.42', 'row': 9, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '37.91', 'row': 1, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '34.17', 'row': 2, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '32.12', 'row': 3, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '33.7', 'row': 4, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '30.16', 'row': 5, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '28.41', 'row': 6, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '32.23', 'row': 7, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '29.12', 'row': 8, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '27.62', 'row': 9, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '32.3', 'row': 10, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '28.13', 'row': 11, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '26.27', 'row': 12, 'column': 11}]}\n","{'index': 2, 'records': [{'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 10', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '30.01', 'row': 1, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 20', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '32.16', 'row': 2, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 30', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '33.43', 'row': 3, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 40', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '34.27', 'row': 4, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 10', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '29.69', 'row': 5, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 20', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '32.04', 'row': 6, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 30', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '33.45', 'row': 7, 'column': 7}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 40', 'metric': 'PSNR', 'model': 'MWCNN', 'value': '34.45', 'row': 8, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V2', 'metric': 'Top-1 Accuracy', 'model': 'DIN', 'value': '34.11', 'row': 7, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'Jester', 'metric': 'Val', 'model': 'DIN', 'value': '95.31', 'row': 8, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'BAN+Glove+Counter', 'value': '70.04', 'row': 7, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'BAN+Glove+Counter', 'value': '70.35', 'row': 7, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'R@1', 'model': 'BAN (Bottom-Up detector)', 'value': '69.69', 'row': 11, 'column': 2}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'R@5', 'model': 'BAN (Bottom-Up detector)', 'value': '84.22', 'row': 11, 'column': 3}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'R@10', 'model': 'BAN (Bottom-Up detector)', 'value': '86.35', 'row': 11, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-German', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '81.2', 'row': 4, 'column': 2}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Spanish', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '72.5', 'row': 4, 'column': 4}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '72.38', 'row': 4, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Italian', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '69.38', 'row': 4, 'column': 6}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Russian', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '60.8', 'row': 4, 'column': 7}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Chinese', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '74.73', 'row': 4, 'column': 8}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Japanese', 'metric': 'Accuracy', 'model': 'MultiCCA + CNN', 'value': '67.63', 'row': 4, 'column': 9}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot German-to-French', 'metric': 'Accuracy', 'model': 'BiLSTM (Europarl)', 'value': '75.45', 'row': 12, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-German', 'metric': 'Accuracy', 'model': 'BiLSTM (Europarl)', 'value': '71.83', 'row': 13, 'column': 2}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Spanish', 'metric': 'Accuracy', 'model': 'BiLSTM (Europarl)', 'value': '66.65', 'row': 13, 'column': 4}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Accuracy', 'model': 'BiLSTM (Europarl)', 'value': '72.83', 'row': 13, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Italian', 'metric': 'Accuracy', 'model': 'BiLSTM (Europarl)', 'value': '60.73', 'row': 13, 'column': 6}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Spanish', 'metric': 'Accuracy', 'model': 'BiLSTM (UN)', 'value': '69.5', 'row': 18, 'column': 4}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Accuracy', 'model': 'BiLSTM (UN)', 'value': '74.52', 'row': 18, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Russian', 'metric': 'Accuracy', 'model': 'BiLSTM (UN)', 'value': '61.42', 'row': 18, 'column': 7}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Chinese', 'metric': 'Accuracy', 'model': 'BiLSTM (UN)', 'value': '71.97', 'row': 18, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Text Classification', 'dataset': 'Yahoo! Answers', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '73.53', 'row': 10, 'column': 1}, {'task': 'Text Classification', 'dataset': 'AG News', 'metric': 'Error', 'model': 'SWEM-concat', 'value': '7.34', 'row': 10, 'column': 2}, {'task': 'Text Classification', 'dataset': 'DBpedia', 'metric': 'Error', 'model': 'SWEM-concat', 'value': '1.43', 'row': 10, 'column': 5}, {'task': 'Sentiment Analysis', 'dataset': 'Yelp Binary classification', 'metric': 'Error', 'model': 'SWEM-hier', 'value': '4.19', 'row': 11, 'column': 3}, {'task': 'Sentiment Analysis', 'dataset': 'Yelp Fine-grained classification', 'metric': 'Error', 'model': 'SWEM-hier', 'value': '36.21', 'row': 11, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Natural Language Inference', 'dataset': 'SNLI', 'metric': '% Test Accuracy', 'model': 'SWEM-max', 'value': '83.8', 'row': 6, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'SWEM-max', 'value': '68.2', 'row': 6, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Mismatched', 'model': 'SWEM-max', 'value': '67.7', 'row': 6, 'column': 3}, {'task': 'Question Answering', 'dataset': 'WikiQA', 'metric': 'MAP', 'model': 'SWEM-concat', 'value': '0.6788', 'row': 7, 'column': 4}, {'task': 'Question Answering', 'dataset': 'WikiQA', 'metric': 'MRR', 'model': 'SWEM-concat', 'value': '0.6908', 'row': 7, 'column': 5}, {'task': 'Question Answering', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '83.03', 'row': 7, 'column': 6}, {'task': 'Paraphrase Identification', 'dataset': 'MSRP', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '71.5', 'row': 7, 'column': 7}, {'task': 'Paraphrase Identification', 'dataset': 'MSRP', 'metric': 'F1', 'model': 'SWEM-concat', 'value': '81.3', 'row': 7, 'column': 8}]}\n","{'index': 7, 'records': [{'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'SWEM-aver', 'value': '7.8', 'row': 9, 'column': 5}, {'task': 'Sentiment Analysis', 'dataset': 'MR', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '78.2', 'row': 11, 'column': 1}, {'task': 'Sentiment Analysis', 'dataset': 'SST-5 Fine-grained classification', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '46.1', 'row': 11, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '84.3', 'row': 11, 'column': 3}, {'task': 'Subjectivity Analysis', 'dataset': 'SUBJ', 'metric': 'Accuracy', 'model': 'SWEM-concat', 'value': '93', 'row': 11, 'column': 4}]}\n","{'index': 9, 'records': [{'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2000', 'metric': 'F1', 'model': 'SWEM-CRF', 'value': '90.34', 'row': 3, 'column': 1}, {'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2003 (English)', 'metric': 'F1', 'model': 'SWEM-CRF', 'value': '86.28', 'row': 3, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'TADAM', 'value': '58.5', 'row': 9, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'TADAM', 'value': '76.7', 'row': 9, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (10-shot)', 'metric': 'Accuracy', 'model': 'TADAM', 'value': '80.8', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '325', 'row': 1, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '-10', 'row': 2, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '300', 'row': 3, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '1200', 'row': 4, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '920', 'row': 5, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '4600', 'row': 6, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '1250', 'row': 7, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '320', 'row': 8, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '830', 'row': 9, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'IDVQ + DRSC + XNES', 'value': '4600', 'row': 10, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'PSENet-1s', 'value': '88.71', 'row': 20, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'PSENet-1s', 'value': '85.51', 'row': 20, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'PSENet-1s', 'value': '87.08', 'row': 20, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'PSENet-1s', 'value': '77.01', 'row': 20, 'column': 5}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'PSENet-1s', 'value': '68.4', 'row': 20, 'column': 6}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'PSENet-1s', 'value': '72.45', 'row': 20, 'column': 7}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'PSENet-1s', 'value': '82.5', 'row': 20, 'column': 8}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'PSENet-1s', 'value': '79.89', 'row': 20, 'column': 9}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'F-Measure', 'model': 'PSENet-1s', 'value': '81.17', 'row': 20, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR', 'model': 'NLRN', 'value': '30.8', 'row': 6, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma15', 'metric': 'PSNR', 'model': 'NLRN', 'value': '33.16', 'row': 1, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma30', 'metric': 'PSNR', 'model': 'NLRN', 'value': '30.8', 'row': 2, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma50', 'metric': 'PSNR', 'model': 'NLRN', 'value': '27.64', 'row': 3, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'NLRN', 'value': '31.88', 'row': 4, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'NLRN', 'value': '29.41', 'row': 5, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'NLRN', 'value': '26.47', 'row': 6, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma15', 'metric': 'PSNR', 'model': 'NLRN', 'value': '33.45', 'row': 7, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma25', 'metric': 'PSNR', 'model': 'NLRN', 'value': '30.94', 'row': 8, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma50', 'metric': 'PSNR', 'model': 'NLRN', 'value': '27.49', 'row': 9, 'column': 7}]}\n","{'index': 4, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma30', 'metric': 'PSNR', 'model': 'NLRN-MV', 'value': '28.2', 'row': 4, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma50', 'metric': 'PSNR', 'model': 'NLRN-MV', 'value': '25.97', 'row': 5, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma70', 'metric': 'PSNR', 'model': 'NLRN-MV', 'value': '24.62', 'row': 6, 'column': 7}]}\n","{'index': 5, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'NLRN', 'value': '31.92', 'row': 3, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'NLRN', 'value': '28.36', 'row': 6, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'NLRN', 'value': '25.79', 'row': 12, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Entity Typing', 'dataset': 'Freebase FIGER', 'metric': 'P@1', 'model': 'TextEnt-full', 'value': '93.2', 'row': 1, 'column': 1}, {'task': 'Entity Typing', 'dataset': 'Freebase FIGER', 'metric': 'BEP', 'model': 'TextEnt-full', 'value': '94.8', 'row': 1, 'column': 2}, {'task': 'Entity Typing', 'dataset': 'Freebase FIGER', 'metric': 'Accuracy', 'model': 'TextEnt-full', 'value': '37.4', 'row': 1, 'column': 3}, {'task': 'Entity Typing', 'dataset': 'Freebase FIGER', 'metric': 'Micro F1', 'model': 'TextEnt-full', 'value': '85.7', 'row': 1, 'column': 4}, {'task': 'Entity Typing', 'dataset': 'Freebase FIGER', 'metric': 'Macro F1', 'model': 'TextEnt-full', 'value': '84.2', 'row': 1, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'TextEnt-full', 'value': '84.5', 'row': 2, 'column': 1}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'F1', 'model': 'TextEnt-full', 'value': '83.9', 'row': 2, 'column': 2}, {'task': 'Text Classification', 'dataset': 'R8', 'metric': 'Accuracy', 'model': 'TextEnt-full', 'value': '96.7', 'row': 2, 'column': 3}, {'task': 'Text Classification', 'dataset': 'R8', 'metric': 'F1', 'model': 'TextEnt-full', 'value': '91', 'row': 2, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Proposal Generation', 'dataset': 'ActivityNet-1.3', 'metric': 'AR@100', 'model': 'BSN', 'value': '74.16', 'row': 1, 'column': 5}, {'task': 'Temporal Action Proposal Generation', 'dataset': 'ActivityNet-1.3', 'metric': 'AUC (val)', 'model': 'BSN', 'value': '66.17', 'row': 2, 'column': 5}, {'task': 'Temporal Action Proposal Generation', 'dataset': 'ActivityNet-1.3', 'metric': 'AUC (test)', 'model': 'BSN', 'value': '66.26', 'row': 3, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Proposal Generation', 'dataset': \"THUMOS' 14\", 'metric': 'AR@50', 'model': 'BSN + Soft-NMS', 'value': '37.46', 'row': 10, 'column': 2}, {'task': 'Temporal Action Proposal Generation', 'dataset': \"THUMOS' 14\", 'metric': 'AR@100', 'model': 'BSN + Soft-NMS', 'value': '46.06', 'row': 10, 'column': 3}, {'task': 'Temporal Action Proposal Generation', 'dataset': \"THUMOS' 14\", 'metric': 'AR@200', 'model': 'BSN + Soft-NMS', 'value': '53.21', 'row': 10, 'column': 4}, {'task': 'Temporal Action Proposal Generation', 'dataset': \"THUMOS' 14\", 'metric': 'AR@500', 'model': 'BSN + Soft-NMS', 'value': '60.64', 'row': 10, 'column': 5}, {'task': 'Temporal Action Proposal Generation', 'dataset': \"THUMOS' 14\", 'metric': 'AR@1000', 'model': 'BSN + Soft-NMS', 'value': '64.52', 'row': 10, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'BSN', 'value': '46.45', 'row': 8, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'BSN', 'value': '46.45', 'row': 8, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.75', 'model': 'BSN', 'value': '29.96', 'row': 8, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.95', 'model': 'BSN', 'value': '8.02', 'row': 8, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP', 'model': 'BSN', 'value': '30.03', 'row': 8, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'BSN', 'value': '29.4', 'row': 17, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': 'BSN UNet', 'value': '20', 'row': 18, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.6', 'model': 'BSN UNet', 'value': '28.4', 'row': 18, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'BSN UNet', 'value': '36.9', 'row': 18, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'BSN UNet', 'value': '45', 'row': 18, 'column': 5}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'BSN UNet', 'value': '53.5', 'row': 18, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Delta-encoder', 'value': '59.9', 'row': 11, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR100 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Delta-encoder', 'value': '66.7', 'row': 11, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Caltech-256 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Delta-encoder', 'value': '73.2', 'row': 11, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'Delta-encoder', 'value': '69.8', 'row': 11, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '2242.2', 'row': 1, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '1362', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '1812', 'row': 3, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '17984.2', 'row': 4, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '2259.4', 'row': 5, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '3084781.7', 'row': 6, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '1137.8', 'row': 7, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '25075', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '2366.2', 'row': 9, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '31.1', 'row': 10, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '99.6', 'row': 11, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '452', 'row': 12, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '7559.5', 'row': 13, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '6710', 'row': 14, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '130185.8', 'row': 15, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '10140.5', 'row': 16, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '21.5', 'row': 17, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '1205.1', 'row': 18, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '55.8', 'row': 19, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '32.2', 'row': 20, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '6289.8', 'row': 21, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '23304.2', 'row': 22, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '1874.2', 'row': 23, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '33156.7', 'row': 24, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '-2.4', 'row': 25, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '310.8', 'row': 26, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '2888.3', 'row': 27, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '10614.6', 'row': 28, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '34449.2', 'row': 29, 'column': 3}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'A2C + SIL', 'value': '1100', 'row': 30, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '4025.1', 'row': 31, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '14958.2', 'row': 32, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '20.9', 'row': 33, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '661.2', 'row': 34, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '104975.6', 'row': 35, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '14306.1', 'row': 36, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '57071.7', 'row': 37, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '10.5', 'row': 38, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '2456.5', 'row': 39, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '2951.7', 'row': 40, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '31309.2', 'row': 41, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '-17.3', 'row': 42, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '10811.7', 'row': 43, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '340.5', 'row': 44, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '53314.6', 'row': 45, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '0', 'row': 46, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '461522.4', 'row': 47, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '7088.3', 'row': 48, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'A2C + SIL', 'value': '9164.2', 'row': 49, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Hand Gesture Segmentation', 'dataset': 'OUHANDS', 'metric': 'F-score', 'model': 'HGR-Net (Stage 1)', 'value': '0.963', 'row': 6, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Hand Gesture Segmentation', 'dataset': 'HGR1', 'metric': 'F-score', 'model': 'HGR-Net (Stage 1)', 'value': '0.9825', 'row': 8, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'CGP', 'value': '1978', 'row': 1, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'CGP', 'value': '199', 'row': 2, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'CGP', 'value': '890.4', 'row': 3, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'CGP', 'value': '1880', 'row': 4, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'CGP', 'value': '9412', 'row': 5, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'CGP', 'value': '99240', 'row': 6, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'CGP', 'value': '148', 'row': 7, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'CGP', 'value': '34200', 'row': 8, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'CGP', 'value': '1341.6', 'row': 9, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'CGP', 'value': '1138', 'row': 10, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'CGP', 'value': '85.8', 'row': 11, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'CGP', 'value': '38.4', 'row': 12, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'CGP', 'value': '13.2', 'row': 13, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'CGP', 'value': '24708', 'row': 14, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'CGP', 'value': '3580', 'row': 15, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'CGP', 'value': '12900', 'row': 16, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'CGP', 'value': '993010', 'row': 17, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'CGP', 'value': '2387', 'row': 18, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'CGP', 'value': '2', 'row': 19, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'CGP', 'value': '56.8', 'row': 20, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'CGP', 'value': '-51', 'row': 21, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'CGP', 'value': '28.2', 'row': 22, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'CGP', 'value': '782', 'row': 23, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'CGP', 'value': '1696', 'row': 24, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'CGP', 'value': '2350', 'row': 25, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'CGP', 'value': '2974', 'row': 26, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'CGP', 'value': '4', 'row': 27, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'CGP', 'value': '6130', 'row': 28, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'CGP', 'value': '1400', 'row': 29, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'CGP', 'value': '9086.8', 'row': 30, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'CGP', 'value': '57400', 'row': 31, 'column': 9}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'CGP', 'value': '0', 'row': 32, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'CGP', 'value': '2568', 'row': 33, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'CGP', 'value': '3696', 'row': 34, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'CGP', 'value': '7520', 'row': 35, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'CGP', 'value': '0', 'row': 36, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'CGP', 'value': '20', 'row': 37, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'CGP', 'value': '12702.2', 'row': 38, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'CGP', 'value': '770', 'row': 39, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'CGP', 'value': '2914', 'row': 40, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'CGP', 'value': '8960', 'row': 41, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'CGP', 'value': '24.2', 'row': 42, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'CGP', 'value': '724', 'row': 43, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'CGP', 'value': '-9011', 'row': 44, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'CGP', 'value': '8324', 'row': 45, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'CGP', 'value': '1001', 'row': 46, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'CGP', 'value': '2320', 'row': 47, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'CGP', 'value': '0', 'row': 48, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'CGP', 'value': '12040', 'row': 49, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'CGP', 'value': '0', 'row': 50, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'CGP', 'value': '14524', 'row': 51, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'CGP', 'value': '0', 'row': 52, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'CGP', 'value': '33752.4', 'row': 53, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'CGP', 'value': '3820', 'row': 54, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Yars Revenge', 'metric': 'Score', 'model': 'CGP', 'value': '28838.2', 'row': 55, 'column': 9}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'CGP', 'value': '2980', 'row': 56, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Semantic Object Interaction Classification', 'dataset': 'VLOG', 'metric': 'MAP', 'model': 'Object Relation Network', 'value': '44.7', 'row': 3, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'IQN', 'value': '7022', 'row': 1, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'IQN', 'value': '2946', 'row': 2, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'IQN', 'value': '29091', 'row': 3, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'IQN', 'value': '342016', 'row': 4, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'IQN', 'value': '2898', 'row': 5, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'IQN', 'value': '978200', 'row': 6, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'IQN', 'value': '1416', 'row': 7, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'IQN', 'value': '42244', 'row': 8, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'IQN', 'value': '42776', 'row': 9, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Berzerk', 'metric': 'Score', 'model': 'IQN', 'value': '1053', 'row': 10, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'IQN', 'value': '86.5', 'row': 11, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'IQN', 'value': '99.8', 'row': 12, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'IQN', 'value': '734', 'row': 13, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'IQN', 'value': '11561', 'row': 14, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'IQN', 'value': '16836', 'row': 15, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'IQN', 'value': '179082', 'row': 16, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Defender', 'metric': 'Score', 'model': 'IQN', 'value': '53537', 'row': 17, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'IQN', 'value': '128580', 'row': 18, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'IQN', 'value': '5.6', 'row': 19, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'IQN', 'value': '2359', 'row': 20, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'IQN', 'value': '33.8', 'row': 21, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'IQN', 'value': '34', 'row': 22, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'IQN', 'value': '4324', 'row': 23, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'IQN', 'value': '118365', 'row': 24, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'IQN', 'value': '911', 'row': 25, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 HERO', 'metric': 'Score', 'model': 'IQN', 'value': '28386', 'row': 26, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'IQN', 'value': '0.2', 'row': 27, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'IQN', 'value': '35108', 'row': 28, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'IQN', 'value': '15487', 'row': 29, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'IQN', 'value': '10707', 'row': 30, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'IQN', 'value': '73512', 'row': 31, 'column': 6}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'IQN', 'value': '0', 'row': 32, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'IQN', 'value': '6349', 'row': 33, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'IQN', 'value': '22682', 'row': 34, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Phoenix', 'metric': 'Score', 'model': 'IQN', 'value': '56599', 'row': 35, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'IQN', 'value': '0', 'row': 36, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'IQN', 'value': '21', 'row': 37, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'IQN', 'value': '200', 'row': 38, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'IQN', 'value': '25750', 'row': 39, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'IQN', 'value': '17765', 'row': 40, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'IQN', 'value': '57900', 'row': 41, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'IQN', 'value': '62.5', 'row': 42, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'IQN', 'value': '30140', 'row': 43, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Skiing', 'metric': 'Score', 'model': 'IQN', 'value': '-9289', 'row': 44, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'IQN', 'value': '8007', 'row': 45, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'IQN', 'value': '28888', 'row': 46, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'IQN', 'value': '74677', 'row': 47, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Surround', 'metric': 'Score', 'model': 'IQN', 'value': '9.4', 'row': 48, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'IQN', 'value': '23.6', 'row': 49, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'IQN', 'value': '12236', 'row': 50, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'IQN', 'value': '293', 'row': 51, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'IQN', 'value': '88148', 'row': 52, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'IQN', 'value': '1318', 'row': 53, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'IQN', 'value': '698045', 'row': 54, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'IQN', 'value': '31190', 'row': 55, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Yars Revenge', 'metric': 'Score', 'model': 'IQN', 'value': '28379', 'row': 56, 'column': 6}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'IQN', 'value': '21772', 'row': 57, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Object Localization', 'dataset': 'Mall', 'metric': 'Precision', 'model': 'Hausdorff Loss', 'value': '95.2', 'row': 1, 'column': 1}, {'task': 'Object Localization', 'dataset': 'Mall', 'metric': 'Precision', 'model': 'Hausdorff Loss', 'value': '99.5', 'row': 1, 'column': 2}, {'task': 'Object Localization', 'dataset': 'Mall', 'metric': 'Precision', 'model': 'Hausdorff Loss', 'value': '88.1', 'row': 1, 'column': 3}, {'task': 'Object Localization', 'dataset': 'Pupil', 'metric': 'Recall', 'model': 'Hausdorff Loss', 'value': '96.2', 'row': 2, 'column': 1}, {'task': 'Object Localization', 'dataset': 'Pupil', 'metric': 'Recall', 'model': 'Hausdorff Loss', 'value': '99.5', 'row': 2, 'column': 2}, {'task': 'Object Localization', 'dataset': 'Pupil', 'metric': 'Recall', 'model': 'Hausdorff Loss', 'value': '89.2', 'row': 2, 'column': 3}, {'task': 'Object Localization', 'dataset': 'Plant', 'metric': 'F-Score', 'model': 'Hausdorff Loss', 'value': '95.7', 'row': 3, 'column': 1}, {'task': 'Object Localization', 'dataset': 'Plant', 'metric': 'F-Score', 'model': 'Hausdorff Loss', 'value': '99.5', 'row': 3, 'column': 2}, {'task': 'Object Localization', 'dataset': 'Plant', 'metric': 'F-Score', 'model': 'Hausdorff Loss', 'value': '88.6', 'row': 3, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Accuracy', 'model': 'MQAN', 'value': '72.8', 'row': 5, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'GNN (DiffPool)', 'value': '62.53', 'row': 13, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'GNN (DiffPool)', 'value': '80.64', 'row': 13, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'REDDIT-MULTI-12K', 'metric': 'Accuracy', 'model': 'GNN (DiffPool)', 'value': '47.08', 'row': 13, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'GNN (DiffPool)', 'value': '75.48', 'row': 13, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'GNN (DiffPool)', 'value': '76.25', 'row': 13, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'S2V (with 2 DiffPool)', 'value': '63.33', 'row': 2, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'S2V (with 2 DiffPool)', 'value': '82.07', 'row': 3, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'POP3D', 'value': '1510.8', 'row': 1, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'POP3D', 'value': '729.15', 'row': 2, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'POP3D', 'value': '5400.13', 'row': 3, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'POP3D', 'value': '4310.67', 'row': 4, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asteroids', 'metric': 'Score', 'model': 'POP3D', 'value': '2488.1', 'row': 5, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Atlantis', 'metric': 'Score', 'model': 'POP3D', 'value': '2193605.67', 'row': 6, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bank Heist', 'metric': 'Score', 'model': 'POP3D', 'value': '1212.23', 'row': 7, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'POP3D', 'value': '15466.67', 'row': 8, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'POP3D', 'value': '4549', 'row': 9, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Bowling', 'metric': 'Score', 'model': 'POP3D', 'value': '38.99', 'row': 10, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Boxing', 'metric': 'Score', 'model': 'POP3D', 'value': '97.23', 'row': 11, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'POP3D', 'value': '458.41', 'row': 12, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Centipede', 'metric': 'Score', 'model': 'POP3D', 'value': '3315.44', 'row': 13, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Chopper Command', 'metric': 'Score', 'model': 'POP3D', 'value': '6308.33', 'row': 15, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'POP3D', 'value': '120247.33', 'row': 16, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Demon Attack', 'metric': 'Score', 'model': 'POP3D', 'value': '61147.33', 'row': 17, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Double Dunk', 'metric': 'Score', 'model': 'POP3D', 'value': '-7.89', 'row': 18, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'POP3D', 'value': '459.85', 'row': 19, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Fishing Derby', 'metric': 'Score', 'model': 'POP3D', 'value': '28.99', 'row': 20, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'POP3D', 'value': '21.21', 'row': 21, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'POP3D', 'value': '316.87', 'row': 22, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gopher', 'metric': 'Score', 'model': 'POP3D', 'value': '6207', 'row': 23, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'POP3D', 'value': '557.17', 'row': 24, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ice Hockey', 'metric': 'Score', 'model': 'POP3D', 'value': '-4.12', 'row': 25, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'POP3D', 'value': '358.54', 'row': 26, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'POP3D', 'value': '3891.67', 'row': 27, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Krull', 'metric': 'Score', 'model': 'POP3D', 'value': '7715.68', 'row': 28, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kung-Fu Master', 'metric': 'Score', 'model': 'POP3D', 'value': '33728', 'row': 29, 'column': 2}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'POP3D', 'value': '0', 'row': 31, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'POP3D', 'value': '1683.87', 'row': 32, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Name This Game', 'metric': 'Score', 'model': 'POP3D', 'value': '6065.63', 'row': 33, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'POP3D', 'value': '0', 'row': 34, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'POP3D', 'value': '20.5', 'row': 35, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'POP3D', 'value': '79.67', 'row': 36, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'POP3D', 'value': '15396.67', 'row': 37, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 River Raid', 'metric': 'Score', 'model': 'POP3D', 'value': '8052.23', 'row': 38, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'POP3D', 'value': '44679.67', 'row': 39, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Robotank', 'metric': 'Score', 'model': 'POP3D', 'value': '4.6', 'row': 40, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'POP3D', 'value': '1807.47', 'row': 41, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'POP3D', 'value': '1216.15', 'row': 42, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Star Gunner', 'metric': 'Score', 'model': 'POP3D', 'value': '48984', 'row': 43, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tennis', 'metric': 'Score', 'model': 'POP3D', 'value': '-8.32', 'row': 44, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Time Pilot', 'metric': 'Score', 'model': 'POP3D', 'value': '3770.33', 'row': 45, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Tutankham', 'metric': 'Score', 'model': 'POP3D', 'value': '241.21', 'row': 46, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'POP3D', 'value': '242701.51', 'row': 47, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'POP3D', 'value': '36.33', 'row': 48, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Video Pinball', 'metric': 'Score', 'model': 'POP3D', 'value': '37780.7', 'row': 49, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Wizard of Wor', 'metric': 'Score', 'model': 'POP3D', 'value': '4704', 'row': 50, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Zaxxon', 'metric': 'Score', 'model': 'POP3D', 'value': '9472', 'row': 51, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'MuJoCo Games', 'dataset': 'HalfCheetah', 'metric': 'Mean', 'model': 'POP3D', 'value': '3184.54', 'row': 1, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'Hopper', 'metric': 'Mean', 'model': 'POP3D', 'value': '1452.09', 'row': 2, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'InvertedDoublePendulum', 'metric': 'Mean', 'model': 'POP3D', 'value': '4907.64', 'row': 3, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'InvertedPendulum', 'metric': 'Mean', 'model': 'POP3D', 'value': '741.94', 'row': 4, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'Reacher', 'metric': 'Mean', 'model': 'POP3D', 'value': '-4.29', 'row': 5, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'Swimmer', 'metric': 'Mean', 'model': 'POP3D', 'value': '111.08', 'row': 6, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'Walker2d', 'metric': 'Mean', 'model': 'POP3D', 'value': '3966.01', 'row': 7, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'TextSnake', 'value': '82.7', 'row': 4, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'TextSnake', 'value': '74.5', 'row': 4, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'TextSnake', 'value': '78.4%', 'row': 4, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'TextSnake', 'value': '67.9', 'row': 6, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'TextSnake', 'value': '85.3', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'F-Measure', 'model': 'TextSnake', 'value': '75.6', 'row': 6, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'TextSnake', 'value': '84.9', 'row': 11, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'TextSnake', 'value': '80.4', 'row': 11, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'TextSnake', 'value': '82.6', 'row': 11, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'TextSnake', 'value': '83.2', 'row': 9, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'TextSnake', 'value': '73.9', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'TextSnake', 'value': '78.3', 'row': 9, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'Mask TextSpotter', 'value': '95', 'row': 11, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'Mask TextSpotter', 'value': '88.6', 'row': 11, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'Mask TextSpotter', 'value': '91.7', 'row': 11, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'Mask TextSpotter', 'value': '91.6', 'row': 11, 'column': 5}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'Mask TextSpotter', 'value': '81', 'row': 11, 'column': 6}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'Mask TextSpotter', 'value': '86', 'row': 11, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'Mask TextSpotter', 'value': '69', 'row': 4, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'Mask TextSpotter', 'value': '55', 'row': 4, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'Mask TextSpotter', 'value': '61.3', 'row': 4, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Machine Translation', 'dataset': 'IWSLT2014 German-English', 'metric': 'BLEU score', 'model': 'Variational Attention', 'value': '33.1', 'row': 10, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR (sRGB)', 'model': 'CBDNet (Blind)', 'value': '38.06', 'row': 15, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'SSIM (sRGB)', 'model': 'CBDNet (Blind)', 'value': '0.9421', 'row': 15, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'MEDA MEDA', 'value': '92.8', 'row': 14, 'column': 18}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'DQNMMCe', 'value': '29.5', 'row': 1, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'DQNMMCe', 'value': '1078.3', 'row': 2, 'column': 5}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'DQNMMCe+SR', 'value': '1778.6', 'row': 3, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'DQNMMCe+SR', 'value': '99.1', 'row': 4, 'column': 7}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'DQNMMCe', 'value': '2244.6', 'row': 5, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'DQNMMCe+SR', 'value': '1241.8', 'row': 6, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MR', 'model': 'CapsE', 'value': '719.0', 'row': 9, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MRR', 'model': 'CapsE', 'value': '0.415', 'row': 9, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@1', 'model': 'CapsE', 'value': '0.56', 'row': 9, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MR', 'model': 'CapsE', 'value': '303.0', 'row': 9, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MRR', 'model': 'CapsE', 'value': '0.523', 'row': 9, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@10', 'model': 'CapsE', 'value': '0.593', 'row': 9, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'Intrinsic Reward Agent', 'value': '1165.1', 'row': 2, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'Intrinsic Reward Agent', 'value': '32.8', 'row': 2, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'Intrinsic Reward Agent', 'value': '416', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'Intrinsic Reward Agent', 'value': '3036.5', 'row': 2, 'column': 4}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Intrinsic Reward Agent', 'value': '2504.6', 'row': 2, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Amazon Beauty', 'metric': 'Hit@10', 'model': 'SASRec', 'value': '0.4854', 'row': 2, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'Amazon Beauty', 'metric': 'nDCG@10', 'model': 'SASRec', 'value': '0.3219', 'row': 3, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'Amazon Games', 'metric': 'Hit@10', 'model': 'SASRec', 'value': '0.741', 'row': 4, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'Amazon Games', 'metric': 'nDCG@10', 'model': 'SASRec', 'value': '0.536', 'row': 5, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'Steam', 'metric': 'Hit@10', 'model': 'SASRec', 'value': '0.8729', 'row': 6, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'Steam', 'metric': 'nDCG@10', 'model': 'SASRec', 'value': '0.6306', 'row': 7, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 1M', 'metric': 'HR@10', 'model': 'SASRec', 'value': '0.8245', 'row': 8, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 1M', 'metric': 'nDCG@10', 'model': 'SASRec', 'value': '0.5905', 'row': 9, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': ' CUB-200-2011', 'metric': 'Accuracy', 'model': 'NTS-Net (K = 4)', 'value': '87.5', 'row': 13, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'FGVC Aircraft', 'metric': 'Accuracy', 'model': 'NTS-Net (K=4)', 'value': '91.4', 'row': 10, 'column': 1}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Stanford Cars', 'metric': 'Accuracy', 'model': 'NTS-Net (K=4)', 'value': '93.9', 'row': 10, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Average Score', 'model': 'A2C (SF-GRU)', 'value': '-1641', 'row': 1, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Best Score', 'model': 'A2C (SF-GRU)', 'value': '-718', 'row': 1, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Fortress Death', 'model': 'A2C (SF-GRU)', 'value': '3', 'row': 1, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Average Score', 'model': 'A2C (SF-GRU)', 'value': '-2444', 'row': 2, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Best Score', 'model': 'A2C (SF-GRU)', 'value': '-1700', 'row': 2, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Fortress Death', 'model': 'A2C (SF-GRU)', 'value': '11', 'row': 2, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Average Score', 'model': 'PPO (SF-FF)', 'value': '2337', 'row': 3, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Best Score', 'model': 'PPO (SF-FF)', 'value': '2818', 'row': 3, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Fortress Death', 'model': 'PPO (SF-FF)', 'value': '41', 'row': 3, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Average Score', 'model': 'PPO (SF-FF)', 'value': '2235', 'row': 4, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Best Score', 'model': 'PPO (SF-FF)', 'value': '2880', 'row': 4, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Fortress Death', 'model': 'PPO (SF-FF)', 'value': '40', 'row': 4, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Average Score', 'model': 'PPO (SF-GRU)', 'value': '2510', 'row': 5, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Best Score', 'model': 'PPO (SF-GRU)', 'value': '2870', 'row': 5, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Fortress Death', 'model': 'PPO (SF-GRU)', 'value': '43', 'row': 5, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Average Score', 'model': 'PPO (SF-GRU)', 'value': '2356', 'row': 6, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Best Score', 'model': 'PPO (SF-GRU)', 'value': '2932', 'row': 6, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Fortress Death', 'model': 'PPO (SF-GRU)', 'value': '41', 'row': 6, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Average Score', 'model': 'Rainbow', 'value': '-2973', 'row': 7, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Best Score', 'model': 'Rainbow', 'value': '-2330', 'row': 7, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Autoturn', 'metric': 'Fortress Death', 'model': 'Rainbow', 'value': '1.2', 'row': 7, 'column': 6}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Average Score', 'model': 'Rainbow', 'value': '-4112', 'row': 8, 'column': 4}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Best Score', 'model': 'Rainbow', 'value': '-3934', 'row': 8, 'column': 5}, {'task': 'Space Fortress', 'dataset': 'Youturn', 'metric': 'Fortress Death', 'model': 'Rainbow', 'value': '0', 'row': 8, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'Dense Prediction Cell', 'value': '82.7', 'row': 4, 'column': 20}]}\n","{'index': 2, 'records': [{'task': 'Human Part Segmentation', 'dataset': 'PASCAL-Person-Part', 'metric': 'mIoU', 'model': 'DPC', 'value': '71.34', 'row': 4, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 test', 'metric': 'Mean IoU', 'model': 'DPC', 'value': '87.9', 'row': 6, 'column': 21}]}\n","{'index': 2, 'records': [{'task': 'Online Multi-Object Tracking', 'dataset': 'MOT16', 'metric': 'MOTA', 'model': 'MOTDT', 'value': '47.6', 'row': 9, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari-57', 'metric': 'Medium Human-Normalized Score', 'model': 'PopArt-IMPALA', 'value': '110.7', 'row': 3, 'column': 1}, {'task': 'Visual Navigation', 'dataset': 'Dmlab-30', 'metric': 'Medium Human-Normalized Score', 'model': 'PopArt-IMPALA', 'value': '72.8%', 'row': 3, 'column': 6}]}\n","{'index': 1, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Synthetic Occlusion Aug+ Vol Heatmaps', 'value': '54.2', 'row': 15, 'column': 16}]}\n","{'index': 3, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'ResNet-50-FPN Mask R-CNN + KL Loss + var voting + soft-NMS', 'value': '40.4', 'row': 12, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'CLAN', 'value': '43.2', 'row': 15, 'column': 22}]}\n","{'index': 1, 'records': [{'task': 'Density Estimation', 'dataset': 'UCI POWER', 'metric': 'NLL', 'model': 'FFJORD', 'value': '-0.46', 'row': 3, 'column': 1}, {'task': 'Density Estimation', 'dataset': 'UCI GAS', 'metric': 'NLL', 'model': 'FFJORD', 'value': '-8.59', 'row': 3, 'column': 2}, {'task': 'Density Estimation', 'dataset': 'UCI HEPMASS', 'metric': 'NLL', 'model': 'FFJORD', 'value': '14.92', 'row': 3, 'column': 3}, {'task': 'Density Estimation', 'dataset': 'UCI MINIBOONE', 'metric': 'NLL', 'model': 'FFJORD', 'value': '10.43', 'row': 3, 'column': 4}, {'task': 'Density Estimation', 'dataset': 'BSDS300', 'metric': 'NLL', 'model': 'FFJORD', 'value': '-157.4', 'row': 3, 'column': 5}, {'task': 'Density Estimation', 'dataset': 'MNIST', 'metric': 'NLL', 'model': 'FFJORD', 'value': '0.99', 'row': 3, 'column': 6}, {'task': 'Density Estimation', 'dataset': 'CIFAR-10', 'metric': 'NLL', 'model': 'FFJORD', 'value': '3.4', 'row': 3, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Density Estimation', 'dataset': 'MNIST', 'metric': 'Negative ELBO', 'model': 'FFJORD', 'value': '82.82', 'row': 5, 'column': 1}, {'task': 'Density Estimation', 'dataset': 'OMNIGLOT', 'metric': 'Negative ELBO', 'model': 'FFJORD', 'value': '98.33', 'row': 5, 'column': 2}, {'task': 'Density Estimation', 'dataset': 'Freyfaces', 'metric': 'Negative ELBO', 'model': 'FFJORD', 'value': '4.39', 'row': 5, 'column': 3}, {'task': 'Density Estimation', 'dataset': 'Caltech-101', 'metric': 'Negative ELBO', 'model': 'FFJORD', 'value': '104.03', 'row': 5, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'SR-K-means', 'value': '0.936', 'row': 3, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'Accuracy', 'model': 'SR-K-means', 'value': '0.974', 'row': 3, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'SR-K-means', 'value': '0.873', 'row': 3, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'Accuracy', 'model': 'SR-K-means', 'value': '0.863', 'row': 3, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'SR-K-means', 'value': '0.866', 'row': 3, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'Accuracy', 'model': 'SR-K-means', 'value': '0.939', 'row': 3, 'column': 6}, {'task': 'Image Clustering', 'dataset': 'YouTube Faces DB', 'metric': 'NMI', 'model': 'SR-K-means', 'value': '0.806', 'row': 3, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'YouTube Faces DB', 'metric': 'Accuracy', 'model': 'SR-K-means', 'value': '0.605', 'row': 3, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'CMU-PIE', 'metric': 'NMI', 'model': 'SR-K-means', 'value': '0.945', 'row': 3, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'CMU-PIE', 'metric': 'Accuracy', 'model': 'SR-K-means', 'value': '0.902', 'row': 3, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'FRGC', 'metric': 'NMI', 'model': 'SR-K-means', 'value': '0.487', 'row': 3, 'column': 11}, {'task': 'Image Clustering', 'dataset': 'FRGC', 'metric': 'Accuracy', 'model': 'SR-K-means', 'value': '0.413', 'row': 3, 'column': 12}]}\n","{'index': 0, 'records': [{'task': 'Question Answering', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'BERT (single model)', 'value': '72.1', 'row': 6, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'BERT base (single)', 'value': '88.5', 'row': 8, 'column': 4}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'BERT base (single)', 'value': '80.8', 'row': 10, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'BERT large (single)', 'value': '84.1', 'row': 11, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'BERT large (single)', 'value': '90.9', 'row': 11, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'BERT large (+TriviaQA)', 'value': '84.2', 'row': 13, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'BERT large (+TriviaQA)', 'value': '91.1', 'row': 13, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'EM', 'model': 'BERT large', 'value': '78.7', 'row': 10, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'BERT large', 'value': '81.9', 'row': 10, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Common Sense Reasoning', 'dataset': 'SWAG', 'metric': 'Dev', 'model': 'BERT Base', 'value': '81.6', 'row': 4, 'column': 1}, {'task': 'Common Sense Reasoning', 'dataset': 'SWAG', 'metric': 'Dev', 'model': 'BERT Large', 'value': '86.6', 'row': 5, 'column': 1}, {'task': 'Common Sense Reasoning', 'dataset': 'SWAG', 'metric': 'Test', 'model': 'BERT Large', 'value': '86.3', 'row': 5, 'column': 2}]}\n","{'index': 6, 'records': [{'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2003 (English)', 'metric': 'F1', 'model': 'BERT Large', 'value': '92.8', 'row': 5, 'column': 2}, {'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2003 (English)', 'metric': 'F1', 'model': 'BERT Base', 'value': '92.4', 'row': 6, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'SF + RFC', 'value': '88.4', 'row': 6, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'SF + RFC', 'value': '62.8', 'row': 6, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'SF + RFC', 'value': '43.7', 'row': 6, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'SF + RFC', 'value': '73.6', 'row': 6, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'SF + RFC', 'value': '24.6', 'row': 6, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'SF + RFC', 'value': '75.2', 'row': 6, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'MAML++', 'value': '97.65', 'row': 11, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'MAML++', 'value': '99.33', 'row': 11, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MAML++', 'value': '52.40', 'row': 12, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MAML++', 'value': '67.15', 'row': 12, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'MAML++', 'value': '99.47', 'row': 11, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'MAML++', 'value': '99.85', 'row': 11, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'Criteo', 'metric': 'AUC', 'model': 'AutoInt', 'value': '0.8061', 'row': 10, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Criteo', 'metric': 'Log Loss', 'model': 'AutoInt', 'value': '0.4454', 'row': 10, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avazu', 'metric': 'AUC', 'model': 'AutoInt', 'value': '0.7752', 'row': 10, 'column': 4}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avazu', 'metric': 'LogLoss', 'model': 'AutoInt', 'value': '0.3823', 'row': 10, 'column': 5}, {'task': 'Click-Through Rate Prediction', 'dataset': 'KDD12', 'metric': 'AUC', 'model': 'AutoInt', 'value': '0.7881', 'row': 10, 'column': 6}, {'task': 'Click-Through Rate Prediction', 'dataset': 'KDD12', 'metric': 'Log Loss', 'model': 'AutoInt', 'value': '0.1545', 'row': 10, 'column': 7}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'AUC', 'model': 'AutoInt', 'value': '0.846', 'row': 10, 'column': 8}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'Log Loss', 'model': 'AutoInt', 'value': '0.3784', 'row': 10, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma25', 'metric': 'PSNR', 'model': 'N3Net', 'value': '30.19', 'row': 7, 'column': 3}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma25', 'metric': 'SSIM', 'model': 'N3Net', 'value': '0.892', 'row': 7, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma25', 'metric': 'PSNR', 'model': 'N3Net', 'value': '30.55', 'row': 1, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma50', 'metric': 'PSNR', 'model': 'N3Net', 'value': '27.43', 'row': 2, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma70', 'metric': 'PSNR', 'model': 'N3Net', 'value': '25.9', 'row': 3, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'N3Net', 'value': '29.3', 'row': 4, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'N3Net', 'value': '26.39', 'row': 5, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma70', 'metric': 'PSNR', 'model': 'N3Net', 'value': '25.14', 'row': 6, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma50', 'metric': 'PSNR', 'model': 'N3Net', 'value': '26.82', 'row': 8, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma70', 'metric': 'PSNR', 'model': 'N3Net', 'value': '25.15', 'row': 9, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'N3Net', 'value': '37.57', 'row': 1, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'N3Net', 'value': '33.84', 'row': 2, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'N3Net', 'value': '31.5', 'row': 3, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Gravitar', 'metric': 'Score', 'model': 'RND', 'value': '3906', 'row': 1, 'column': 1}, {'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'RND', 'value': '8152', 'row': 1, 'column': 2}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'RND', 'value': '-3', 'row': 1, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Private Eye', 'metric': 'Score', 'model': 'RND', 'value': '8666', 'row': 1, 'column': 4}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Solaris', 'metric': 'Score', 'model': 'RND', 'value': '3282', 'row': 1, 'column': 5}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Venture', 'metric': 'Score', 'model': 'RND', 'value': '1859', 'row': 1, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Human Interaction Recognition', 'dataset': 'BIT', 'metric': 'Accuracy', 'model': 'H-LSTCM', 'value': '94.03', 'row': 13, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Human Interaction Recognition', 'dataset': 'UT', 'metric': 'Accuracy', 'model': 'H-LSTCM', 'value': '98.33', 'row': 18, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Group Activity Recognition', 'dataset': 'Collective Activity', 'metric': 'Accuracy', 'model': 'H-LSTCM', 'value': '83.75', 'row': 20, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Group Activity Recognition', 'dataset': 'Volleyball', 'metric': 'Accuracy', 'model': 'H-LSTCM', 'value': '88.4', 'row': 10, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Natural Language Inference', 'dataset': 'SNLI', 'metric': '% Test Accuracy', 'model': 'Bi-LSTM sentence encoder (max-pooling)', 'value': '84.5', 'row': 18, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'Bi-LSTM sentence encoder (max-pooling)', 'value': '70.7', 'row': 18, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Mismatched', 'model': 'Bi-LSTM sentence encoder (max-pooling)', 'value': '71.1', 'row': 18, 'column': 3}, {'task': 'Natural Language Inference', 'dataset': 'SNLI', 'metric': '% Test Accuracy', 'model': 'Stacked Bi-LSTMs (shortcut connections, max-pooling)', 'value': '84.8', 'row': 22, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'Stacked Bi-LSTMs (shortcut connections, max-pooling)', 'value': '71.4', 'row': 22, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Mismatched', 'model': 'Stacked Bi-LSTMs (shortcut connections, max-pooling)', 'value': '72.2', 'row': 22, 'column': 3}, {'task': 'Natural Language Inference', 'dataset': 'SNLI', 'metric': '% Test Accuracy', 'model': 'Stacked Bi-LSTMs (shortcut connections, max-pooling, attention)', 'value': '84.4', 'row': 24, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'Stacked Bi-LSTMs (shortcut connections, max-pooling, attention)', 'value': '70.7', 'row': 24, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Mismatched', 'model': 'Stacked Bi-LSTMs (shortcut connections, max-pooling, attention)', 'value': '70.5', 'row': 24, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Fake News Detection', 'dataset': 'FNC-1', 'metric': 'Weighted Accuracy', 'model': 'Bi-LSTM (max-pooling, attention)', 'value': '82.23', 'row': 17, 'column': 1}, {'task': 'Fake News Detection', 'dataset': 'FNC-1', 'metric': 'Per-class Accuracy (Unrelated)', 'model': 'Bi-LSTM (max-pooling, attention)', 'value': '96.74', 'row': 17, 'column': 2}, {'task': 'Fake News Detection', 'dataset': 'FNC-1', 'metric': 'Per-class Accuracy (Discuss)', 'model': 'Bi-LSTM (max-pooling, attention)', 'value': '81.52', 'row': 17, 'column': 3}, {'task': 'Fake News Detection', 'dataset': 'FNC-1', 'metric': 'Per-class Accuracy (Agree)', 'model': 'Bi-LSTM (max-pooling, attention)', 'value': '51.34', 'row': 17, 'column': 4}, {'task': 'Fake News Detection', 'dataset': 'FNC-1', 'metric': 'Per-class Accuracy (Disagree)', 'model': 'Bi-LSTM (max-pooling, attention)', 'value': '10.33', 'row': 17, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Link Prediction', 'dataset': 'Wiki-Vote', 'metric': 'AUC', 'model': 'Asymmetric Transitivity Preservation', 'value': '94.81', 'row': 9, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Cit-HepPH', 'metric': 'AUC', 'model': 'Asymmetric Transitivity Preservation', 'value': '89.16', 'row': 9, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'Gnutella', 'metric': 'AUC', 'model': 'Asymmetric Transitivity Preservation', 'value': '93.14', 'row': 9, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Common Sense Reasoning', 'dataset': 'CommonsenseQA', 'metric': 'Accuracy', 'model': 'BERT-LARGE', 'value': '55.9', 'row': 6, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@10', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.54', 'row': 8, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@3', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.39', 'row': 8, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@1', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.26', 'row': 8, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MRR', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.35', 'row': 8, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@10', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.54', 'row': 8, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@3', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.48', 'row': 8, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@1', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.43', 'row': 8, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MRR', 'model': 'Structure-Aware Convolutional Networks', 'value': '0.47', 'row': 8, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'YAGO39K', 'metric': 'MRR', 'model': 'TransC (bern)', 'value': '0.11199999999999999', 'row': 11, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'YAGO39K', 'metric': 'MRR', 'model': 'TransC (bern)', 'value': '0.42', 'row': 11, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'YAGO39K', 'metric': 'Hits@1', 'model': 'TransC (bern)', 'value': '0.298', 'row': 11, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'YAGO39K', 'metric': 'Hits@3', 'model': 'TransC (bern)', 'value': '0.502', 'row': 11, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'YAGO39K', 'metric': 'Hits@10', 'model': 'TransC (bern)', 'value': '0.698', 'row': 11, 'column': 5}, {'task': 'Triple Classification', 'dataset': 'YAGO39K', 'metric': 'Accuracy', 'model': 'TransC (bern)', 'value': '93.8', 'row': 11, 'column': 6}, {'task': 'Triple Classification', 'dataset': 'YAGO39K', 'metric': 'Precision', 'model': 'TransC (bern)', 'value': '94.8', 'row': 11, 'column': 7}, {'task': 'Triple Classification', 'dataset': 'YAGO39K', 'metric': 'Recall', 'model': 'TransC (bern)', 'value': '92.7', 'row': 11, 'column': 8}, {'task': 'Triple Classification', 'dataset': 'YAGO39K', 'metric': 'F1-Score', 'model': 'TransC (bern)', 'value': '93.7', 'row': 11, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Gesture Recognition', 'dataset': 'ChaLearn 2013', 'metric': 'Accuracy', 'model': '3S Net TTM', 'value': '92.08', 'row': 8, 'column': 1}]}\n","{'index': 6, 'records': [{'task': 'Gesture Recognition', 'dataset': 'ChaLearn 2016', 'metric': 'Accuracy', 'model': '3S Net TTM', 'value': '39.95', 'row': 8, 'column': 1}]}\n","{'index': 7, 'records': [{'task': 'Gesture Recognition', 'dataset': 'MSRC-12', 'metric': 'Accuracy', 'model': '3S Net TTM', 'value': '99.01', 'row': 8, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Deep Comparison Network', 'value': '62.88', 'row': 16, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Deep Comparison Network', 'value': '75.84', 'row': 16, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 20-way (1-shot)', 'metric': 'Accuracy', 'model': 'Deep Comparison Network', 'value': '32.07', 'row': 6, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 20-way (5-shot)', 'metric': 'Accuracy', 'model': 'Deep Comparison Network', 'value': '47.31', 'row': 6, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Deep Comparison Network', 'value': '68.83', 'row': 8, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Deep Comparison Network', 'value': '79.62', 'row': 8, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'SVDNet + Random Erasing', 'value': '79.3', 'row': 7, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'SVDNet + Random Erasing', 'value': '62.4', 'row': 7, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Multi-Object Tracking', 'dataset': 'MOT16', 'metric': 'MOTA', 'model': 'TNT', 'value': '56.1', 'row': 8, 'column': 1}, {'task': 'Multi-Object Tracking', 'dataset': 'MOT16', 'metric': 'MOTA', 'model': 'TNT', 'value': '49.2', 'row': 8, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Multi-Object Tracking', 'dataset': 'MOT17', 'metric': 'MOTA', 'model': 'TNT', 'value': '58', 'row': 8, 'column': 1}, {'task': 'Multi-Object Tracking', 'dataset': 'MOT17', 'metric': 'MOTA', 'model': 'TNT', 'value': '51.9', 'row': 8, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'VisDA2017', 'metric': 'Accuracy', 'model': 'IAFN', 'value': '76.1', 'row': 7, 'column': 13}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'IAFN+ENT', 'value': '87.1', 'row': 12, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'IAFN+ENT', 'value': '88.9', 'row': 8, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'IAFN (ResNet-50)', 'value': '71.83', 'row': 8, 'column': 13}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'SPCNET', 'value': '68.6', 'row': 9, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'SPCNET', 'value': '80.6', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'SPCNET', 'value': '74.1', 'row': 9, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'SPCNET', 'value': '85.8', 'row': 15, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'SPCNET', 'value': '88.7', 'row': 15, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'SPCNET', 'value': '87.2', 'row': 15, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'SPCNET', 'value': '90.5', 'row': 12, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'SPCNET', 'value': '93.8', 'row': 12, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'F-Measure', 'model': 'SPCNET', 'value': '92.1', 'row': 12, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'SPCNET', 'value': '82.8', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'SPCNET', 'value': '83', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'SPCNET', 'value': '82.9', 'row': 7, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'PAN', 'value': '69.8', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'PAN', 'value': '80', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'PAN', 'value': '74.3', 'row': 1, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'PAN', 'value': '81.5', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'PAN', 'value': '90.8', 'row': 1, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'PAN', 'value': '85.9', 'row': 1, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'PAN', 'value': '83.2', 'row': 1, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'PAN', 'value': '86.8', 'row': 1, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'F-Measure', 'model': 'PAN', 'value': '85', 'row': 1, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'Self-Similarity Grouping (one shot)', 'value': '71.5', 'row': 13, 'column': 1}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'Self-Similarity Grouping (one shot)', 'value': '87.5', 'row': 13, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'Self-Similarity Grouping (one shot)', 'value': '95.2', 'row': 13, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-10', 'model': 'Self-Similarity Grouping (one shot)', 'value': '96.8', 'row': 13, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'mAP', 'model': 'Self-Similarity Grouping (one shot)', 'value': '55.9', 'row': 13, 'column': 1}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'Self-Similarity Grouping (one shot)', 'value': '72.4', 'row': 13, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'Self-Similarity Grouping (one shot)', 'value': '84', 'row': 13, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-10', 'model': 'Self-Similarity Grouping (one shot)', 'value': '87.7', 'row': 13, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'mAP', 'model': 'Self-Similarity Grouping (one shot)', 'value': '23.6', 'row': 3, 'column': 1}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'Rank-1', 'model': 'Self-Similarity Grouping (one shot)', 'value': '43.6', 'row': 3, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'Rank-10', 'model': 'Self-Similarity Grouping (one shot)', 'value': '61.8', 'row': 3, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'mAP', 'model': 'Self-Similarity Grouping (one shot)', 'value': '11.8', 'row': 7, 'column': 1}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'Rank-1', 'model': 'Self-Similarity Grouping (one shot)', 'value': '27.6', 'row': 7, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'Rank-10', 'model': 'Self-Similarity Grouping (one shot)', 'value': '45.7', 'row': 7, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Action Classification', 'dataset': 'Moments in Time', 'metric': 'Top 1 Accuracy', 'model': 'EvaNet', 'value': '31.8', 'row': 6, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'EvaNet', 'value': '82.1', 'row': 9, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR (Raw)', 'model': 'Image Unprocessing', 'value': '48.88', 'row': 16, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'SSIM (Raw)', 'model': 'Image Unprocessing', 'value': '0.9821', 'row': 16, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR (sRGB)', 'model': 'Image Unprocessing', 'value': '40.35', 'row': 16, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'SSIM (sRGB)', 'model': 'Image Unprocessing', 'value': '0.9641', 'row': 16, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Image Generation', 'dataset': 'CUB 128 x 128', 'metric': 'Inception score', 'model': 'FineGAN', 'value': '52.53', 'row': 6, 'column': 1}, {'task': 'Image Generation', 'dataset': 'Stanford Dogs', 'metric': 'Inception score', 'model': 'FineGAN', 'value': '46.92', 'row': 6, 'column': 2}, {'task': 'Image Generation', 'dataset': 'Stanford Cars', 'metric': 'Inception score', 'model': 'FineGAN', 'value': '32.62', 'row': 6, 'column': 3}, {'task': 'Image Generation', 'dataset': 'CUB 128 x 128', 'metric': 'FID', 'model': 'FineGAN', 'value': '11.25', 'row': 6, 'column': 4}, {'task': 'Image Generation', 'dataset': 'Stanford Dogs', 'metric': 'FID', 'model': 'FineGAN', 'value': '25.66', 'row': 6, 'column': 5}, {'task': 'Image Generation', 'dataset': 'Stanford Cars', 'metric': 'FID', 'model': 'FineGAN', 'value': '16.03', 'row': 6, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Image Clustering', 'dataset': 'CUB Birds', 'metric': 'NMI', 'model': 'FineGAN', 'value': '0.403', 'row': 6, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'Stanford Dogs', 'metric': 'NMI', 'model': 'FineGAN', 'value': '0.233', 'row': 6, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'Stanford Cars', 'metric': 'NMI', 'model': 'FineGAN', 'value': '0.354', 'row': 6, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'CUB Birds', 'metric': 'Accuracy', 'model': 'FineGAN', 'value': '0.126', 'row': 6, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'Stanford Dogs', 'metric': 'Accuracy', 'model': 'FineGAN', 'value': '0.079', 'row': 6, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'Stanford Cars', 'metric': 'Accuracy', 'model': 'FineGAN', 'value': '0.078', 'row': 6, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Image Generation', 'dataset': 'CIFAR-10', 'metric': 'FID', 'model': 'SS-GAN (sBN)', 'value': '15.65', 'row': 4, 'column': 2}, {'task': 'Image Generation', 'dataset': 'ImageNet 128x128', 'metric': 'FID', 'model': 'SS-GAN (sBN)', 'value': '43.87', 'row': 8, 'column': 2}, {'task': 'Image Generation', 'dataset': 'LSUN Bedroom 256 x 256', 'metric': 'FID', 'model': 'SS-GAN (sBN)', 'value': '13.3', 'row': 11, 'column': 2}, {'task': 'Image Generation', 'dataset': 'CelebA-HQ 128x128', 'metric': 'FID', 'model': 'SS-GAN (sBN)', 'value': '24.36', 'row': 14, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'Parameter-Free Spatial Attention', 'value': '94.7', 'row': 12, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'Parameter-Free Spatial Attention', 'value': '91.7', 'row': 12, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'Parameter-Free Spatial Attention', 'value': '89.0', 'row': 12, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'Parameter-Free Spatial Attention', 'value': '85.9', 'row': 12, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Image Retrieval', 'dataset': 'SOP', 'metric': 'R@1', 'model': 'NormSoftmax2048 (ResNet-50)', 'value': '79.5', 'row': 20, 'column': 2}, {'task': 'Image Retrieval', 'dataset': 'In-Shop', 'metric': 'R@1', 'model': 'NormSoftmax2048 (ResNet-50)', 'value': '89.4', 'row': 20, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Image Retrieval', 'dataset': 'CARS196', 'metric': 'R@1', 'model': 'NormSoftmax2048 (ResNet-50)', 'value': '89.3', 'row': 19, 'column': 2}, {'task': 'Image Retrieval', 'dataset': 'CUB-200-2011', 'metric': 'R@1', 'model': 'NormSoftmax2048 (ResNet-50)', 'value': '65.3', 'row': 19, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'ADVENT', 'value': '44.8', 'row': 14, 'column': 21}]}\n","{'index': 1, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'ADVENT', 'value': '48', 'row': 13, 'column': 19}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'Keypoint Detector Localization', 'value': '72.6', 'row': 4, 'column': 15}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Accuracy', 'model': 'Keypoint Detector Localization', 'value': '94.5%', 'row': 3, 'column': 2}]}\n","{'index': 0, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Monocular Total Capture', 'value': '58.3', 'row': 1, 'column': 13}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MTL', 'value': '61.2', 'row': 21, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MTL', 'value': '75.5', 'row': 21, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MTL', 'value': '45.1', 'row': 9, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MTL', 'value': '57.6', 'row': 9, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (10-shot)', 'metric': 'Accuracy', 'model': 'MTL', 'value': '63.4', 'row': 9, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'st-ReID(RE, RK)', 'value': '98.0', 'row': 23, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'st-ReID(RE, RK)', 'value': '95.5', 'row': 23, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'st-ReID(RE, RK,Cam)', 'value': '94.5', 'row': 13, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'st-ReID(RE, RK,Cam)', 'value': '92.7', 'row': 13, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'PoseFix', 'value': '74.7', 'row': 14, 'column': 1}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'PoseFix', 'value': '91.2', 'row': 14, 'column': 2}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'PoseFix', 'value': '81.9', 'row': 14, 'column': 3}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'PoseFix', 'value': '71.1', 'row': 14, 'column': 4}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'PoseFix', 'value': '81.2', 'row': 14, 'column': 5}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'PoseFix', 'value': '79.9', 'row': 14, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'feat+ (ProtoNet-ResNet)', 'value': '61.72', 'row': 18, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'feat+ (ProtoNet-ResNet)', 'value': '78.38', 'row': 18, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'feat (ProtoNet)', 'value': '68.65', 'row': 12, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 5-shot', 'metric': 'Accuracy', 'model': 'feat (ProtoNet)', 'value': '83.03', 'row': 12, 'column': 2}]}\n","{'index': 9, 'records': [{'task': 'Action Classification', 'dataset': 'Kinetics-400', 'metric': 'Top-1 Accuracy', 'model': 'SlowFast, R101 + NL', 'value': '79', 'row': 19, 'column': 3}, {'task': 'Action Classification', 'dataset': 'Kinetics-400', 'metric': 'Top-5 Accuracy', 'model': 'SlowFast, R101 + NL', 'value': '93.6', 'row': 19, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'Accuracy', 'model': 'DDC', 'value': '0.965', 'row': 13, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'DDC', 'value': '0.932', 'row': 13, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'Accuracy', 'model': 'DDC', 'value': '0.965', 'row': 13, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'DDC', 'value': '0.916', 'row': 13, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'Accuracy', 'model': 'DDC', 'value': '0.967', 'row': 13, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'DDC', 'value': '0.918', 'row': 13, 'column': 6}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'Accuracy', 'model': 'DDC', 'value': '0.619', 'row': 13, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'NMI', 'model': 'DDC', 'value': '0.682', 'row': 13, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'LetterA-J', 'metric': 'Accuracy', 'model': 'DDC', 'value': '0.573', 'row': 13, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'LetterA-J', 'metric': 'NMI', 'model': 'DDC', 'value': '0.546', 'row': 13, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'Accuracy', 'model': 'DDC-DA', 'value': '0.969', 'row': 14, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'DDC-DA', 'value': '0.941', 'row': 14, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'Accuracy', 'model': 'DDC-DA', 'value': '0.97', 'row': 14, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'DDC-DA', 'value': '0.927', 'row': 14, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'Accuracy', 'model': 'DDC-DA', 'value': '0.977', 'row': 14, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'DDC-DA', 'value': '0.939', 'row': 14, 'column': 6}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'Accuracy', 'model': 'DDC-DA', 'value': '0.609', 'row': 14, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'NMI', 'model': 'DDC-DA', 'value': '0.661', 'row': 14, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'LetterA-J', 'metric': 'Accuracy', 'model': 'DDC-DA', 'value': '0.691', 'row': 14, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'LetterA-J', 'metric': 'NMI', 'model': 'DDC-DA', 'value': '0.629', 'row': 14, 'column': 10}]}\n","{'index': 3, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'VIVA Hand Gestures Dataset', 'metric': 'Accuracy', 'model': 'MTUT', 'value': '86.08', 'row': 6, 'column': 2}, {'task': 'Hand Gesture Recognition', 'dataset': 'VIVA Hand Gestures Dataset', 'metric': 'Accuracy', 'model': 'MTUT', 'value': '86.08', 'row': 6, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'EgoGesture', 'metric': 'Accuracy', 'model': 'MTUT', 'value': '93.87', 'row': 6, 'column': 2}, {'task': 'Hand Gesture Recognition', 'dataset': 'EgoGesture', 'metric': 'Accuracy', 'model': 'MTUT', 'value': '93.87', 'row': 6, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'NVGesture', 'metric': 'Accuracy', 'model': 'MTUT', 'value': '86.93', 'row': 12, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Recipe Generation', 'dataset': 'Recipe1M', 'metric': 'Mean IoU', 'model': 'Set Transformer', 'value': '32.11', 'row': 4, 'column': 1}, {'task': 'Recipe Generation', 'dataset': 'Recipe1M', 'metric': 'F1', 'model': 'Set Transformer', 'value': '48.61', 'row': 4, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'MRR', 'model': 'ComplEx NSCaching', 'value': '0.9355', 'row': 37, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'MR', 'model': 'ComplEx NSCaching', 'value': '1072', 'row': 37, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@10', 'model': 'ComplEx NSCaching', 'value': '0.9398', 'row': 37, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MRR', 'model': 'ComplEx NSCaching', 'value': '0.4463', 'row': 37, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MR', 'model': 'ComplEx NSCaching', 'value': '5365', 'row': 37, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@10', 'model': 'ComplEx NSCaching', 'value': '0.5089', 'row': 37, 'column': 8}, {'task': 'Link Prediction', 'dataset': ' FB15k', 'metric': 'MRR', 'model': 'ComplEx NSCaching', 'value': '0.7721', 'row': 37, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'MR', 'model': 'ComplEx NSCaching', 'value': '82', 'row': 37, 'column': 10}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@10', 'model': 'ComplEx NSCaching', 'value': '86.82', 'row': 37, 'column': 11}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MRR', 'model': 'ComplEx NSCaching', 'value': '0.3021', 'row': 37, 'column': 12}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MR', 'model': 'ComplEx NSCaching', 'value': '221', 'row': 37, 'column': 13}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@10', 'model': 'ComplEx NSCaching', 'value': '0.4805', 'row': 37, 'column': 14}]}\n","{'index': 3, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-German', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '84.78', 'row': 5, 'column': 3}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Spanish', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '77.33', 'row': 5, 'column': 4}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '77.95', 'row': 5, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Italian', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '69.43', 'row': 5, 'column': 6}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Japanese', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '60.3', 'row': 5, 'column': 7}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Russian', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '67.78', 'row': 5, 'column': 8}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Chinese', 'metric': 'Accuracy', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '71.93', 'row': 5, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Cross-Lingual Bitext Mining', 'dataset': 'BUCC German-to-English', 'metric': 'F1 score', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '96.19', 'row': 10, 'column': 5}, {'task': 'Cross-Lingual Bitext Mining', 'dataset': 'BUCC French-to-English', 'metric': 'F1 score', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '93.91', 'row': 10, 'column': 6}, {'task': 'Cross-Lingual Bitext Mining', 'dataset': 'BUCC Russian-to-English', 'metric': 'F1 score', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '93.3', 'row': 10, 'column': 7}, {'task': 'Cross-Lingual Bitext Mining', 'dataset': 'BUCC Chinese-to-English', 'metric': 'F1 score', 'model': 'Massively Multilingual Sentence Embeddings', 'value': '92.27', 'row': 10, 'column': 8}]}\n","{'index': 5, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Kodak24 sigma10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '35.19', 'row': 10, 'column': 1}, {'task': 'Grayscale Image Denoising', 'dataset': 'Kodak24 sigma30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '30.02', 'row': 10, 'column': 2}, {'task': 'Grayscale Image Denoising', 'dataset': 'Kodak24 sigma50', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '27.88', 'row': 10, 'column': 3}, {'task': 'Grayscale Image Denoising', 'dataset': 'Kodak24 sigma70', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '26.57', 'row': 10, 'column': 4}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '34.01', 'row': 10, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '28.58', 'row': 10, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '26.43', 'row': 10, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma70', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '25.12', 'row': 10, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '35.45', 'row': 10, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '30.08', 'row': 10, 'column': 10}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma50', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '27.47', 'row': 10, 'column': 11}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma70', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '25.71', 'row': 10, 'column': 12}]}\n","{'index': 6, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '37.33', 'row': 10, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '31.98', 'row': 10, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma50', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '29.7', 'row': 10, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma70', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '28.24', 'row': 10, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '36.49', 'row': 10, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '30.7', 'row': 10, 'column': 6}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '28.34', 'row': 10, 'column': 7}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma70', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '26.88', 'row': 10, 'column': 8}, {'task': 'Color Image Denoising', 'dataset': 'Urban100 sigma10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '36.75', 'row': 10, 'column': 9}, {'task': 'Color Image Denoising', 'dataset': 'Urban100 sigma30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '31.78', 'row': 10, 'column': 10}, {'task': 'Color Image Denoising', 'dataset': 'Urban100 sigma50', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '29.38', 'row': 10, 'column': 11}, {'task': 'Color Image Denoising', 'dataset': 'Urban100 sigma70', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '27.74', 'row': 10, 'column': 12}]}\n","{'index': 7, 'records': [{'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '29.7', 'row': 2, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 10', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.8252', 'row': 2, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 20', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '32.1', 'row': 3, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 20', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.8886', 'row': 3, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '33.54', 'row': 4, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 30', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.9156', 'row': 4, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 40', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '34.54', 'row': 5, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'LIVE1 Quality 40', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.9304', 'row': 5, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 10', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '30.03', 'row': 6, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 10', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.8194', 'row': 6, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 20', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '32.19', 'row': 7, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 20', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.8704', 'row': 7, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 30', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '33.46', 'row': 8, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 30', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.8932', 'row': 8, 'column': 15}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 40', 'metric': 'PSNR', 'model': 'Residual Dense Network +', 'value': '34.29', 'row': 9, 'column': 14}, {'task': 'Image Compression Artifact Reduction', 'dataset': 'Classic5 Quality 40', 'metric': 'SSIM', 'model': 'Residual Dense Network +', 'value': '0.9063', 'row': 9, 'column': 15}]}\n","{'index': 1, 'records': [{'task': 'Face Identification', 'dataset': 'MegaFace', 'metric': 'Accuracy', 'model': 'SV-AM-Softmax', 'value': '97.2', 'row': 14, 'column': 1}, {'task': 'Face Verification', 'dataset': 'MegaFace', 'metric': 'Accuracy', 'model': 'SV-AM-Softmax', 'value': '97.38', 'row': 14, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Face Identification', 'dataset': 'Trillion Pairs Dataset', 'metric': 'Accuracy', 'model': 'SV-AM-Softmax', 'value': '73.56', 'row': 14, 'column': 1}, {'task': 'Face Verification', 'dataset': 'Trillion Pairs Dataset', 'metric': 'Accuracy', 'model': 'SV-AM-Softmax', 'value': '72.71', 'row': 14, 'column': 2}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'Occlusion LineMOD', 'metric': 'Mean ADD', 'model': 'PVNet', 'value': '40.77', 'row': 10, 'column': 6}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Accuracy', 'model': 'PVNet', 'value': '99%', 'row': 16, 'column': 3}]}\n","{'index': 2, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'PVNet', 'value': '86.27', 'row': 16, 'column': 4}]}\n","{'index': 3, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'Occlusion LineMOD', 'metric': 'Accuracy', 'model': 'PVNet', 'value': '61.06%', 'row': 10, 'column': 4}]}\n","{'index': 6, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'YCB-Video', 'metric': 'Mean AUC', 'model': 'PVNet', 'value': '73.4', 'row': 3, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO minival', 'metric': 'AP', 'model': 'MSPN', 'value': '75.9', 'row': 5, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'MSPN', 'value': '76.1', 'row': 8, 'column': 3}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'MSPN', 'value': '93.4', 'row': 8, 'column': 4}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'MSPN', 'value': '83.8', 'row': 8, 'column': 5}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'MSPN', 'value': '72.3', 'row': 8, 'column': 6}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'MSPN', 'value': '81.5', 'row': 8, 'column': 7}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'MSPN', 'value': '81.6', 'row': 8, 'column': 8}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AR50', 'model': 'MSPN', 'value': '96.3', 'row': 8, 'column': 9}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AR75', 'model': 'MSPN', 'value': '88.1', 'row': 8, 'column': 10}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'ARM', 'model': 'MSPN', 'value': '77.5', 'row': 8, 'column': 11}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'ARL', 'model': 'MSPN', 'value': '87.1', 'row': 8, 'column': 12}]}\n","{'index': 7, 'records': [{'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'AP', 'model': 'MSPN+*', 'value': '76.4', 'row': 6, 'column': 3}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'AP50', 'model': 'MSPN+*', 'value': '92.9', 'row': 6, 'column': 4}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'AP75', 'model': 'MSPN+*', 'value': '82.6', 'row': 6, 'column': 5}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'ARM', 'model': 'MSPN+*', 'value': '71.4', 'row': 6, 'column': 6}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'ARL', 'model': 'MSPN+*', 'value': '83.2', 'row': 6, 'column': 7}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'AR', 'model': 'MSPN+*', 'value': '82.2', 'row': 6, 'column': 8}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'AR50', 'model': 'MSPN+*', 'value': '96', 'row': 6, 'column': 9}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'AR75', 'model': 'MSPN+*', 'value': '87.7', 'row': 6, 'column': 10}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'ARM', 'model': 'MSPN+*', 'value': '77.5', 'row': 6, 'column': 11}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-challenge', 'metric': 'APL', 'model': 'MSPN+*', 'value': '88.6', 'row': 6, 'column': 12}]}\n","{'index': 8, 'records': [{'task': 'Pose Estimation', 'dataset': 'MPII Human Pose', 'metric': 'PCKh-0.5', 'model': 'MSPN', 'value': '92.6', 'row': 14, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Face Anti-Spoofing', 'dataset': 'CASIA-MFSD', 'metric': 'EER', 'model': '3D Synthesis (balancing sampling)', 'value': '2.22', 'row': 12, 'column': 1}, {'task': 'Face Anti-Spoofing', 'dataset': 'CASIA-MFSD', 'metric': 'HTER', 'model': '3D Synthesis (balancing sampling)', 'value': '1.67', 'row': 12, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Face Anti-Spoofing', 'dataset': 'Replay-Attack', 'metric': 'EER', 'model': '3D Synthesis (balancing sampling)', 'value': '0.25', 'row': 11, 'column': 1}, {'task': 'Face Anti-Spoofing', 'dataset': 'Replay-Attack', 'metric': 'HTER', 'model': '3D Synthesis (balancing sampling)', 'value': '0.63', 'row': 11, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'Contrastive Adaptation Network', 'value': '90.6', 'row': 7, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'VisDA2017', 'metric': 'Accuracy', 'model': 'Contrastive Adaptation Network', 'value': '87.2', 'row': 9, 'column': 13}]}\n","{'index': 0, 'records': [{'task': 'Node Classification', 'dataset': 'Cora with Public Split: fixed 20 nodes per class', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '79.5', 'row': 1, 'column': 9}, {'task': 'Node Classification', 'dataset': 'Cora with Public Split: fixed 20 nodes per class', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '80.4', 'row': 1, 'column': 10}, {'task': 'Node Classification', 'dataset': 'Cora (3%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '76.3', 'row': 2, 'column': 9}, {'task': 'Node Classification', 'dataset': 'Cora (3%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '77.7', 'row': 2, 'column': 10}, {'task': 'Node Classification', 'dataset': 'Cora (1%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '66.1', 'row': 3, 'column': 9}, {'task': 'Node Classification', 'dataset': 'Cora (1%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '67.5', 'row': 3, 'column': 10}, {'task': 'Node Classification', 'dataset': 'Cora (0.5%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '58.1', 'row': 4, 'column': 9}, {'task': 'Node Classification', 'dataset': 'Cora (0.5%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '60.8', 'row': 4, 'column': 10}, {'task': 'Node Classification', 'dataset': 'CiteSeer with Public Split: fixed 20 nodes per class', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '66.2', 'row': 6, 'column': 9}, {'task': 'Node Classification', 'dataset': 'CiteSeer with Public Split: fixed 20 nodes per class', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '68.7', 'row': 6, 'column': 10}, {'task': 'Node Classification', 'dataset': 'CiteSeer (1%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '61.3', 'row': 7, 'column': 9}, {'task': 'Node Classification', 'dataset': 'CiteSeer (1%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '63.3', 'row': 7, 'column': 10}, {'task': 'Node Classification', 'dataset': 'CiteSeer (0.5%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '53.2', 'row': 8, 'column': 9}, {'task': 'Node Classification', 'dataset': 'CiteSeer (0.5%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '53.8', 'row': 8, 'column': 10}, {'task': 'Node Classification', 'dataset': 'PubMed with Public Split: fixed 20 nodes per class', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '78.3', 'row': 11, 'column': 9}, {'task': 'Node Classification', 'dataset': 'PubMed with Public Split: fixed 20 nodes per class', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '78.1', 'row': 11, 'column': 10}, {'task': 'Node Classification', 'dataset': 'PubMed (0.1%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '73.4', 'row': 12, 'column': 9}, {'task': 'Node Classification', 'dataset': 'PubMed (0.1%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '72.8', 'row': 12, 'column': 10}, {'task': 'Node Classification', 'dataset': 'PubMed (0.05%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '68.8', 'row': 13, 'column': 9}, {'task': 'Node Classification', 'dataset': 'PubMed (0.05%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '66', 'row': 13, 'column': 10}, {'task': 'Node Classification', 'dataset': 'PubMed (0.03%)', 'metric': 'Accuracy', 'model': 'LanczosNet', 'value': '60.4', 'row': 14, 'column': 9}, {'task': 'Node Classification', 'dataset': 'PubMed (0.03%)', 'metric': 'Accuracy', 'model': 'AdaLanczosNet', 'value': '61', 'row': 14, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Quantum Chemistry Regression', 'dataset': 'Quantum Chemistry Regression', 'metric': 'Validation MAE', 'model': 'LanczosNet', 'value': '9.65', 'row': 10, 'column': 1}, {'task': 'Quantum Chemistry Regression', 'dataset': 'Quantum Chemistry Regression', 'metric': 'Test MAE', 'model': 'LanczosNet', 'value': '9.58', 'row': 10, 'column': 2}]}\n","{'index': 6, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'TridentNet (ResNet-101)', 'value': '42.7', 'row': 6, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'TridentNet (ResNet-101)', 'value': '63.6', 'row': 6, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'TridentNet (ResNet-101)', 'value': '46.5', 'row': 6, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'TridentNet (ResNet-101)', 'value': '23.9', 'row': 6, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'TridentNet (ResNet-101)', 'value': '46.6', 'row': 6, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'TridentNet (ResNet-101)', 'value': '56.6', 'row': 6, 'column': 7}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'TridentNet (ResNet-101-Deformable, Image Pyramid)', 'value': '48.4', 'row': 8, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'TridentNet (ResNet-101-Deformable, Image Pyramid)', 'value': '69.7', 'row': 8, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'TridentNet (ResNet-101-Deformable, Image Pyramid)', 'value': '53.5', 'row': 8, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'TridentNet (ResNet-101-Deformable, Image Pyramid)', 'value': '31.8', 'row': 8, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'TridentNet (ResNet-101-Deformable, Image Pyramid)', 'value': '51.3', 'row': 8, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'TridentNet (ResNet-101-Deformable, Image Pyramid)', 'value': '60.3', 'row': 8, 'column': 7}]}\n","{'index': 7, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'TridentNet (ResNet-101)', 'value': '42', 'row': 4, 'column': 1}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'TridentNet (ResNet-101)', 'value': '63.5', 'row': 4, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'TridentNet (ResNet-101)', 'value': '45.5', 'row': 4, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'TridentNet (ResNet-101)', 'value': '24.9', 'row': 4, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'TridentNet (ResNet-101)', 'value': '47', 'row': 4, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'TridentNet (ResNet-101)', 'value': '56.9', 'row': 4, 'column': 6}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGBD', 'dataset': 'CAMERA25', 'metric': 'mAP 3DIou@25', 'model': 'NOCS (128 bins)', 'value': '91.4', 'row': 6, 'column': 2}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'CAMERA25', 'metric': 'mAP 3DIou@50', 'model': 'NOCS (128 bins)', 'value': '85.3', 'row': 6, 'column': 3}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'CAMERA25', 'metric': 'mAP 5, 5cm', 'model': 'NOCS (128 bins)', 'value': '38.8', 'row': 6, 'column': 4}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'CAMERA25', 'metric': 'mAP 10, 5cm', 'model': 'NOCS (128 bins)', 'value': '61.7', 'row': 6, 'column': 5}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'CAMERA25', 'metric': 'mAP 10, 10cm', 'model': 'NOCS (128 bins)', 'value': '62.2', 'row': 6, 'column': 6}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'REAL275', 'metric': 'mAP 3DIou@25', 'model': 'NOCS (128 bins)', 'value': '84.9', 'row': 10, 'column': 2}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'REAL275', 'metric': 'mAP 3DIou@50', 'model': 'NOCS (128 bins)', 'value': '80.5', 'row': 10, 'column': 3}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'REAL275', 'metric': 'mAP 5, 5cm', 'model': 'NOCS (128 bins)', 'value': '9.5', 'row': 10, 'column': 4}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'REAL275', 'metric': 'mAP 10, 5cm', 'model': 'NOCS (128 bins)', 'value': '26.7', 'row': 10, 'column': 5}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'REAL275', 'metric': 'mAP 10, 10cm', 'model': 'NOCS (128 bins)', 'value': '26.7', 'row': 10, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes val', 'metric': 'mIoU', 'model': 'Auto-DeepLab-L', 'value': '80.33', 'row': 3, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'Auto-DeepLab-L', 'value': '82.1', 'row': 7, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'mIoU', 'model': 'Auto-DeepLab-L', 'value': '82.04', 'row': 13, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 test', 'metric': 'mIoU', 'model': 'Auto-DeepLab-L', 'value': '85.6', 'row': 3, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'ADE20K val', 'metric': 'mIoU', 'model': 'Auto-DeepLab-L', 'value': '43.98', 'row': 3, 'column': 2}, {'task': 'Semantic Segmentation', 'dataset': 'ADE20K val', 'metric': 'Pixel Accuracy', 'model': 'Auto-DeepLab-L', 'value': '81.72%', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Region Proposal', 'dataset': 'COCO test-dev', 'metric': 'AR100', 'model': 'GA-RPN (ResNet-50-FPN)', 'value': '59.2', 'row': 13, 'column': 2}, {'task': 'Region Proposal', 'dataset': 'COCO test-dev', 'metric': 'AR300', 'model': 'GA-RPN (ResNet-50-FPN)', 'value': '65.2', 'row': 13, 'column': 3}, {'task': 'Region Proposal', 'dataset': 'COCO test-dev', 'metric': 'AR1000', 'model': 'GA-RPN (ResNet-50-FPN)', 'value': '68.5', 'row': 13, 'column': 4}, {'task': 'Region Proposal', 'dataset': 'COCO test-dev', 'metric': 'ARS', 'model': 'GA-RPN (ResNet-50-FPN)', 'value': '40.9', 'row': 13, 'column': 5}, {'task': 'Region Proposal', 'dataset': 'COCO test-dev', 'metric': 'ARM', 'model': 'GA-RPN (ResNet-50-FPN)', 'value': '67.8', 'row': 13, 'column': 6}, {'task': 'Region Proposal', 'dataset': 'COCO test-dev', 'metric': 'ARL', 'model': 'GA-RPN (ResNet-50-FPN)', 'value': '79', 'row': 13, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'GA-Faster-RCNN', 'value': '39.8', 'row': 4, 'column': 1}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'GA-Faster-RCNN', 'value': '59.2', 'row': 4, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'GA-Faster-RCNN', 'value': '43.5', 'row': 4, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'GA-Faster-RCNN', 'value': '21.8', 'row': 4, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'GA-Faster-RCNN', 'value': '42.6', 'row': 4, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'GA-Faster-RCNN', 'value': '50.7', 'row': 4, 'column': 6}]}\n","{'index': 6, 'records': [{'task': 'Node Clustering', 'dataset': 'DBLP', 'metric': 'Accuracy', 'model': 'attri2vec-ReLU', 'value': '76.69', 'row': 9, 'column': 1}, {'task': 'Node Clustering', 'dataset': 'DBLP', 'metric': 'F-Measure', 'model': 'attri2vec-ReLU', 'value': '69.67', 'row': 9, 'column': 2}, {'task': 'Node Clustering', 'dataset': 'DBLP', 'metric': 'NMI', 'model': 'attri2vec-ReLU', 'value': '44.34', 'row': 9, 'column': 3}]}\n","{'index': 7, 'records': [{'task': 'Node Clustering', 'dataset': 'Facebook', 'metric': 'Accuracy', 'model': 'attri2vec-kernel', 'value': '66.77', 'row': 10, 'column': 1}, {'task': 'Node Clustering', 'dataset': 'Facebook', 'metric': 'F-Measure', 'model': 'attri2vec-kernel', 'value': '50.32', 'row': 10, 'column': 2}, {'task': 'Node Clustering', 'dataset': 'Facebook', 'metric': 'NMI', 'model': 'attri2vec-kernel', 'value': '17.15', 'row': 10, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'Cambridge', 'metric': 'Accuracy', 'model': 'Key Frames + Feature Fusion', 'value': '98.23', 'row': 12, 'column': 2}]}\n","{'index': 6, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'Northwestern University', 'metric': 'Accuracy', 'model': 'Key Frames + Feature Fusion', 'value': '96.89', 'row': 3, 'column': 2}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'YCB-Video', 'metric': 'Mean AUC', 'model': 'DenseFusion', 'value': '93.1', 'row': 23, 'column': 9}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGBD', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'DeepFusion', 'value': '94.3', 'row': 15, 'column': 7}]}\n","{'index': 4, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'SVDNet', 'value': '56.8', 'row': 3, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Text Classification', 'dataset': 'Yelp-5', 'metric': 'Accuracy', 'model': 'HAHNN (CNN)', 'value': '73.28', 'row': 5, 'column': 1}, {'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'HAHNN (CNN)', 'value': '95.17', 'row': 6, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Community Detection', 'dataset': 'Amazon', 'metric': 'F1-score', 'model': 'CommunityGAN', 'value': '0.86', 'row': 9, 'column': 1}, {'task': 'Community Detection', 'dataset': 'Amazon', 'metric': 'F1-score', 'model': 'CommunityGAN', 'value': '0.327', 'row': 9, 'column': 2}, {'task': 'Community Detection', 'dataset': 'DBLP', 'metric': 'F1-Score', 'model': 'CommunityGAN', 'value': '0.456', 'row': 9, 'column': 3}, {'task': 'Community Detection', 'dataset': 'Amazon', 'metric': 'F1-score', 'model': 'CommunityGAN', 'value': '0.853', 'row': 19, 'column': 1}, {'task': 'Community Detection', 'dataset': 'Amazon', 'metric': 'F1-score', 'model': 'CommunityGAN', 'value': '0.091', 'row': 19, 'column': 2}, {'task': 'Community Detection', 'dataset': 'DBLP', 'metric': 'F1-Score', 'model': 'CommunityGAN', 'value': '0.153', 'row': 19, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Clique Prediction', 'dataset': 'arXiv-AstroPh 2-clique', 'metric': 'AUC', 'model': 'CommunityGAN', 'value': '92.3', 'row': 7, 'column': 1}, {'task': 'Clique Prediction', 'dataset': 'arXiv-AstroPh 3-clique', 'metric': 'AUC', 'model': 'CommunityGAN', 'value': '99', 'row': 7, 'column': 2}, {'task': 'Clique Prediction', 'dataset': 'arXiv-AstroPh 4-clique', 'metric': 'AUC', 'model': 'CommunityGAN', 'value': '97', 'row': 7, 'column': 3}, {'task': 'Clique Prediction', 'dataset': 'arXiv-GrQc 2-clique', 'metric': 'AUC', 'model': 'CommunityGAN', 'value': '90.4', 'row': 15, 'column': 1}, {'task': 'Clique Prediction', 'dataset': 'arXiv-GrQc 3-clique', 'metric': 'AUC', 'model': 'CommunityGAN', 'value': '99.3', 'row': 15, 'column': 2}, {'task': 'Clique Prediction', 'dataset': 'arXiv-GrQc 4-clique', 'metric': 'AUC', 'model': 'CommunityGAN', 'value': '95.6', 'row': 15, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'MNIST', 'metric': 'Percentage error', 'model': 'VGG8B + LocalLearning + CO', 'value': '0.26', 'row': 4, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'Fashion-MNIST', 'metric': 'Percentage error', 'model': 'VGG8B(2x) + LocalLearning + CO', 'value': '4.14', 'row': 5, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'Kuzushiji-MNIST', 'metric': 'Percentage error', 'model': 'VGG8B(2x) + LocalLearning + CO', 'value': '0.99', 'row': 4, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'VGG11B(2x) + LocalLearning + CO', 'value': '96.4', 'row': 7, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage correct', 'model': 'VGG11B(3x) + LocalLearning', 'value': '79.9', 'row': 6, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Image Classification', 'dataset': 'SVHN', 'metric': 'Percentage error', 'model': 'VGG8B + LocalLearning + CO', 'value': '1.65', 'row': 3, 'column': 5}]}\n","{'index': 7, 'records': [{'task': 'Image Classification', 'dataset': 'STL-10', 'metric': 'Percentage correct', 'model': 'VGG8B + LocalLearning + CO', 'value': '80.75', 'row': 3, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Visual Entailment', 'dataset': 'SNLI-VE val', 'metric': 'Accuracy', 'model': 'EVE-ROI*', 'value': '70.81', 'row': 8, 'column': 1}, {'task': 'Visual Entailment', 'dataset': 'SNLI-VE test', 'metric': 'Accuracy', 'model': 'EVE-ROI*', 'value': '70.47', 'row': 8, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Head Pose Estimation', 'dataset': 'AFLW2000', 'metric': 'MAE', 'model': 'Hybrid Coarse-Fine', 'value': '5.395', 'row': 3, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Head Pose Estimation', 'dataset': 'BIWI', 'metric': 'MAE', 'model': 'Hybrid Coarse-Fine', 'value': '3.0174', 'row': 7, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Head Pose Estimation', 'dataset': 'AFLW', 'metric': 'MAE', 'model': 'Hybrid Coarse-Fine', 'value': '5.09', 'row': 5, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Gesture Recognition', 'dataset': 'CapgMyo DB-a', 'metric': 'Accuracy', 'model': '2SRNN', 'value': '97.1', 'row': 5, 'column': 1}, {'task': 'Gesture Recognition', 'dataset': 'CapgMyo DB-b', 'metric': 'Accuracy', 'model': '2SRNN', 'value': '97.1', 'row': 5, 'column': 2}, {'task': 'Gesture Recognition', 'dataset': 'CapgMyo DB-c', 'metric': 'Accuracy', 'model': '2SRNN', 'value': '96.8', 'row': 5, 'column': 3}, {'task': 'Gesture Recognition', 'dataset': 'Ninapro DB-1 12 gestures', 'metric': 'Accuracy', 'model': '2SRNN', 'value': '84.7', 'row': 5, 'column': 4}, {'task': 'Gesture Recognition', 'dataset': 'Ninapro DB-1 8 gestures', 'metric': 'Accuracy', 'model': '2SRNN', 'value': '90.7', 'row': 5, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'FALSR-A', 'value': '37.82', 'row': 12, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'FALSR-A', 'value': '33.55', 'row': 12, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'FALSR-A', 'value': '32.12', 'row': 12, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'FALSR-A', 'value': '31.93', 'row': 12, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2016 English-German', 'metric': 'BLEU', 'model': 'MLM pretraining for encoder and decoder', 'value': '26.4', 'row': 8, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'Accuracy', 'model': 'DynAE', 'value': '0.987', 'row': 20, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'DynAE', 'value': '0.964', 'row': 20, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'Accuracy', 'model': 'DynAE', 'value': '0.987', 'row': 20, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'DynAE', 'value': '0.963', 'row': 20, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'Accuracy', 'model': 'DynAE', 'value': '0.981', 'row': 20, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'DynAE', 'value': '0.948', 'row': 20, 'column': 6}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'Accuracy', 'model': 'DynAE', 'value': '0.591', 'row': 20, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'NMI', 'model': 'DynAE', 'value': '0.642', 'row': 20, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Age Estimation', 'dataset': 'UTKFace', 'metric': 'MAE', 'model': 'CORAL', 'value': '5.39', 'row': 13, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Age Estimation', 'dataset': 'MORPH Album2', 'metric': 'MAE', 'model': 'CORAL', 'value': '2.59', 'row': 4, 'column': 2}, {'task': 'Age Estimation', 'dataset': 'AFAD', 'metric': 'MAE', 'model': 'CORAL', 'value': '3.48', 'row': 4, 'column': 3}, {'task': 'Age Estimation', 'dataset': 'CACD', 'metric': 'MAE', 'model': 'CORAL', 'value': '5.35', 'row': 4, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Heart Segmentation', 'dataset': 'Multi-Modality Whole Heart Segmentation Challenge 2017', 'metric': 'Average Dice', 'model': 'SIFA', 'value': '73', 'row': 9, 'column': 7}, {'task': 'Heart Segmentation', 'dataset': 'Multi-Modality Whole Heart Segmentation Challenge 2017', 'metric': 'Average ASD', 'model': 'SIFA', 'value': '8.1', 'row': 9, 'column': 12}]}\n","{'index': 1, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'AUC', 'model': 'MKR', 'value': '0.917', 'row': 8, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'Accuracy', 'model': 'MKR', 'value': '84.3', 'row': 8, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': \"Children's Book Test Common noun\", 'metric': 'AUC', 'model': 'MKR', 'value': '0.7340000000000001', 'row': 8, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': \"Children's Book Test Common noun\", 'metric': 'Accuracy', 'model': 'MKR', 'value': '70.4', 'row': 8, 'column': 4}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Last.FM', 'metric': 'AUC', 'model': 'MKR', 'value': '0.797', 'row': 8, 'column': 5}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Last.FM', 'metric': 'Accuracy', 'model': 'MKR', 'value': '75.2', 'row': 8, 'column': 6}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Last.FM', 'metric': 'AUC', 'model': 'MKR', 'value': '0.6890000000000001', 'row': 8, 'column': 7}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Last.FM', 'metric': 'Accuracy', 'model': 'MKR', 'value': '64.5', 'row': 8, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'DeepFake Detection', 'dataset': 'FaceForensics', 'metric': 'DF', 'model': 'XceptionNet', 'value': '96.36', 'row': 7, 'column': 1}, {'task': 'DeepFake Detection', 'dataset': 'FaceForensics', 'metric': 'FSF', 'model': 'XceptionNet', 'value': '86.86', 'row': 7, 'column': 2}, {'task': 'DeepFake Detection', 'dataset': 'FaceForensics', 'metric': 'FS', 'model': 'XceptionNet', 'value': '90.29', 'row': 7, 'column': 3}, {'task': 'DeepFake Detection', 'dataset': 'FaceForensics', 'metric': 'NT', 'model': 'XceptionNet', 'value': '80.67', 'row': 7, 'column': 4}, {'task': 'DeepFake Detection', 'dataset': 'FaceForensics', 'metric': 'Real', 'model': 'XceptionNet', 'value': '52.4', 'row': 7, 'column': 5}, {'task': 'DeepFake Detection', 'dataset': 'FaceForensics', 'metric': 'Total Accuracy', 'model': 'XceptionNet', 'value': '70.1', 'row': 7, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Feature Selection', 'dataset': 'MNIST', 'metric': 'Accuracy', 'model': 'CAE', 'value': '90.6', 'row': 1, 'column': 8}, {'task': 'Feature Selection', 'dataset': 'Fashion-MNIST', 'metric': 'Accuracy', 'model': 'CAE', 'value': '67.7', 'row': 2, 'column': 8}, {'task': 'Feature Selection', 'dataset': 'Coil-20', 'metric': 'Accuracy', 'model': 'CAE', 'value': '58.6', 'row': 3, 'column': 8}, {'task': 'Feature Selection', 'dataset': 'Mice Protein', 'metric': 'Accuracy', 'model': 'CAE', 'value': '13.4', 'row': 4, 'column': 8}, {'task': 'Feature Selection', 'dataset': 'ISOLET', 'metric': 'Accuracy', 'model': 'CAE', 'value': '68.5', 'row': 5, 'column': 8}, {'task': 'Feature Selection', 'dataset': 'Activity', 'metric': 'Accuracy', 'model': 'CAE', 'value': '42', 'row': 6, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'FGVC Aircraft', 'metric': 'Accuracy', 'model': 'WS-DAN', 'value': '93.0', 'row': 12, 'column': 1}]}\n","{'index': 5, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'Stanford Cars', 'metric': 'Accuracy', 'model': 'WS-DAN', 'value': '94.5', 'row': 12, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '81.87', 'row': 7, 'column': 1}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '81.4', 'row': 7, 'column': 2}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '80.62', 'row': 7, 'column': 3}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '95.57', 'row': 16, 'column': 1}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '95.51', 'row': 16, 'column': 2}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '95.54', 'row': 16, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Chinese Named Entity Recognition', 'dataset': 'Weibo NER', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '67.68', 'row': 7, 'column': 1}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'Weibo NER', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '67.71', 'row': 7, 'column': 2}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'Weibo NER', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '67.6', 'row': 7, 'column': 3}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'Resume NER', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '96.62', 'row': 16, 'column': 1}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'Resume NER', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '96.48', 'row': 16, 'column': 2}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'Resume NER', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '96.54', 'row': 16, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Chinese Word Segmentation', 'dataset': 'PKU', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '97.1', 'row': 6, 'column': 1}, {'task': 'Chinese Word Segmentation', 'dataset': 'PKU', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '96.4', 'row': 6, 'column': 2}, {'task': 'Chinese Word Segmentation', 'dataset': 'PKU', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '96.7', 'row': 6, 'column': 3}, {'task': 'Chinese Word Segmentation', 'dataset': 'MSR', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '98.2', 'row': 14, 'column': 1}, {'task': 'Chinese Word Segmentation', 'dataset': 'MSR', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '98.3', 'row': 14, 'column': 2}, {'task': 'Chinese Word Segmentation', 'dataset': 'MSR', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '98.3', 'row': 14, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Chinese Word Segmentation', 'dataset': 'CITYU', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '97.9', 'row': 6, 'column': 1}, {'task': 'Chinese Word Segmentation', 'dataset': 'CITYU', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '98', 'row': 6, 'column': 2}, {'task': 'Chinese Word Segmentation', 'dataset': 'CITYU', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '97.9', 'row': 6, 'column': 3}, {'task': 'Chinese Word Segmentation', 'dataset': 'AS', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '96.6', 'row': 14, 'column': 1}, {'task': 'Chinese Word Segmentation', 'dataset': 'AS', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '96.8', 'row': 14, 'column': 2}, {'task': 'Chinese Word Segmentation', 'dataset': 'AS', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '96.7', 'row': 14, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '96.5', 'row': 8, 'column': 1}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '96.74', 'row': 8, 'column': 2}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '96.61', 'row': 8, 'column': 3}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB6', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '95.56', 'row': 17, 'column': 1}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB6', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '95.26', 'row': 17, 'column': 2}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB6', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '95.41', 'row': 17, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB9', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '93.49', 'row': 8, 'column': 1}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB9', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '92.84', 'row': 8, 'column': 2}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB9', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '93.15', 'row': 8, 'column': 3}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'UD1', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '96.19', 'row': 18, 'column': 1}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'UD1', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '96.1', 'row': 18, 'column': 2}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'UD1', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '96.14', 'row': 18, 'column': 3}]}\n","{'index': 7, 'records': [{'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '84.2', 'row': 6, 'column': 1}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '86.9', 'row': 6, 'column': 2}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '85.5', 'row': 6, 'column': 3}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'Accuracy', 'model': 'Glyce + BERT', 'value': '85.8', 'row': 6, 'column': 4}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI', 'metric': 'Accuracy', 'model': 'Glyce + BERT', 'value': '79.2', 'row': 14, 'column': 4}]}\n","{'index': 8, 'records': [{'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '86.8', 'row': 6, 'column': 1}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '91.2', 'row': 6, 'column': 2}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '88.8', 'row': 6, 'column': 3}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'Accuracy', 'model': 'Glyce + BERT', 'value': '0.887', 'row': 6, 'column': 4}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'Precision', 'model': 'Glyce + BERT', 'value': '81.1', 'row': 14, 'column': 1}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'Recall', 'model': 'Glyce + BERT', 'value': '85.8', 'row': 14, 'column': 2}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'F1', 'model': 'Glyce + BERT', 'value': '83.4', 'row': 14, 'column': 3}]}\n","{'index': 9, 'records': [{'task': 'Chinese Sentence Pair Classification', 'dataset': 'ChnSentiCorp', 'metric': 'Accuracy', 'model': 'Glyce + BERT', 'value': '95.9', 'row': 5, 'column': 1}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'Fudan corpus', 'metric': 'Accuracy', 'model': 'Glyce + BERT', 'value': '99.8', 'row': 5, 'column': 2}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'iFeng', 'metric': 'Accuracy', 'model': 'Glyce + BERT', 'value': '87.5', 'row': 5, 'column': 3}]}\n","{'index': 10, 'records': [{'task': 'Chinese Dependency Parsing', 'dataset': 'Chinese Pennbank', 'metric': 'UAS', 'model': 'Biaffine + Glyce', 'value': '90.2', 'row': 6, 'column': 1}, {'task': 'Chinese Dependency Parsing', 'dataset': 'Chinese Pennbank', 'metric': 'LAS', 'model': 'Biaffine + Glyce', 'value': '89', 'row': 6, 'column': 2}]}\n","{'index': 11, 'records': [{'task': 'Chinese Semantic Role Labeling', 'dataset': 'CoNLL-2009', 'metric': 'Precision', 'model': 'k-order pruning + Glyce', 'value': '85.4', 'row': 5, 'column': 1}, {'task': 'Chinese Semantic Role Labeling', 'dataset': 'CoNLL-2009', 'metric': 'Recall', 'model': 'k-order pruning + Glyce', 'value': '82.1', 'row': 5, 'column': 2}, {'task': 'Chinese Semantic Role Labeling', 'dataset': 'CoNLL-2009', 'metric': 'F1', 'model': 'k-order pruning + Glyce', 'value': '83.7', 'row': 5, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'DBLP', 'metric': 'AUC', 'model': 'Event2vec', 'value': '90.1', 'row': 1, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Douban', 'metric': 'AUC', 'model': 'Event2vec', 'value': '82.3', 'row': 1, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'IMDb', 'metric': 'AUC', 'model': 'Event2vec', 'value': '89.4', 'row': 1, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'Yelp', 'metric': 'AUC', 'model': 'Event2vec', 'value': '86.2', 'row': 1, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'EgoGesture', 'metric': 'Accuracy', 'model': 'ResNeXt-101', 'value': '94.03', 'row': 7, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'NVGesture', 'metric': 'Accuracy', 'model': 'ResNeXt-101', 'value': '83.82', 'row': 4, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'LightConv', 'value': '28.9', 'row': 7, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'LightConv', 'value': '43.1', 'row': 7, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'DynamicConv', 'value': '29.7', 'row': 8, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'DynamicConv', 'value': '43.2', 'row': 8, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Machine Translation', 'dataset': 'IWSLT2014 German-English', 'metric': 'BLEU score', 'model': 'LightConv', 'value': '34.8', 'row': 4, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT 2017 English-Chinese', 'metric': 'BLEU score', 'model': 'LightConv', 'value': '24.3', 'row': 4, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'IWSLT2014 German-English', 'metric': 'BLEU score', 'model': 'DynamicConv', 'value': '35.2', 'row': 5, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT 2017 English-Chinese', 'metric': 'BLEU score', 'model': 'DynamicConv', 'value': '24.4', 'row': 5, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Language Modelling', 'dataset': 'One Billion Word', 'metric': 'PPL', 'model': 'DynamicConv', 'value': '26.67', 'row': 5, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-1', 'model': 'LightConv', 'value': '39.52', 'row': 4, 'column': 2}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-2', 'model': 'LightConv', 'value': '15.97', 'row': 4, 'column': 3}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-L', 'model': 'LightConv', 'value': '36.51', 'row': 4, 'column': 4}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-1', 'model': 'DynamicConv', 'value': '39.84', 'row': 5, 'column': 2}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-2', 'model': 'DynamicConv', 'value': '16.25', 'row': 5, 'column': 3}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-L', 'model': 'DynamicConv', 'value': '36.73', 'row': 5, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Atari Games', 'dataset': \"Atari 2600 Montezuma's Revenge\", 'metric': 'Score', 'model': 'Go-Explore', 'value': '43763', 'row': 26, 'column': 1}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pitfall!', 'metric': 'Score', 'model': 'Go-Explore', 'value': '107363', 'row': 28, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'Evolved Transformer Base', 'value': '28.4', 'row': 1, 'column': 7}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'Evolved Transformer Big', 'value': '29.3', 'row': 2, 'column': 7}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'Evolved Transformer Base', 'value': '40.6', 'row': 4, 'column': 7}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'Evolved Transformer Big', 'value': '41.3', 'row': 5, 'column': 7}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-Czech', 'metric': 'BLEU score', 'model': 'Evolved Transformer Base', 'value': '27.6', 'row': 6, 'column': 7}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-Czech', 'metric': 'BLEU score', 'model': 'Evolved Transformer Big', 'value': '28.2', 'row': 7, 'column': 7}, {'task': 'Language Modelling', 'dataset': 'One Billion Word', 'metric': 'PPL', 'model': 'Evolved Transformer Big', 'value': '28.6', 'row': 8, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'Evolved Transformer', 'value': '29.8', 'row': 8, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'SacreBLEU', 'model': 'Evolved Transformer', 'value': '29.2', 'row': 8, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Iris Segmentation', 'dataset': 'CASIA', 'metric': 'F1', 'model': 'IrisParseNet (ASPP) CASIA', 'value': '94.30', 'row': 11, 'column': 4}, {'task': 'Iris Segmentation', 'dataset': 'CASIA', 'metric': 'mIoU', 'model': 'IrisParseNet (ASPP) CASIA', 'value': '89.4', 'row': 11, 'column': 6}, {'task': 'Iris Segmentation', 'dataset': 'UBIRIS', 'metric': 'F1', 'model': 'IrisParseNet (ASPP)', 'value': '91.82', 'row': 12, 'column': 4}, {'task': 'Iris Segmentation', 'dataset': 'UBIRIS', 'metric': 'mIoU', 'model': 'IrisParseNet (ASPP)', 'value': '85.39', 'row': 12, 'column': 6}, {'task': 'Iris Segmentation', 'dataset': 'MICHE', 'metric': 'F1', 'model': 'IrisParseNet (PSP)', 'value': '91.5', 'row': 16, 'column': 4}, {'task': 'Iris Segmentation', 'dataset': 'MICHE', 'metric': 'mIoU', 'model': 'IrisParseNet (PSP)', 'value': '85.07', 'row': 16, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Hanzi', 'metric': 'PSNR', 'model': 'DnCNN (n2t)', 'value': '13.9', 'row': 9, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'ImageNet', 'metric': 'PSNR', 'model': 'DnCNN (n2t)', 'value': '22', 'row': 9, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'CellNet', 'metric': 'PSNR', 'model': 'DnCNN (n2t)', 'value': '34.4', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'MT-DNN', 'value': '95.6', 'row': 6, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'BLOCK', 'value': '67.58', 'row': 10, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'BLOCK', 'value': '67.92', 'row': 10, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Visual Relationship Detection', 'dataset': 'VRD Predicate Detection', 'metric': 'R@50', 'model': 'BLOCK', 'value': '86.58', 'row': 10, 'column': 2}, {'task': 'Visual Relationship Detection', 'dataset': 'VRD Predicate Detection', 'metric': 'R@100', 'model': 'BLOCK', 'value': '92.58', 'row': 10, 'column': 3}, {'task': 'Visual Relationship Detection', 'dataset': 'VRD Phrase Detection', 'metric': 'R@50', 'model': 'BLOCK', 'value': '26.32', 'row': 10, 'column': 4}, {'task': 'Visual Relationship Detection', 'dataset': 'VRD Phrase Detection', 'metric': 'R@100', 'model': 'BLOCK', 'value': '28.96', 'row': 10, 'column': 5}, {'task': 'Visual Relationship Detection', 'dataset': 'VRD Relationship Detection', 'metric': 'R@50', 'model': 'BLOCK', 'value': '19.06', 'row': 10, 'column': 6}, {'task': 'Visual Relationship Detection', 'dataset': 'VRD Relationship Detection', 'metric': 'R@100', 'model': 'BLOCK', 'value': '20.96', 'row': 10, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Hyperspectral Image Denoising', 'dataset': 'HYDICE DC Mall', 'metric': 'MPSNR', 'model': 'Deep HS (prior 3D)', 'value': '23.24', 'row': 3, 'column': 6}, {'task': 'Hyperspectral Image Denoising', 'dataset': 'HYDICE DC Mall', 'metric': 'MSSIM', 'model': 'Deep HS (prior 3D)', 'value': '0.852', 'row': 4, 'column': 6}, {'task': 'Hyperspectral Image Denoising', 'dataset': 'HYDICE DC Mall', 'metric': 'SAM', 'model': 'Deep HS (prior 3D)', 'value': '9.91', 'row': 5, 'column': 6}, {'task': 'Hyperspectral Image Inpainting', 'dataset': 'Indian Pines', 'metric': 'MPSNR', 'model': 'Deep HS (prior 3D)', 'value': '35.34', 'row': 9, 'column': 6}, {'task': 'Hyperspectral Image Inpainting', 'dataset': 'Indian Pines', 'metric': 'MSSIM', 'model': 'Deep HS (prior 3D)', 'value': '0.966', 'row': 10, 'column': 6}, {'task': 'Hyperspectral Image Inpainting', 'dataset': 'Indian Pines', 'metric': 'SAM', 'model': 'Deep HS (prior 3D)', 'value': '1.133', 'row': 11, 'column': 6}, {'task': 'Hyperspectral Image Super-Resolution', 'dataset': 'ROSIS-03', 'metric': 'MPSNR', 'model': 'Deep HS (prior 3D)', 'value': '32.31', 'row': 15, 'column': 6}, {'task': 'Hyperspectral Image Super-Resolution', 'dataset': 'ROSIS-03', 'metric': 'MSSIM', 'model': 'Deep HS (prior 3D)', 'value': '0.945', 'row': 16, 'column': 6}, {'task': 'Hyperspectral Image Super-Resolution', 'dataset': 'ROSIS-03', 'metric': 'SAM', 'model': 'Deep HS (prior 3D)', 'value': '4.692', 'row': 17, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'FER2013', 'metric': 'Accuracy', 'model': 'DeepEmotion', 'value': '70.02', 'row': 5, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'FERG', 'metric': 'Accuracy', 'model': 'DeepEmotion', 'value': '99.3', 'row': 4, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'JAFFE', 'metric': 'Accuracy', 'model': 'DeepEmotion', 'value': '92.8', 'row': 4, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'CK+', 'metric': 'Accuracy (10-fold)', 'model': 'DeepEmotion', 'value': '98', 'row': 9, 'column': 1}]}\n","{'index': 3, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'T-LESS', 'metric': 'Mean Recall', 'model': 'Augmented Autoencoder', 'value': '36.79', 'row': 33, 'column': 7}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'T-LESS', 'metric': 'Mean Recall', 'model': 'Augmented Autoencoder', 'value': '72.76', 'row': 33, 'column': 8}]}\n","{'index': 4, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'Augmented Autoencoder', 'value': '28.65', 'row': 16, 'column': 2}, {'task': '6D Pose Estimation using RGBD', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'Augmented Autoencoder', 'value': '64.67', 'row': 16, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (No Gen) fixed', 'metric': 'Score', 'model': 'PPO', 'value': '5', 'row': 1, 'column': 1}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (No Gen) varied', 'metric': 'Score', 'model': 'PPO', 'value': '1', 'row': 1, 'column': 2}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (No Gen) fixed', 'metric': 'Score', 'model': 'RNB', 'value': '7', 'row': 1, 'column': 3}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (No Gen) varied', 'metric': 'Score', 'model': 'RNB', 'value': '4.8', 'row': 1, 'column': 4}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Weak Gen) fixed', 'metric': 'Score', 'model': 'PPO', 'value': '1.2', 'row': 2, 'column': 1}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Weak Gen) varied', 'metric': 'Score', 'model': 'PPO', 'value': '0.8', 'row': 2, 'column': 2}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Weak Gen) fixed', 'metric': 'Score', 'model': 'RNB', 'value': '1', 'row': 2, 'column': 3}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Weak Gen) varied', 'metric': 'Score', 'model': 'RNB', 'value': '3.4', 'row': 2, 'column': 4}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Strong Gen) fixed', 'metric': 'Score', 'model': 'PPO', 'value': '0.6', 'row': 3, 'column': 1}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Strong Gen) varied', 'metric': 'Score', 'model': 'PPO', 'value': '0.6', 'row': 3, 'column': 2}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Strong Gen) fixed', 'metric': 'Score', 'model': 'RNB', 'value': '0.6', 'row': 3, 'column': 3}, {'task': 'General Reinforcement Learning', 'dataset': 'Obstacle Tower (Strong Gen) varied', 'metric': 'Score', 'model': 'RNB', 'value': '0.8', 'row': 3, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Face Alignment', 'dataset': '300W', 'metric': 'Fullset (public)', 'model': '3DDE (Inter-pupil Norm)', 'value': '4.39', 'row': 22, 'column': 5}, {'task': 'Face Alignment', 'dataset': '300W', 'metric': 'Fullset (public)', 'model': '3DDE (Inter-ocular Norm)', 'value': '3.13', 'row': 22, 'column': 6}, {'task': 'Facial Landmark Detection', 'dataset': '300W', 'metric': 'NME', 'model': '3DDE (Inter-ocular Norm)', 'value': '3.13', 'row': 22, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Face Alignment', 'dataset': 'COFW', 'metric': 'Mean Error Rate', 'model': '3DDE (Inter-pupil Norm)', 'value': '5.11', 'row': 10, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Face Alignment', 'dataset': 'WFLW', 'metric': 'ME (%, all) ', 'model': '3DDE (Inter-ocular Norm)', 'value': '4.68', 'row': 7, 'column': 1}, {'task': 'Face Alignment', 'dataset': 'WFLW', 'metric': 'AUC@0.1 (all)', 'model': '3DDE (Inter-ocular Norm)', 'value': '0.5544', 'row': 7, 'column': 2}, {'task': 'Face Alignment', 'dataset': 'WFLW', 'metric': 'FR@0.1(%, all)', 'model': '3DDE (Inter-ocular Norm)', 'value': '5.04', 'row': 7, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'APL', 'value': '97.9', 'row': 7, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'APL', 'value': '99.9', 'row': 7, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'APL', 'value': '97.2', 'row': 7, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'APL', 'value': '97.6', 'row': 7, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 423 way', 'metric': 'Accuracy', 'model': 'APL', 'value': '73.5', 'row': 7, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 423 way', 'metric': 'Accuracy', 'model': 'APL', 'value': '88', 'row': 7, 'column': 6}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 1000 way', 'metric': 'Accuracy', 'model': 'APL', 'value': '68.9', 'row': 7, 'column': 7}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 1000 way', 'metric': 'Accuracy', 'model': 'APL', 'value': '78.9', 'row': 7, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'VRGC', 'value': '86.3', 'row': 9, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'VRGC', 'value': '48.4', 'row': 9, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'VRGC', 'value': '74.8', 'row': 9, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'VRGC', 'value': '80.7', 'row': 9, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'OTB-2013', 'metric': 'AUC', 'model': 'SiamVGG', 'value': '0.665', 'row': 7, 'column': 1}, {'task': 'Visual Object Tracking', 'dataset': 'OTB-50', 'metric': 'AUC', 'model': 'SiamVGG', 'value': '0.61', 'row': 7, 'column': 2}, {'task': 'Visual Object Tracking', 'dataset': 'OTB-100', 'metric': 'AUC', 'model': 'SiamVGG', 'value': '0.654', 'row': 7, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Crop Yield Prediction', 'dataset': '2018 Syngenta (2016 val)', 'metric': 'RMSE', 'model': 'DNN', 'value': '12.79', 'row': 1, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '99.97', 'row': 8, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '99.89', 'row': 8, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '88', 'row': 8, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '99.65', 'row': 8, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '54.9', 'row': 10, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '55.73', 'row': 10, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '69.46', 'row': 10, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MC2+', 'value': '70.33', 'row': 10, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Trajectory Prediction', 'dataset': 'ActEV', 'metric': 'ADE-8/12', 'model': 'Next', 'value': '17.99', 'row': 6, 'column': 2}, {'task': 'Trajectory Prediction', 'dataset': 'ActEV', 'metric': 'FDE-8/12', 'model': 'Next', 'value': '37.24', 'row': 6, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Activity Prediction', 'dataset': 'ActEV', 'metric': 'mAP', 'model': 'Next', 'value': '0.192', 'row': 1, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Trajectory Prediction', 'dataset': 'ETH/UCY', 'metric': 'ADE-8/12', 'model': 'Next', 'value': '0.46', 'row': 8, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'YOLOv3 (sync. BN + rand. shapes + cos. lr + lbl. smoothing + mixup)', 'value': '83.68', 'row': 7, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'Faster-RCNN (cos. lr, label smoothing, mixup)', 'value': '81.32', 'row': 5, 'column': 1}]}\n","{'index': 0, 'records': [{'task': '3D Instance Segmentation', 'dataset': 'ScanNet', 'metric': 'mAP', 'model': 'MASC', 'value': '0.447', 'row': 4, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'Fast-SCNN', 'value': '68', 'row': 10, 'column': 1}]}\n","{'index': 5, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes val', 'metric': 'mIoU', 'model': 'Fast-SCNN + Coarse + ImageNet', 'value': '69.19', 'row': 5, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Depth Completion', 'dataset': 'KITTI Depth Completion', 'metric': 'RMSE', 'model': 'FusionNet', 'value': '773.0', 'row': 12, 'column': 2}, {'task': 'Depth Completion', 'dataset': 'KITTI Depth Completion', 'metric': 'MAE', 'model': 'FusionNet', 'value': '215', 'row': 12, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain ResNet-50 (AutoAugment, 224px)', 'value': '78.2', 'row': 5, 'column': 5}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain ResNet-50 (AutoAugment, 500px)', 'value': '79.4', 'row': 7, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Image Retrieval', 'dataset': 'INRIA Holidays', 'metric': 'Mean mAP', 'model': 'MultiGrain R50 @ 500', 'value': '91.8', 'row': 1, 'column': 2}, {'task': 'Image Retrieval', 'dataset': 'INRIA Holidays', 'metric': 'Mean mAP', 'model': 'MultiGrain R50 @ 800', 'value': '92.5', 'row': 4, 'column': 2}]}\n","{'index': 7, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain NASNet-A-Mobile (350px)', 'value': '75.1', 'row': 2, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain SENet154 (350px)', 'value': '82.6', 'row': 3, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain SENet154 (350px)', 'value': '83', 'row': 3, 'column': 6}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain SENet154 (450px)', 'value': '83.1', 'row': 3, 'column': 8}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain SENet154 (500px)', 'value': '82.7', 'row': 3, 'column': 10}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain PNASNet (300px)', 'value': '81.3', 'row': 4, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain PNASNet (400px)', 'value': '82.6', 'row': 4, 'column': 6}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain PNASNet (450px)', 'value': '83.2', 'row': 4, 'column': 8}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MultiGrain PNASNet (500px)', 'value': '83.6', 'row': 4, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '37.66', 'row': 8, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'SSIM', 'model': 'LFFN-S', 'value': '0.9585', 'row': 8, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '37.93', 'row': 8, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'SSIM', 'model': 'LFFN-S', 'value': '0.9746', 'row': 8, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '31.96', 'row': 8, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '34.04', 'row': 15, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'SSIM', 'model': 'LFFN-S', 'value': '0.9233', 'row': 15, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '32.8', 'row': 15, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'SSIM', 'model': 'LFFN-S', 'value': '0.9381', 'row': 15, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '28.91', 'row': 15, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '31.79', 'row': 22, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'LFFN-S', 'value': '0.8886', 'row': 22, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '29.76', 'row': 22, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'LFFN-S', 'value': '0.8979', 'row': 22, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'LFFN-S', 'value': '27.42', 'row': 22, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Frappe', 'metric': 'Recall@10', 'model': 'RATE-CSE', 'value': '33.47', 'row': 12, 'column': 1}, {'task': 'Recommendation Systems', 'dataset': 'Frappe', 'metric': 'mAP@10', 'model': 'RATE-CSE', 'value': '0.2047', 'row': 12, 'column': 2}, {'task': 'Recommendation Systems', 'dataset': 'CiteULike', 'metric': 'Recall@10', 'model': 'RATE-CSE', 'value': '0.2362', 'row': 12, 'column': 3}, {'task': 'Recommendation Systems', 'dataset': 'CiteULike', 'metric': 'mAP@10', 'model': 'RATE-CSE', 'value': '0.1452', 'row': 12, 'column': 4}, {'task': 'Recommendation Systems', 'dataset': 'Netflix', 'metric': 'Recall@10', 'model': 'RATE-CSE', 'value': '0.2014', 'row': 12, 'column': 5}, {'task': 'Recommendation Systems', 'dataset': 'Netflix', 'metric': 'mAP@10', 'model': 'RATE-CSE', 'value': '0.1039', 'row': 12, 'column': 6}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens-Latest', 'metric': 'Recall@10', 'model': 'RATE-CSE', 'value': '0.3225', 'row': 12, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens-Latest', 'metric': 'mAP@10', 'model': 'RATE-CSE', 'value': '0.199', 'row': 12, 'column': 8}]}\n","{'index': 2, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Last.FM-360k', 'metric': 'Recall@10', 'model': 'RANK-CSE', 'value': '0.1762', 'row': 11, 'column': 1}, {'task': 'Recommendation Systems', 'dataset': 'Last.FM-360k', 'metric': 'mAP@10', 'model': 'RANK-CSE', 'value': '0.097', 'row': 11, 'column': 2}, {'task': 'Recommendation Systems', 'dataset': 'Amazon-Book', 'metric': 'Recall@10', 'model': 'RANK-CSE', 'value': '0.0625', 'row': 11, 'column': 3}, {'task': 'Recommendation Systems', 'dataset': 'Amazon-Book', 'metric': 'mAP@10', 'model': 'RANK-CSE', 'value': '0.0274', 'row': 11, 'column': 4}, {'task': 'Recommendation Systems', 'dataset': 'Epinions-Extend', 'metric': 'Recall@10', 'model': 'RANK-CSE', 'value': '0.1767', 'row': 11, 'column': 5}, {'task': 'Recommendation Systems', 'dataset': 'Epinions-Extend', 'metric': 'mAP@10', 'model': 'RANK-CSE', 'value': '0.0921', 'row': 11, 'column': 6}, {'task': 'Recommendation Systems', 'dataset': 'Echonest', 'metric': 'Recall@10', 'model': 'RANK-CSE', 'value': '0.1358', 'row': 11, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'Echonest', 'metric': 'mAP@10', 'model': 'RANK-CSE', 'value': '0.0679', 'row': 11, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'MovieLens 1M', 'metric': 'HR@10', 'model': 'KTUP (soft)', 'value': '0.8903', 'row': 11, 'column': 4}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 1M', 'metric': 'NDCG', 'model': 'KTUP (soft)', 'value': '0.6992', 'row': 11, 'column': 5}, {'task': 'Recommendation Systems', 'dataset': 'DBbook2014', 'metric': 'HR@10', 'model': 'KTUP (soft)', 'value': '0.3461', 'row': 11, 'column': 9}, {'task': 'Recommendation Systems', 'dataset': 'DBbook2014', 'metric': 'NDCG', 'model': 'KTUP (soft)', 'value': '0.2762', 'row': 11, 'column': 10}]}\n","{'index': 3, 'records': [{'task': 'Knowledge Graph Completion', 'dataset': 'MovieLens 1M', 'metric': 'Hits@10', 'model': 'KTUP (soft)', 'value': '48.9', 'row': 10, 'column': 1}, {'task': 'Knowledge Graph Completion', 'dataset': 'MovieLens 1M', 'metric': 'Mean Rank', 'model': 'KTUP (soft)', 'value': '527', 'row': 10, 'column': 2}, {'task': 'Knowledge Graph Completion', 'dataset': 'DBbook2014', 'metric': 'Hits@10', 'model': 'KTUP (soft)', 'value': '60.75', 'row': 10, 'column': 3}, {'task': 'Knowledge Graph Completion', 'dataset': 'DBbook2014', 'metric': 'Mean Rank', 'model': 'KTUP (soft)', 'value': '499', 'row': 10, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'DBLP', 'metric': 'AUC', 'model': 'HSRL (DW)', 'value': '84.7', 'row': 4, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'MIT', 'metric': 'AUC', 'model': 'HSRL (DW)', 'value': '92.6', 'row': 4, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'Yelp', 'metric': 'AUC', 'model': 'HSRL (DW)', 'value': '90.1', 'row': 4, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'Douban', 'metric': 'AUC', 'model': 'HSRL (DW)', 'value': '84.2', 'row': 4, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'AM3-TADAM', 'value': '65.30', 'row': 27, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'AM3-TADAM', 'value': '78.10', 'row': 27, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (10-shot)', 'metric': 'Accuracy', 'model': 'AM3-TADAM', 'value': '81.57', 'row': 27, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'AM3-TADAM', 'value': '69.08', 'row': 20, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'AM3-TADAM', 'value': '82.58', 'row': 20, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Text Classification', 'dataset': 'R8', 'metric': 'Accuracy', 'model': 'SGCN', 'value': '97.2', 'row': 4, 'column': 2}, {'task': 'Text Classification', 'dataset': 'R52', 'metric': 'Accuracy', 'model': 'SGCN', 'value': '94.0', 'row': 6, 'column': 2}, {'task': 'Text Classification', 'dataset': 'Ohsumed', 'metric': 'Accuracy', 'model': 'SGCN', 'value': '68.5', 'row': 8, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Node Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'GraphVAT', 'value': '73.7', 'row': 7, 'column': 2}, {'task': 'Node Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'GraphVAT', 'value': '82.6', 'row': 7, 'column': 3}, {'task': 'Node Classification', 'dataset': 'NELL', 'metric': 'Accuracy', 'model': 'GraphVAT', 'value': '64.7', 'row': 7, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '88.9', 'row': 12, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '69', 'row': 12, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '74.1', 'row': 12, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '65.9', 'row': 12, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '58.04', 'row': 12, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '74.86', 'row': 12, 'column': 6}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'BC + Capsules', 'value': '27', 'row': 12, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'CK+', 'metric': 'Accuracy (10-fold)', 'model': 'Facial Motion Prior Network', 'value': '98.06', 'row': 10, 'column': 2}, {'task': 'Facial Expression Recognition', 'dataset': 'MMI', 'metric': 'Accuracy', 'model': 'Facial Motion Prior Network', 'value': '82.74', 'row': 10, 'column': 3}, {'task': 'Facial Expression Recognition', 'dataset': 'AffectNet', 'metric': 'Accuracy', 'model': 'Facial Motion Prior Network', 'value': '61.52', 'row': 10, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'F1', 'model': 'VLAWE', 'value': '89.3', 'row': 27, 'column': 1}, {'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'VLAWE', 'value': '5.8', 'row': 27, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'HRNet-W48 + extra data', 'value': '77', 'row': 18, 'column': 5}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'HRNet-W48 + extra data', 'value': '92.7', 'row': 18, 'column': 6}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'HRNet-W48 + extra data', 'value': '84.5', 'row': 18, 'column': 7}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'HRNet-W48 + extra data', 'value': '73.4', 'row': 18, 'column': 8}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'HRNet-W48 + extra data', 'value': '83.1', 'row': 18, 'column': 9}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'HRNet-W48 + extra data', 'value': '82', 'row': 18, 'column': 10}]}\n","{'index': 2, 'records': [{'task': 'Pose Estimation', 'dataset': 'MPII Human Pose', 'metric': 'PCKh-0.5', 'model': 'HRNet-W32', 'value': '92.3', 'row': 16, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Pose Tracking', 'dataset': 'PoseTrack2017', 'metric': 'MAP', 'model': 'HRNet-W48 COCO', 'value': '74.9', 'row': 12, 'column': 2}, {'task': 'Pose Tracking', 'dataset': 'PoseTrack2017', 'metric': 'MOTA', 'model': 'HRNet-W48 COCO', 'value': '57.9', 'row': 12, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'Twitter', 'metric': 'Accuracy', 'model': 'AEN-GloVe', 'value': '72.83', 'row': 13, 'column': 2}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Sub Task 2', 'metric': 'Restaurant (Acc)', 'model': 'AEN-GloVe', 'value': '80.98', 'row': 13, 'column': 4}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Sub Task 2', 'metric': 'Laptop (Acc)', 'model': 'AEN-GloVe', 'value': '73.51', 'row': 13, 'column': 6}, {'task': 'Sentiment Analysis', 'dataset': 'Twitter', 'metric': 'Accuracy', 'model': 'BERT-SPC', 'value': '73.55', 'row': 14, 'column': 2}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Sub Task 2', 'metric': 'Restaurant (Acc)', 'model': 'BERT-SPC', 'value': '84.46', 'row': 14, 'column': 4}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Sub Task 2', 'metric': 'Laptop (Acc)', 'model': 'BERT-SPC', 'value': '78.99', 'row': 14, 'column': 6}, {'task': 'Sentiment Analysis', 'dataset': 'Twitter', 'metric': 'Accuracy', 'model': 'AEN-BERT', 'value': '74.71', 'row': 15, 'column': 2}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Sub Task 2', 'metric': 'Restaurant (Acc)', 'model': 'AEN-BERT', 'value': '83.12', 'row': 15, 'column': 4}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Sub Task 2', 'metric': 'Laptop (Acc)', 'model': 'AEN-BERT', 'value': '79.93', 'row': 15, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Douban', 'metric': 'Recall@20', 'model': 'DGRec', 'value': '0.1861', 'row': 9, 'column': 2}, {'task': 'Recommendation Systems', 'dataset': 'Douban', 'metric': 'NDCG', 'model': 'DGRec', 'value': '0.195', 'row': 9, 'column': 3}, {'task': 'Recommendation Systems', 'dataset': 'Delicious', 'metric': 'Recall@20', 'model': 'DGRec', 'value': '0.4066', 'row': 9, 'column': 4}, {'task': 'Recommendation Systems', 'dataset': 'Delicious', 'metric': 'NDCG', 'model': 'DGRec', 'value': '0.2944', 'row': 9, 'column': 5}, {'task': 'Recommendation Systems', 'dataset': 'Yelp', 'metric': 'Recall@20', 'model': 'DGRec', 'value': '0.0842', 'row': 9, 'column': 6}, {'task': 'Recommendation Systems', 'dataset': 'Yelp', 'metric': 'NDCG', 'model': 'DGRec', 'value': '0.1427', 'row': 9, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'NDCG', 'model': 'DAN', 'value': '57.59', 'row': 11, 'column': 1}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'MRR', 'model': 'DAN', 'value': '63.2', 'row': 11, 'column': 2}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@1', 'model': 'DAN', 'value': '49.63', 'row': 11, 'column': 3}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@5', 'model': 'DAN', 'value': '79.75', 'row': 11, 'column': 4}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@10', 'model': 'DAN', 'value': '89.35', 'row': 11, 'column': 5}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'Mean Rank', 'model': 'DAN', 'value': '4.3', 'row': 11, 'column': 6}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'MRR', 'model': 'DAN', 'value': '66.38', 'row': 11, 'column': 7}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@1', 'model': 'DAN', 'value': '53.33', 'row': 11, 'column': 8}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@5', 'model': 'DAN', 'value': '82.42', 'row': 11, 'column': 9}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@10', 'model': 'DAN', 'value': '90.38', 'row': 11, 'column': 10}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'Mean Rank', 'model': 'DAN', 'value': '4.04', 'row': 11, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Brain Image Segmentation', 'dataset': 'T1-weighted MRI', 'metric': 'Dice Score', 'model': 'Learned Transformations (random augmentaiton)', 'value': '81.5', 'row': 6, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'MuRel', 'value': '68.03', 'row': 16, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'MuRel', 'value': '68.41', 'row': 16, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Visual Question Answering', 'dataset': 'TDIUC', 'metric': 'Accuracy', 'model': 'Accuracy', 'value': '88.2', 'row': 17, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA-CP', 'metric': 'Score', 'model': 'MuRel', 'value': '39.54', 'row': 5, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'GQA test-std', 'metric': 'Accuracy', 'model': 'CNN+LSTM', 'value': '46.55', 'row': 18, 'column': 5}, {'task': 'Visual Question Answering', 'dataset': 'GQA test-std', 'metric': 'Accuracy', 'model': 'MAC', 'value': '54.06', 'row': 18, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Frappe', 'metric': 'RMSE', 'model': 'INN', 'value': '0.3071', 'row': 9, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Plane Instance Segmentation', 'dataset': 'NYU Depth v2', 'metric': 'RI', 'model': 'Associative Embeddings', 'value': '0.888', 'row': 3, 'column': 1}, {'task': 'Plane Instance Segmentation', 'dataset': 'NYU Depth v2', 'metric': 'VI', 'model': 'Associative Embeddings', 'value': '1.38', 'row': 3, 'column': 2}, {'task': 'Plane Instance Segmentation', 'dataset': 'NYU Depth v2', 'metric': 'SC', 'model': 'Associative Embeddings', 'value': '0.519', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mPrec', 'model': 'ASIS (PN++)', 'value': '63.6', 'row': 12, 'column': 4}, {'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mRec', 'model': 'ASIS (PN++)', 'value': '47.5', 'row': 12, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'S3DIS', 'metric': 'Mean IoU', 'model': 'ASIS', 'value': '59.3', 'row': 13, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'MR', 'model': 'RotatE', 'value': '309.0', 'row': 8, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MR', 'model': 'RotatE', 'value': '177.0', 'row': 7, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Text Classification', 'dataset': 'ODIC 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Induction Networks', 'value': '87.16', 'row': 7, 'column': 1}, {'task': 'Few-Shot Text Classification', 'dataset': 'ODIC 5-way (10-shot)', 'metric': 'Accuracy', 'model': 'Induction Networks', 'value': '88.49', 'row': 7, 'column': 2}, {'task': 'Few-Shot Text Classification', 'dataset': 'ODIC 10-way (5-shot)', 'metric': 'Accuracy', 'model': 'Induction Networks', 'value': '78.27', 'row': 7, 'column': 3}, {'task': 'Few-Shot Text Classification', 'dataset': 'ODIC 10-way (10-shot)', 'metric': 'Accuracy', 'model': 'Induction Networks', 'value': '81.64', 'row': 7, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'Graph-RISE (40M)', 'value': '68.29', 'row': 6, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'Graph-RISE (40M)', 'value': '87.75', 'row': 6, 'column': 2}, {'task': 'Image Classification', 'dataset': 'iNaturalist', 'metric': 'Top 1 Accuracy', 'model': 'Graph-RISE (40M)', 'value': '31.12', 'row': 6, 'column': 3}, {'task': 'Image Classification', 'dataset': 'iNaturalist', 'metric': 'Top 5 Accuracy', 'model': 'Graph-RISE (40M)', 'value': '52.76', 'row': 6, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Grammatical Error Correction', 'dataset': 'CoNLL-2014 Shared Task', 'metric': 'Precision', 'model': 'Copy-augmented Model (4 Ensemble +Denoising Autoencoder)', 'value': '71.57', 'row': 11, 'column': 2}, {'task': 'Grammatical Error Correction', 'dataset': 'CoNLL-2014 Shared Task', 'metric': 'Recall', 'model': 'Copy-augmented Model (4 Ensemble +Denoising Autoencoder)', 'value': '38.65', 'row': 11, 'column': 3}, {'task': 'Grammatical Error Correction', 'dataset': 'CoNLL-2014 Shared Task', 'metric': 'F0.5', 'model': 'Copy-augmented Model (4 Ensemble +Denoising Autoencoder)', 'value': '61.15', 'row': 11, 'column': 4}, {'task': 'Grammatical Error Correction', 'dataset': 'JFLEG', 'metric': 'GLEU', 'model': 'Copy-augmented Model (4 Ensemble +Denoising Autoencoder)', 'value': '61', 'row': 11, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '56.3', 'row': 18, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'MAP', 'model': 'UTAL', 'value': '42.3', 'row': 18, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '69.2', 'row': 18, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'UTAL', 'value': '46.2', 'row': 18, 'column': 4}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '62.3', 'row': 18, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'UTAL', 'value': '44.6', 'row': 18, 'column': 6}, {'task': 'Person Re-Identification', 'dataset': 'MSMT17', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '31.4', 'row': 18, 'column': 7}, {'task': 'Person Re-Identification', 'dataset': 'MSMT17', 'metric': 'mAP', 'model': 'UTAL', 'value': '13.1', 'row': 18, 'column': 8}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'PRID2011', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '54.7', 'row': 11, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'PRID2011', 'metric': 'Rank-5', 'model': 'UTAL', 'value': '83.1', 'row': 11, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'PRID2011', 'metric': 'Rank-20', 'model': 'UTAL', 'value': '96.2', 'row': 11, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '35.1', 'row': 11, 'column': 4}, {'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-5', 'model': 'UTAL', 'value': '59', 'row': 11, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-20', 'model': 'UTAL', 'value': '83.8', 'row': 11, 'column': 6}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '49.9', 'row': 11, 'column': 7}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-10', 'model': 'UTAL', 'value': '66.4', 'row': 11, 'column': 8}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-20', 'model': 'UTAL', 'value': '77.8', 'row': 11, 'column': 9}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'mAP', 'model': 'UTAL', 'value': '35.2', 'row': 11, 'column': 10}, {'task': 'Person Re-Identification', 'dataset': 'DukeTracklet', 'metric': 'Rank-1', 'model': 'UTAL', 'value': '43.8', 'row': 11, 'column': 11}, {'task': 'Person Re-Identification', 'dataset': 'DukeTracklet', 'metric': 'Rank-5', 'model': 'UTAL', 'value': '62.8', 'row': 11, 'column': 12}, {'task': 'Person Re-Identification', 'dataset': 'DukeTracklet', 'metric': 'Rank-20', 'model': 'UTAL', 'value': '76.5', 'row': 11, 'column': 13}, {'task': 'Person Re-Identification', 'dataset': 'DukeTracklet', 'metric': 'mAP', 'model': 'UTAL', 'value': '36.6', 'row': 11, 'column': 14}]}\n","{'index': 2, 'records': [{'task': 'Traffic Accident Detection', 'dataset': 'A3D', 'metric': 'AUC', 'model': 'FOL-MaxSTD (pred only)', 'value': '60.1', 'row': 9, 'column': 1}, {'task': 'Traffic Accident Detection', 'dataset': 'SA', 'metric': 'AUC', 'model': 'FOL-MaxSTD (pred only)', 'value': '55.6', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'FSAF (ResNet-50)', 'value': '35.9', 'row': 4, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'FSAF (ResNet-50)', 'value': '55.0', 'row': 4, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'FSAF (ResNet-50)', 'value': '37.9', 'row': 4, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'FSAF (ResNet-50)', 'value': '19.8', 'row': 4, 'column': 7}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'FSAF (ResNet-50)', 'value': '39.6', 'row': 4, 'column': 8}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'FSAF (ResNet-50)', 'value': '48.2', 'row': 4, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'FSAF (ResNet-101)', 'value': '37.9', 'row': 5, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'FSAF (ResNet-101)', 'value': '58.0', 'row': 5, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'FSAF (ResNet-101, anchor-based branches)', 'value': '39.3', 'row': 6, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'FSAF (ResNet-101, anchor-based branches)', 'value': '59.2', 'row': 6, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'FSAF (ResNeXt-101, anchor-based branches)', 'value': '41.6', 'row': 9, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'FSAF (ResNeXt-101, anchor-based branches)', 'value': '62.4', 'row': 9, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'FSAF (ResNet-101, single-scale)', 'value': '40.9', 'row': 9, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'FSAF (ResNet-101, single-scale)', 'value': '61.5', 'row': 19, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'FSAF (ResNet-101, single-scale)', 'value': '44.0', 'row': 19, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'FSAF (ResNet-101, single-scale)', 'value': '24.0', 'row': 19, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'FSAF (ResNet-101, single-scale)', 'value': '44.2', 'row': 19, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'FSAF (ResNet-101, single-scale)', 'value': '51.3', 'row': 19, 'column': 7}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'FSAF (ResNeXt-101, multi-scale)', 'value': '44.6', 'row': 25, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'FSAF (ResNeXt-101, multi-scale)', 'value': '65.2', 'row': 25, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'FSAF (ResNeXt-101, multi-scale)', 'value': '48.6', 'row': 25, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'FSAF (ResNeXt-101, multi-scale)', 'value': '29.7', 'row': 25, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'FSAF (ResNeXt-101, multi-scale)', 'value': '47.1', 'row': 25, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'FSAF (ResNeXt-101, multi-scale)', 'value': '54.6', 'row': 25, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'CUFED5 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRNTT-l2', 'value': '26.24', 'row': 13, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Sun80 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRNTT-l2', 'value': '28.54', 'row': 13, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRNTT-l2', 'value': '25.5', 'row': 13, 'column': 3}]}\n","{'index': 1, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'EpipolarPose (self-supervised)', 'value': '76.6', 'row': 12, 'column': 1}, {'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'NMPJPE', 'model': 'EpipolarPose (self-supervised)', 'value': '75.25', 'row': 12, 'column': 2}, {'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'PMPJPE', 'model': 'EpipolarPose (self-supervised)', 'value': '67.45', 'row': 12, 'column': 3}, {'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'PSS@50', 'model': 'EpipolarPose (self-supervised)', 'value': '73.09', 'row': 12, 'column': 4}, {'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'PSS@100', 'model': 'EpipolarPose (self-supervised)', 'value': '64.03', 'row': 12, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Object Counting', 'dataset': 'Pascal VOC 2007 count-test', 'metric': 'mRMSE', 'model': 'Supervised Density Map', 'value': '0.29', 'row': 8, 'column': 2}, {'task': 'Object Counting', 'dataset': 'Pascal VOC 2007 count-test', 'metric': 'mRMSE-nz', 'model': 'Supervised Density Map', 'value': '1.14', 'row': 8, 'column': 3}, {'task': 'Object Counting', 'dataset': 'Pascal VOC 2007 count-test', 'metric': 'm-relRMSE', 'model': 'Supervised Density Map', 'value': '0.17', 'row': 8, 'column': 4}, {'task': 'Object Counting', 'dataset': 'Pascal VOC 2007 count-test', 'metric': 'm-reIRMSE-nz', 'model': 'Supervised Density Map', 'value': '0.61', 'row': 8, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Object Counting', 'dataset': 'COCO count-test', 'metric': 'mRMSE', 'model': 'Supervised Density Map', 'value': '0.34', 'row': 7, 'column': 2}, {'task': 'Object Counting', 'dataset': 'COCO count-test', 'metric': 'mRMSE-nz', 'model': 'Supervised Density Map', 'value': '1.89', 'row': 7, 'column': 3}, {'task': 'Object Counting', 'dataset': 'COCO count-test', 'metric': 'm-reIRMSE', 'model': 'Supervised Density Map', 'value': '0.18', 'row': 7, 'column': 4}, {'task': 'Object Counting', 'dataset': 'COCO count-test', 'metric': 'm-reIRMSE-nz', 'model': 'Supervised Density Map', 'value': '0.84', 'row': 7, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Drug Discovery', 'dataset': 'HIV dataset', 'metric': 'AUC', 'model': 'RNN-DFS', 'value': '0.627', 'row': 9, 'column': 1}, {'task': 'Drug Discovery', 'dataset': 'MUV', 'metric': 'AUC', 'model': 'RNN-DFS', 'value': '0.648', 'row': 9, 'column': 2}, {'task': 'Drug Discovery', 'dataset': 'Tox21', 'metric': 'AUC', 'model': 'RNN-DFS', 'value': '0.748', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Meta Reinforcement Learning', 'dataset': '10-Monty-Hall', 'metric': 'AUC', 'model': 'Max-Until-Exploit', 'value': '9575.42', 'row': 4, 'column': 1}, {'task': 'Meta Reinforcement Learning', 'dataset': '10-Monty-Hall', 'metric': 'Final Performance', 'model': 'Max-Until-Exploit', 'value': '100%', 'row': 4, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Meta Reinforcement Learning', 'dataset': '3-Color-Choice', 'metric': 'AUC', 'model': 'StDev-Until-Exploit', 'value': '11436.83', 'row': 5, 'column': 1}, {'task': 'Meta Reinforcement Learning', 'dataset': '3-Color-Choice', 'metric': 'Final Performance', 'model': 'StDev-Until-Exploit', 'value': '43.9%', 'row': 5, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Meta Reinforcement Learning', 'dataset': '3-Reacher', 'metric': 'AUC', 'model': 'StDev-Until-Exploit', 'value': '9626.29', 'row': 5, 'column': 1}, {'task': 'Meta Reinforcement Learning', 'dataset': '3-Reacher', 'metric': 'Final Performance', 'model': 'StDev-Until-Exploit', 'value': '58.9%', 'row': 5, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Optic Disc Segmentation', 'dataset': 'ORIGA', 'metric': 'Error rate', 'model': 'CE-Net', 'value': '0.058', 'row': 7, 'column': 1}, {'task': 'Optic Disc Segmentation', 'dataset': 'Messidor', 'metric': 'Error rate', 'model': 'CE-Net', 'value': '0.051', 'row': 7, 'column': 2}, {'task': 'Optic Disc Segmentation', 'dataset': 'RIM-ONE-R1', 'metric': 'Error rate', 'model': 'CE-Net', 'value': '0.087', 'row': 7, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Retinal Vessel Segmentation', 'dataset': 'DRIVE', 'metric': 'Accuracy', 'model': 'CE-Net', 'value': '0.9545', 'row': 8, 'column': 2}, {'task': 'Retinal Vessel Segmentation', 'dataset': 'DRIVE', 'metric': 'AUC', 'model': 'CE-Net', 'value': '0.9779', 'row': 8, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Lung Nodule Segmentation', 'dataset': 'LUNA', 'metric': 'Accuracy', 'model': 'CE-Net', 'value': '0.99', 'row': 3, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Medical Image Segmentation', 'dataset': 'ISBI 2012 EM Segmentation', 'metric': 'VRand', 'model': 'CE-Net', 'value': '0.9743', 'row': 3, 'column': 1}, {'task': 'Medical Image Segmentation', 'dataset': 'ISBI 2012 EM Segmentation', 'metric': 'VInfo', 'model': 'CE-Net', 'value': '0.9878', 'row': 3, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Retinal OCT Layer Segmentation', 'dataset': 'Topcon', 'metric': 'MAE', 'model': 'CE-Net w/ Dice', 'value': '1.68', 'row': 7, 'column': 11}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'VisDA2017', 'metric': 'Accuracy', 'model': 'SWD', 'value': '76.4', 'row': 5, 'column': 13}]}\n","{'index': 2, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'SWD', 'value': '44.5', 'row': 12, 'column': 20}]}\n","{'index': 3, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'SWD', 'value': '48.1', 'row': 9, 'column': 14}]}\n","{'index': 1, 'records': [{'task': 'One-Shot Visual Object Segmentation', 'dataset': 'YouTube-VOS', 'metric': 'Jaccard (Seen)', 'model': 'RVOS-Mask-ST+', 'value': '63.6', 'row': 7, 'column': 2}, {'task': 'One-Shot Visual Object Segmentation', 'dataset': 'YouTube-VOS', 'metric': 'Jaccard (Unseen)', 'model': 'RVOS-Mask-ST+', 'value': '45.5', 'row': 7, 'column': 3}, {'task': 'One-Shot Visual Object Segmentation', 'dataset': 'YouTube-VOS', 'metric': 'F-Measure (Seen)', 'model': 'RVOS-Mask-ST+', 'value': '67.2', 'row': 7, 'column': 4}, {'task': 'One-Shot Visual Object Segmentation', 'dataset': 'YouTube-VOS', 'metric': 'F-Measure (Unseen)', 'model': 'RVOS-Mask-ST+', 'value': '51', 'row': 7, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Online Multi-Object Tracking', 'dataset': 'MOT17', 'metric': 'MOTA', 'model': 'Tracktor++', 'value': '53.5', 'row': 1, 'column': 2}, {'task': 'Online Multi-Object Tracking', 'dataset': 'MOT16', 'metric': 'MOTA', 'model': 'Tracktor++', 'value': '54.4', 'row': 7, 'column': 2}, {'task': 'Online Multi-Object Tracking', 'dataset': '2D MOT 2015', 'metric': 'MOTA', 'model': 'Tracktor++', 'value': '44.1', 'row': 13, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Middlebury - 2x upscaling', 'metric': 'PSNR', 'model': 'PASSRnet', 'value': '34.05', 'row': 2, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Middlebury - 4x upscaling', 'metric': 'PSNR', 'model': 'PASSRnet', 'value': '28.63', 'row': 3, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'KITTI 2012 - 2x upscaling', 'metric': 'PSNR', 'model': 'PASSRnet', 'value': '30.65', 'row': 4, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'KITTI 2012 - 4x upscaling', 'metric': 'PSNR', 'model': 'PASSRnet', 'value': '26.26', 'row': 5, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'KITTI 2015 - 2x upscaling', 'metric': 'PSNR', 'model': 'PASSRnet', 'value': '29.78', 'row': 6, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'KITTI 2015 - 4x upscaling', 'metric': 'PSNR', 'model': 'PASSRnet', 'value': '25.43', 'row': 7, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Text-to-Image Generation', 'dataset': 'CUB', 'metric': 'Inception score', 'model': 'MirrorGAN', 'value': '4.56', 'row': 7, 'column': 1}, {'task': 'Text-to-Image Generation', 'dataset': 'COCO', 'metric': 'Inception score', 'model': 'MirrorGAN', 'value': '26.47', 'row': 7, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'MAR', 'value': '67.7', 'row': 14, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'MAR', 'value': '81.9', 'row': 14, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'MAR', 'value': '40', 'row': 14, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'MAR', 'value': '67.1', 'row': 11, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'MAR', 'value': '79.8', 'row': 11, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'MAR', 'value': '48', 'row': 11, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'SKNet-29 (ResNeXt-29, 16×32d)', 'value': '96.53', 'row': 5, 'column': 2}, {'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage correct', 'model': 'SKNet-29 (ResNeXt-29, 16×32d)', 'value': '82.67', 'row': 5, 'column': 3}]}\n","{'index': 8, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'SKNet-101', 'value': '48.9M', 'row': 17, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'SKNet-101', 'value': '79.81', 'row': 17, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'PifPaf (single-scale)', 'value': '66.4', 'row': 4, 'column': 1}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'PifPaf (single-scale)', 'value': '62.6', 'row': 4, 'column': 2}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'PifPaf (single-scale)', 'value': '72.1', 'row': 4, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'BoT Baseline(RK)', 'value': '89.1', 'row': 23, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Aspect', 'model': 'BERT-pair-QA-M', 'value': '86.4', 'row': 9, 'column': 2}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Sentiment', 'model': 'BERT-pair-QA-M', 'value': '93.6', 'row': 9, 'column': 4}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Aspect (AUC)', 'model': 'BERT-pair-NLI-M', 'value': '97.5', 'row': 10, 'column': 3}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Aspect', 'model': 'BERT-pair-QA-B', 'value': '87.9', 'row': 11, 'column': 2}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Sentiment', 'model': 'BERT-pair-QA-B', 'value': '93.3', 'row': 11, 'column': 4}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Sentiment (AUC)', 'model': 'BERT-pair-QA-B', 'value': '97.0', 'row': 11, 'column': 5}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'Sentihood', 'metric': 'Aspect (Accuracy)', 'model': 'BERT-pair-NLI-B', 'value': '79.8', 'row': 12, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Aspect Category Detection', 'dataset': 'SemEval 2014 Task 4 Subtask 3', 'metric': 'Precision', 'model': 'BERT-pair-NLI-B', 'value': '93.57', 'row': 7, 'column': 1}, {'task': 'Aspect Category Detection', 'dataset': 'SemEval 2014 Task 4 Subtask 3', 'metric': 'Recall', 'model': 'BERT-pair-NLI-B', 'value': '90.83', 'row': 7, 'column': 2}, {'task': 'Aspect Category Detection', 'dataset': 'SemEval 2014 Task 4 Subtask 3', 'metric': 'F1 score', 'model': 'BERT-pair-NLI-B', 'value': '92.18', 'row': 7, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Subtask 4', 'metric': 'Accuracy (4-way)', 'model': 'BERT-pair-QA-B', 'value': '85.9', 'row': 8, 'column': 1}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Subtask 4', 'metric': 'Accuracy (3-way)', 'model': 'BERT-pair-QA-B', 'value': '89.9', 'row': 8, 'column': 2}, {'task': 'Aspect-Based Sentiment Analysis', 'dataset': 'SemEval 2014 Task 4 Subtask 4', 'metric': 'Binary Accuracy', 'model': 'BERT-pair-QA-B', 'value': '95.6', 'row': 8, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '38.11', 'row': 2, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '34.70', 'row': 3, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '32.47', 'row': 4, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '33.82', 'row': 5, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '30.1', 'row': 6, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '28.81', 'row': 7, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '32.29', 'row': 8, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '29.24', 'row': 9, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '27.72', 'row': 10, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '32.62', 'row': 11, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '28.73', 'row': 12, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '26.6', 'row': 13, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '39.08', 'row': 14, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '34.18', 'row': 15, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRFBN', 'value': '31.15', 'row': 16, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'rRevGrad+CAT', 'value': '80.1', 'row': 18, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'SVNH-to-MNIST', 'metric': 'Accuracy', 'model': 'rRevGrad+CAT', 'value': '98.8', 'row': 12, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'MNIST-to-USPS', 'metric': 'Accuracy', 'model': 'rRevGrad+CAT', 'value': '96', 'row': 12, 'column': 3}, {'task': 'Domain Adaptation', 'dataset': 'USPS-to-MNIST', 'metric': 'Accuracy', 'model': 'MCD+CAT', 'value': '96.3', 'row': 14, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'rRevGrad+CAT', 'value': '80.7', 'row': 15, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Image Reconstruction', 'dataset': 'Edge-to-Shoes', 'metric': 'HP', 'model': 'PI-REC', 'value': '62.30', 'row': 8, 'column': 1}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Shoes', 'metric': 'MMD', 'model': 'PI-REC', 'value': '0.081', 'row': 8, 'column': 2}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Shoes', 'metric': 'FID', 'model': 'PI-REC', 'value': '0.015', 'row': 8, 'column': 3}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Shoes', 'metric': 'LPIPS', 'model': 'PI-REC', 'value': '0.085', 'row': 8, 'column': 4}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Handbags', 'metric': 'HP', 'model': 'PI-REC', 'value': '57.10', 'row': 8, 'column': 5}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Handbags', 'metric': 'MMD', 'model': 'PI-REC', 'value': '0.112', 'row': 8, 'column': 6}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Handbags', 'metric': 'FID', 'model': 'PI-REC', 'value': '0.069', 'row': 8, 'column': 7}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Handbags', 'metric': 'LPIPS', 'model': 'PI-REC', 'value': '0.168', 'row': 8, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'DeepRED', 'value': '30.72', 'row': 2, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'PSNR', 'model': 'DeepRED', 'value': '26.04', 'row': 6, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'DeepRED', 'value': '27.63', 'row': 2, 'column': 13}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'PSNR', 'model': 'DeepRED', 'value': '24.28', 'row': 6, 'column': 13}]}\n","{'index': 2, 'records': [{'task': 'Face Verification', 'dataset': 'CASIA NIR-VIS 2.0', 'metric': 'TAR @ FAR=0.001', 'model': 'LightCNN-29 + DVG', 'value': '99.8', 'row': 15, 'column': 2}, {'task': 'Face Verification', 'dataset': 'Oulu-CASIA NIR-VIS', 'metric': 'TAR @ FAR=0.01', 'model': 'LightCNN-29 + DVG', 'value': '98.5', 'row': 15, 'column': 4}, {'task': 'Face Verification', 'dataset': 'Oulu-CASIA NIR-VIS', 'metric': 'TAR @ FAR=0.001', 'model': 'LightCNN-29 + DVG', 'value': '92.9', 'row': 15, 'column': 5}, {'task': 'Face Verification', 'dataset': 'BUAA-VisNir', 'metric': 'TAR @ FAR=0.01', 'model': 'LightCNN-29 + DVG', 'value': '98.5', 'row': 15, 'column': 7}, {'task': 'Face Verification', 'dataset': 'BUAA-VisNir', 'metric': 'TAR @ FAR=0.001', 'model': 'LightCNN-29 + DVG', 'value': '97.3', 'row': 15, 'column': 8}, {'task': 'Face Verification', 'dataset': 'IIIT-D Viewed Sketch', 'metric': 'TAR @ FAR=0.01', 'model': 'LightCNN-29 + DVG', 'value': '97.86', 'row': 15, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Epinions', 'metric': 'MAE', 'model': 'DANSER', 'value': '0.7781', 'row': 9, 'column': 1}, {'task': 'Recommendation Systems', 'dataset': 'Epinions', 'metric': 'RMSE', 'model': 'DANSER', 'value': '1.0268', 'row': 9, 'column': 2}, {'task': 'Recommendation Systems', 'dataset': 'WeChat', 'metric': 'P@10', 'model': 'DANSER', 'value': '0.0823', 'row': 9, 'column': 3}, {'task': 'Recommendation Systems', 'dataset': 'WeChat', 'metric': 'AUC', 'model': 'DANSER', 'value': '0.8165', 'row': 9, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '43.12', 'row': 9, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '64.15', 'row': 9, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '47.11', 'row': 9, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '56.39', 'row': 9, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '47.19', 'row': 9, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '25.49', 'row': 9, 'column': 7}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'mask AP', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '38.34', 'row': 9, 'column': 8}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '61.07', 'row': 9, 'column': 9}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '40.82', 'row': 9, 'column': 10}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '56.08', 'row': 9, 'column': 11}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '41.73', 'row': 9, 'column': 12}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'Mask R-CNN-FPN (ResNeXt-101, GN+WS)', 'value': '18.32', 'row': 9, 'column': 13}]}\n","{'index': 6, 'records': [{'task': 'Image Retrieval', 'dataset': 'CUB-200-2011', 'metric': 'R@1', 'model': 'CGD (MG/SG)', 'value': '79.2', 'row': 13, 'column': 3}, {'task': 'Image Retrieval', 'dataset': 'CARS196', 'metric': 'R@1', 'model': 'CGD (MG/SG)', 'value': '94.8', 'row': 13, 'column': 7}]}\n","{'index': 7, 'records': [{'task': 'Image Retrieval', 'dataset': 'SOP', 'metric': 'R@1', 'model': 'CGD (SG/GS)', 'value': '84.2', 'row': 14, 'column': 3}, {'task': 'Image Retrieval', 'dataset': 'In-Shop', 'metric': 'R@1', 'model': 'CGD (SG/GS)', 'value': '91.9', 'row': 14, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Sentence Classification', 'dataset': 'ACL-ARC', 'metric': 'F1', 'model': 'SciBERT (SciVocab)', 'value': '65.71', 'row': 12, 'column': 7}]}\n","{'index': 2, 'records': [{'task': '3D Object Detection', 'dataset': 'nuScenes', 'metric': 'NDS', 'model': 'PointPillars (KITTI)', 'value': '44.8', 'row': 3, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'nuScenes', 'metric': 'NDS', 'model': 'PointPillars (ImageNet)', 'value': '44.9', 'row': 4, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'nuScenes', 'metric': 'NDS', 'model': 'PointPillars', 'value': '44.2', 'row': 5, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'PMTD*', 'value': '84.42', 'row': 13, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'PMTD*', 'value': '76.25', 'row': 13, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'PMTD*', 'value': '80.13', 'row': 13, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'PMTD', 'value': '91.3', 'row': 18, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'PMTD', 'value': '87.43', 'row': 18, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'PMTD', 'value': '89.33', 'row': 18, 'column': 3}]}\n","{'index': 7, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'InterNet (ResNet-101-FPN, multi-scale)', 'value': '44.2', 'row': 15, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'InterNet (ResNet-101-FPN, multi-scale)', 'value': '67.5', 'row': 15, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'InterNet (ResNet-101-FPN, multi-scale)', 'value': '51.1', 'row': 15, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'InterNet (ResNet-101-FPN, multi-scale)', 'value': '27.2', 'row': 15, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'InterNet (ResNet-101-FPN, multi-scale)', 'value': '50.3', 'row': 15, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'InterNet (ResNet-101-FPN, multi-scale)', 'value': '57.7', 'row': 15, 'column': 7}]}\n","{'index': 8, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'InterNet (ResNet-101)', 'value': '82.7', 'row': 7, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'mask AP', 'model': 'TensorMask (ResNet-101-FPN)', 'value': '37.3', 'row': 4, 'column': 6}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'CenterMask + X101-32x8d (single-scale)', 'value': '61.2', 'row': 5, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'LiveJournal', 'metric': 'MRR', 'model': 'PyTorch BigGraph', 'value': '0.7490000000000001', 'row': 5, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'LiveJournal', 'metric': 'MR', 'model': 'PBG (1 partition)', 'value': '245.9', 'row': 5, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'LiveJournal', 'metric': 'Hits@10', 'model': 'PBG (1 partition)', 'value': '0.857', 'row': 5, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'YouTube', 'metric': 'Micro F1', 'model': 'PyTorch BigGraph', 'value': '48', 'row': 5, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'YouTube', 'metric': 'Macro F1', 'model': 'PyTorch BigGraph', 'value': '40.9', 'row': 5, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'MRR raw', 'model': 'PyTorch BigGraph (ComplEx)', 'value': '0.242', 'row': 10, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'MRR filtered', 'model': 'PyTorch BigGraph (ComplEx)', 'value': '0.79', 'row': 10, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'FB15k', 'metric': 'Hits@10', 'model': 'PyTorch BigGraph (ComplEx)', 'value': '0.872', 'row': 10, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'DN4 (k=3)', 'value': '51.24', 'row': 10, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'DN4 (k=3)', 'value': '71.02', 'row': 10, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Stanford Dogs 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'DN4-DA (k=1)', 'value': '45.73', 'row': 9, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Stanford Dogs 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'DN4-DA (k=1)', 'value': '66.33', 'row': 9, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Stanford Cars 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'DN4-DA (k=1)', 'value': '61.51', 'row': 9, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'Stanford Cars 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'DN4-DA (k=1)', 'value': '89.6', 'row': 9, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'DN4-DA (k=1)', 'value': '53.15', 'row': 9, 'column': 6}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 5-shot', 'metric': 'Accuracy', 'model': 'DN4-DA (k=1)', 'value': '81.9', 'row': 9, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Facial Expression Translation', 'dataset': 'AR Face', 'metric': 'AMT', 'model': 'AGGAN', 'value': '12.8', 'row': 14, 'column': 1}, {'task': 'Facial Expression Translation', 'dataset': 'AR Face', 'metric': 'PSNR', 'model': 'AGGAN', 'value': '14.9187', 'row': 14, 'column': 2}, {'task': 'Facial Expression Translation', 'dataset': 'AR Face', 'metric': 'MSE', 'model': 'AGGAN', 'value': '25.086', 'row': 14, 'column': 3}, {'task': 'Facial Expression Translation', 'dataset': 'Bu3dfe', 'metric': 'AMT', 'model': 'AGGAN', 'value': '32.9', 'row': 14, 'column': 4}, {'task': 'Facial Expression Translation', 'dataset': 'Bu3dfe', 'metric': 'PSNR', 'model': 'AGGAN', 'value': '21.3247', 'row': 14, 'column': 5}, {'task': 'Facial Expression Translation', 'dataset': 'Bu3dfe', 'metric': 'MSE', 'model': 'AGGAN', 'value': '5.745', 'row': 14, 'column': 6}, {'task': 'Facial Expression Translation', 'dataset': 'CelebA', 'metric': 'AMT', 'model': 'AGGAN', 'value': '38.9', 'row': 14, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'PSENet-1s', 'value': '84.8', 'row': 8, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'PSENet-1s', 'value': '79.7', 'row': 8, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'F-Measure', 'model': 'PSENet-1s', 'value': '82.2', 'row': 8, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'PSENet-4s', 'value': '84.5', 'row': 8, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'PSENet-4s', 'value': '75.2', 'row': 8, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'PSENet-4s', 'value': '79.6%', 'row': 8, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'PSENet-1s', 'value': '86.9', 'row': 15, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'PSENet-1s', 'value': '84.5', 'row': 15, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'PSENet-1s', 'value': '85.7', 'row': 15, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'PSENet (ResNet-152)', 'value': '75.35', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'PSENet (ResNet-152)', 'value': '69.18', 'row': 9, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'PSENet (ResNet-152)', 'value': '72.13%', 'row': 9, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'Bias-controlled Adversarial Training', 'value': '93.1', 'row': 31, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'Bias-controlled Adversarial Training', 'value': '89.3', 'row': 31, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'Bias-controlled Adversarial Training', 'value': '85.2', 'row': 31, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'Bias-controlled Adversarial Training', 'value': '74.8', 'row': 31, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Dense Object Detection', 'dataset': 'SKU-110K', 'metric': 'AP', 'model': 'Soft-IoU + EM-Merger unit', 'value': '0.492', 'row': 8, 'column': 1}, {'task': 'Dense Object Detection', 'dataset': 'SKU-110K', 'metric': 'AP75', 'model': 'Soft-IoU + EM-Merger unit', 'value': '0.556', 'row': 8, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Object Counting', 'dataset': 'CARPK', 'metric': 'MAE', 'model': 'Soft-IoU + EM-Merger unit', 'value': '6.77', 'row': 9, 'column': 1}, {'task': 'Object Counting', 'dataset': 'CARPK', 'metric': 'RMSE', 'model': 'Soft-IoU + EM-Merger unit', 'value': '8.52', 'row': 9, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'UGraphEmb-F', 'value': '73.56', 'row': 11, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'UGraphEmb-F', 'value': '50.97', 'row': 11, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'Web', 'metric': 'Accuracy', 'model': 'UGraphEmb-F', 'value': '45.03', 'row': 11, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'UGraphEmb-F', 'value': '74.48', 'row': 11, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'REDDIT-MULTI-12K', 'metric': 'Accuracy', 'model': 'UGraphEmb-F', 'value': '41.84', 'row': 11, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'Res2Net-50-299', 'value': '78.59', 'row': 4, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'Res2Net-50-299', 'value': '94.12', 'row': 4, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'Res2Net-101', 'value': '79.19', 'row': 3, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'Res2Net-101', 'value': '94.43', 'row': 3, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage correct', 'model': 'Res2NeXt-29', 'value': '83.44', 'row': 11, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '74.4', 'row': 2, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '33.7', 'row': 4, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '53.6', 'row': 4, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '14', 'row': 3, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '38.3', 'row': 3, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '51.1', 'row': 3, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'mIoU', 'model': 'Deeplab v3+ (Res2Net-101)', 'value': '79.3', 'row': 3, 'column': 2}]}\n","{'index': 7, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '15.7', 'row': 3, 'column': 2}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '37.9', 'row': 3, 'column': 3}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '53.7', 'row': 3, 'column': 4}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'mask AP', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '35.6', 'row': 3, 'column': 5}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Faster R-CNN (Res2Net-50)', 'value': '57.6', 'row': 3, 'column': 6}]}\n","{'index': 8, 'records': [{'task': 'Salient Object Detection', 'dataset': 'ECSSD', 'metric': 'F-Measure', 'model': 'DSS (Res2Net-50)', 'value': '92.6', 'row': 2, 'column': 2}, {'task': 'Salient Object Detection', 'dataset': 'ECSSD', 'metric': 'MAE', 'model': 'DSS (Res2Net-50)', 'value': '0.056', 'row': 2, 'column': 3}, {'task': 'Salient Object Detection', 'dataset': 'PASCAL-S', 'metric': 'F-Measure', 'model': 'DSS (Res2Net-50)', 'value': '84.1', 'row': 4, 'column': 2}, {'task': 'Salient Object Detection', 'dataset': 'PASCAL-S', 'metric': 'MAE', 'model': 'DSS (Res2Net-50)', 'value': '0.099', 'row': 4, 'column': 3}, {'task': 'Salient Object Detection', 'dataset': 'HKU-IS', 'metric': 'F-Measure', 'model': 'DSS (Res2Net-50)', 'value': '90.5', 'row': 6, 'column': 2}, {'task': 'Salient Object Detection', 'dataset': 'HKU-IS', 'metric': 'MAE', 'model': 'DSS (Res2Net-50)', 'value': '0.05', 'row': 6, 'column': 3}, {'task': 'Salient Object Detection', 'dataset': 'DUT-OMRON', 'metric': 'F-Measure', 'model': 'DSS (Res2Net-50)', 'value': '80', 'row': 8, 'column': 2}, {'task': 'Salient Object Detection', 'dataset': 'DUT-OMRON', 'metric': 'MAE', 'model': 'DSS (Res2Net-50)', 'value': '0.071', 'row': 8, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Text-to-Image Generation', 'dataset': 'CUB', 'metric': 'Inception score', 'model': 'DM-GAN', 'value': '4.75', 'row': 1, 'column': 6}, {'task': 'Text-to-Image Generation', 'dataset': 'COCO', 'metric': 'Inception score', 'model': 'DM-GAN', 'value': '30.49', 'row': 2, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'IDDA (AlexNet)', 'value': '78.5', 'row': 14, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'IDDA', 'value': '49.46', 'row': 8, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'IDDA (Alexnet)', 'value': '80.6', 'row': 6, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'Mask R-CNN (ResNeXt-101-FPN)', 'value': '38.9', 'row': 3, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'CornerNet511 (Hourglass-104)', 'value': '40.5', 'row': 3, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'Charades', 'metric': 'MAP', 'model': 'Spatial Prior', 'value': '10.03', 'row': 10, 'column': 18}]}\n","{'index': 2, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'HICO-DET', 'metric': 'MAP', 'model': 'Spatial Prior', 'value': '5.39', 'row': 6, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Action Classification', 'dataset': 'YouCook2', 'metric': 'Verb Top-1 Accuracy', 'model': 'VideoBERT (cross modal)', 'value': '3.2', 'row': 4, 'column': 2}, {'task': 'Action Classification', 'dataset': 'YouCook2', 'metric': 'Verb Top-5 Accuracy', 'model': 'VideoBERT (cross modal)', 'value': '43.3', 'row': 4, 'column': 3}, {'task': 'Action Classification', 'dataset': 'YouCook2', 'metric': 'Object Top-1 Accuracy', 'model': 'VideoBERT (cross modal)', 'value': '13.1', 'row': 4, 'column': 4}, {'task': 'Action Classification', 'dataset': 'YouCook2', 'metric': 'Object Top 5 Accuracy', 'model': 'VideoBERT (cross modal)', 'value': '33.7', 'row': 4, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Video Captioning', 'dataset': 'YouCook2', 'metric': 'BLEU-3', 'model': 'VideoBERT + S3D', 'value': '7.59', 'row': 5, 'column': 1}, {'task': 'Video Captioning', 'dataset': 'YouCook2', 'metric': 'BLEU-4', 'model': 'VideoBERT + S3D', 'value': '4.33', 'row': 5, 'column': 2}, {'task': 'Video Captioning', 'dataset': 'YouCook2', 'metric': 'METEOR', 'model': 'VideoBERT + S3D', 'value': '11.94', 'row': 5, 'column': 3}, {'task': 'Video Captioning', 'dataset': 'YouCook2', 'metric': 'ROUGE-L', 'model': 'VideoBERT + S3D', 'value': '28.8', 'row': 5, 'column': 4}, {'task': 'Video Captioning', 'dataset': 'YouCook2', 'metric': 'ROUGE-L', 'model': 'VideoBERT + S3D', 'value': '0.55', 'row': 5, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'DADA', 'value': '42.6', 'row': 8, 'column': 18}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Recall', 'model': 'CRAFT', 'value': '93.1', 'row': 18, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'Precision', 'model': 'CRAFT', 'value': '97.4', 'row': 18, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2013', 'metric': 'H-Mean', 'model': 'CRAFT', 'value': '95.2', 'row': 18, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CRAFT', 'value': '84.3', 'row': 18, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CRAFT', 'value': '89.8', 'row': 18, 'column': 5}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'H-Mean', 'model': 'CRAFT', 'value': '86.9', 'row': 18, 'column': 6}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'CRAFT', 'value': '68.2', 'row': 18, 'column': 7}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'CRAFT', 'value': '80.6', 'row': 18, 'column': 8}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'H-Mean', 'model': 'CRAFT', 'value': '73.9', 'row': 18, 'column': 9}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'CRAFT', 'value': '78.2', 'row': 18, 'column': 10}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Precision', 'model': 'CRAFT', 'value': '88.2', 'row': 18, 'column': 11}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'H-Mean', 'model': 'CRAFT', 'value': '82.9', 'row': 18, 'column': 12}]}\n","{'index': 1, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'CRAFT', 'value': '79.9', 'row': 5, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'CRAFT', 'value': '87.6', 'row': 5, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'H-Mean', 'model': 'CRAFT', 'value': '83.6', 'row': 5, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'CRAFT', 'value': '81.1', 'row': 5, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'CRAFT', 'value': '86', 'row': 5, 'column': 5}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'H-Mean', 'model': 'CRAFT', 'value': '83.5', 'row': 5, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Document Classification', 'dataset': 'BBCSport', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '95.73', 'row': 8, 'column': 1}, {'task': 'Document Classification', 'dataset': 'Twitter', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '72.6', 'row': 8, 'column': 2}, {'task': 'Document Classification', 'dataset': 'Recipe', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '59.06', 'row': 8, 'column': 3}, {'task': 'Text Classification', 'dataset': 'Ohsumed', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '64.06', 'row': 8, 'column': 4}, {'task': 'Document Classification', 'dataset': 'Classic', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '96.24', 'row': 8, 'column': 5}, {'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '97.17', 'row': 8, 'column': 6}, {'task': 'Document Classification', 'dataset': 'Amazon', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '94.31', 'row': 8, 'column': 7}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '76.18', 'row': 8, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '86.33', 'row': 14, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '70.74', 'row': 14, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'IMDb-B', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '71.46', 'row': 14, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '48.92', 'row': 14, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'REDDIT-B', 'metric': 'Accuracy', 'model': 'ApproxRepSet', 'value': '80.3', 'row': 14, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-1', 'model': 'ECN', 'value': '75.1', 'row': 7, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-5', 'model': 'ECN', 'value': '87.6', 'row': 7, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-10', 'model': 'ECN', 'value': '91.6', 'row': 7, 'column': 4}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-20', 'model': 'ECN', 'value': '94.5', 'row': 7, 'column': 5}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'mAP', 'model': 'ECN', 'value': '43', 'row': 7, 'column': 6}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'ECN', 'value': '63.3', 'row': 7, 'column': 8}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'ECN', 'value': '75.8', 'row': 7, 'column': 9}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->DukeMTMC-reID', 'metric': 'Rank-10', 'model': 'ECN', 'value': '80.4', 'row': 7, 'column': 10}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->DukeMTMC-reID', 'metric': 'Rank-20', 'model': 'ECN', 'value': '84.2', 'row': 7, 'column': 11}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->DukeMTMC-reID', 'metric': 'mAP', 'model': 'ECN', 'value': '40.4', 'row': 7, 'column': 12}]}\n","{'index': 3, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'ECN', 'value': '75.1', 'row': 14, 'column': 1}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'ECN', 'value': '87.6', 'row': 14, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-10', 'model': 'ECN', 'value': '91.6', 'row': 14, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'ECN', 'value': '43', 'row': 14, 'column': 4}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'ECN', 'value': '63.3', 'row': 14, 'column': 5}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'ECN', 'value': '75.8', 'row': 14, 'column': 6}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-10', 'model': 'ECN', 'value': '80.4', 'row': 14, 'column': 7}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'ECN', 'value': '40.4', 'row': 14, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'Rank-1', 'model': 'ECN', 'value': '25.3', 'row': 3, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'Rank-5', 'model': 'ECN', 'value': '36.3', 'row': 3, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'Rank-10', 'model': 'ECN', 'value': '42.1', 'row': 3, 'column': 4}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501->MSMT17', 'metric': 'mAP', 'model': 'ECN', 'value': '8.5', 'row': 3, 'column': 5}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'Rank-1', 'model': 'ECN', 'value': '30.2', 'row': 5, 'column': 2}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'Rank-5', 'model': 'ECN', 'value': '41.5', 'row': 5, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'Rank-10', 'model': 'ECN', 'value': '46.8', 'row': 5, 'column': 4}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->MSMT17', 'metric': 'mAP', 'model': 'ECN', 'value': '10.2', 'row': 5, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'DFANet A', 'value': '71.3', 'row': 13, 'column': 6}]}\n","{'index': 5, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'CamVid', 'metric': 'Mean IoU', 'model': 'DFANet A', 'value': '64.7', 'row': 8, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '99.0', 'row': 1, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '99.4', 'row': 2, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '95.9', 'row': 3, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '98.15', 'row': 4, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '51.57', 'row': 4, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '66.27', 'row': 4, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '60.52', 'row': 6, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 5-shot', 'metric': 'Accuracy', 'model': 'Hyperbolic ProtoNet', 'value': '72.22', 'row': 6, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'MDAIR', 'value': '89.8', 'row': 7, 'column': 12}]}\n","{'index': 4, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'MDAIR', 'value': '72.8', 'row': 14, 'column': 13}]}\n","{'index': 1, 'records': [{'task': 'Video Object Segmentation', 'dataset': 'YouTube', 'metric': 'mIoU', 'model': 'Spatiotemporal CNN', 'value': '79.6', 'row': 11, 'column': 12}]}\n","{'index': 4, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Mean)', 'model': 'Spatiotemporal CNN', 'value': '83.8', 'row': 2, 'column': 4}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Mean)', 'model': 'Spatiotemporal CNN', 'value': '83.8', 'row': 5, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'DAVIS-2017', 'metric': 'Jaccard (Mean)', 'model': 'Spatiotemporal CNN', 'value': '58.7', 'row': 1, 'column': 7}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS-2017', 'metric': 'F-measure (Mean)', 'model': 'Spatiotemporal CNN', 'value': '64.6', 'row': 2, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'Sports-1M', 'metric': 'Video hit@1 ', 'model': 'ir-CSN-152', 'value': '75.5', 'row': 7, 'column': 2}, {'task': 'Action Recognition In Videos', 'dataset': 'Sports-1M', 'metric': 'Video hit@5', 'model': 'ir-CSN-152', 'value': '92.7', 'row': 7, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'Kinetics-400', 'metric': 'Video hit@1 ', 'model': 'ir-CSN-152 (Sports-1M pretraining)', 'value': '78.5', 'row': 20, 'column': 2}, {'task': 'Action Recognition In Videos', 'dataset': 'Kinetics-400', 'metric': 'Video hit@5', 'model': 'ir-CSN-152 (Sports-1M pretraining)', 'value': '93.4', 'row': 20, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top-1 Accuracy', 'model': 'Single-Path NAS', 'value': '74.96', 'row': 13, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top-5 Accuracy', 'model': 'Single-Path NAS', 'value': '92.21', 'row': 13, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'Jasper DR 10x5', 'value': '2.95', 'row': 9, 'column': 5}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'Jasper DR 10x5', 'value': '8.79', 'row': 9, 'column': 6}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'Jasper DR 10x5 (+ Time/Freq Masks)', 'value': '2.84', 'row': 10, 'column': 5}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'Jasper DR 10x5 (+ Time/Freq Masks)', 'value': '7.84', 'row': 10, 'column': 6}]}\n","{'index': 5, 'records': [{'task': 'Speech Recognition', 'dataset': 'WSJ eval92', 'metric': 'Word Error Rate (WER)', 'model': 'Jasper 10x3', 'value': '6.9', 'row': 7, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Speech Recognition', 'dataset': \"Hub5'00 SwitchBoard\", 'metric': 'SwitchBoard', 'model': 'Jasper DR 10x5', 'value': '7.8', 'row': 8, 'column': 3}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 SwitchBoard\", 'metric': 'CallHome', 'model': 'Jasper DR 10x5', 'value': '16.2', 'row': 8, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Pose Transfer', 'dataset': 'Market-1501', 'metric': 'SSIM', 'model': 'Progressive Pose Attention', 'value': '0.311', 'row': 8, 'column': 1}, {'task': 'Pose Transfer', 'dataset': 'Market-1501', 'metric': 'IS', 'model': 'Progressive Pose Attention', 'value': '3.323', 'row': 8, 'column': 2}, {'task': 'Pose Transfer', 'dataset': 'Market-1501', 'metric': 'mask-SSIM', 'model': 'Progressive Pose Attention', 'value': '0.811', 'row': 8, 'column': 3}, {'task': 'Pose Transfer', 'dataset': 'Market-1501', 'metric': 'mask-IS', 'model': 'Progressive Pose Attention', 'value': '3.773', 'row': 8, 'column': 4}, {'task': 'Pose Transfer', 'dataset': 'Market-1501', 'metric': 'DS', 'model': 'Progressive Pose Attention', 'value': '0.74', 'row': 8, 'column': 5}, {'task': 'Pose Transfer', 'dataset': 'Market-1501', 'metric': 'PCKh', 'model': 'Progressive Pose Attention', 'value': '0.94', 'row': 8, 'column': 6}, {'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'SSIM', 'model': 'Progressive Pose Attention', 'value': '0.773', 'row': 8, 'column': 7}, {'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'IS', 'model': 'Progressive Pose Attention', 'value': '3.209', 'row': 8, 'column': 8}, {'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'DS', 'model': 'Progressive Pose Attention', 'value': '0.976', 'row': 8, 'column': 9}, {'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'PCKh', 'model': 'Progressive Pose Attention', 'value': '0.96', 'row': 8, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '36.62', 'row': 8, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.9658', 'row': 8, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '32.82', 'row': 8, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8999', 'row': 8, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '31.36', 'row': 8, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.9097', 'row': 8, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '30.36', 'row': 8, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8949', 'row': 8, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '36.06', 'row': 8, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.9474', 'row': 8, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '32.16', 'row': 15, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.9420000000000001', 'row': 15, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '29.46', 'row': 15, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8229', 'row': 15, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '28.56', 'row': 15, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8493', 'row': 15, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '25.94', 'row': 15, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8165', 'row': 15, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '28.21', 'row': 15, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8739', 'row': 15, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '31.52', 'row': 22, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.9278', 'row': 22, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '28.26', 'row': 22, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.7688', 'row': 22, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '27.29', 'row': 22, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8014', 'row': 22, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '25.33', 'row': 22, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.7759999999999999', 'row': 22, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'IKC', 'value': '29.9', 'row': 22, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'IKC', 'value': '0.8793', 'row': 22, 'column': 11}]}\n","{'index': 2, 'records': [{'task': 'Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR', 'model': 'Pixel-shuffling Downsampling', 'value': '38.4', 'row': 14, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'ACNet (ResNet-50)', 'value': '77.5', 'row': 2, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'ACNet (ResNet-50)', 'value': '29.38M', 'row': 2, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage error', 'model': 'Standard ACNet', 'value': '6', 'row': 1, 'column': 1}, {'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'Standard ACNet', 'value': '94', 'row': 1, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'Mask R-CNN (ResNet-50, ACNet)', 'value': '39.5', 'row': 3, 'column': 1}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'mask AP', 'model': 'Mask R-CNN (ResNet-50, ACNet)', 'value': '35.2', 'row': 3, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-1', 'model': 'TriNet + Era + Reranking (ACNet, bs=32)', 'value': '64.8', 'row': 14, 'column': 1}]}\n","{'index': 6, 'records': [{'task': 'Document Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'ACNet', 'value': '83.5', 'row': 12, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '64.09', 'row': 17, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '80', 'row': 17, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '65.81', 'row': 17, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '81.75', 'row': 17, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR-FS 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '72.8', 'row': 10, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR-FS 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '85', 'row': 10, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '47.2', 'row': 10, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MetaOptNet-SVM-trainval', 'value': '62.5', 'row': 10, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'FoveaBox (ResNet-50-FPN, 600x600)', 'value': '55.2', 'row': 8, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'FoveaBox (ResNet-50-FPN, 600x600)', 'value': '37.9', 'row': 8, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'CornerNet511 (Hourglass-104, multi-scale)', 'value': '42.1', 'row': 21, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'FoveaBox', 'value': '61.9', 'row': 21, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'FoveaBox', 'value': '45.2', 'row': 21, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'Faster R-CNN (HRNetV2p-W48)', 'value': '24.9', 'row': 21, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'FoveaBox', 'value': '46.8', 'row': 21, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'FoveaBox (ResNeXt-101)', 'value': '55.6', 'row': 21, 'column': 7}]}\n","{'index': 6, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'FoveaBox+Retina (ResNet-50)', 'value': '38.1', 'row': 4, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'FoveaBox+Retina (ResNet-50)', 'value': '57.8', 'row': 4, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'FoveaBox+Retina (ResNet-50)', 'value': '40.5', 'row': 4, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Image Retrieval', 'dataset': 'CUB-200-2011', 'metric': 'R@1', 'model': 'EPSHN512', 'value': '64.9', 'row': 9, 'column': 1}, {'task': 'Image Retrieval', 'dataset': 'CARS196', 'metric': 'R@1', 'model': 'EPSHN512', 'value': '82.7', 'row': 9, 'column': 4}, {'task': 'Image Retrieval', 'dataset': 'SOP', 'metric': 'R@1', 'model': 'EPSHN512', 'value': '78.3', 'row': 9, 'column': 7}, {'task': 'Image Retrieval', 'dataset': 'In-Shop', 'metric': 'R@1', 'model': 'EPSHN512', 'value': '87.8', 'row': 9, 'column': 10}]}\n","{'index': 4, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'Criteo', 'metric': 'AUC', 'model': 'FGCNN+IPNN', 'value': '0.8022', 'row': 9, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Criteo', 'metric': 'Log Loss', 'model': 'FGCNN+IPNN', 'value': '0.5388', 'row': 9, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avazu', 'metric': 'AUC', 'model': 'FGCNN+IPNN', 'value': '0.7883', 'row': 9, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avazu', 'metric': 'Log Loss', 'model': 'FGCNN+IPNN', 'value': '0.3746', 'row': 9, 'column': 4}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Huawei App Store', 'metric': 'AUC', 'model': 'FGCNN+IPNN', 'value': '0.9407', 'row': 9, 'column': 5}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Huawei App Store', 'metric': 'Log Loss', 'model': 'FGCNN+IPNN', 'value': '0.1134', 'row': 9, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Density Estimation', 'dataset': 'UCI POWER', 'metric': 'Log-likelihood', 'model': 'B-NAF', 'value': '0.61', 'row': 10, 'column': 1}, {'task': 'Density Estimation', 'dataset': 'UCI GAS', 'metric': 'Log-likelihood', 'model': 'B-NAF', 'value': '12.06', 'row': 10, 'column': 2}, {'task': 'Density Estimation', 'dataset': 'UCI HEPMASS', 'metric': 'Log-likelihood', 'model': 'B-NAF', 'value': '-14.71', 'row': 10, 'column': 3}, {'task': 'Density Estimation', 'dataset': 'UCI MINIBOONE', 'metric': 'Log-likelihood', 'model': 'B-NAF', 'value': '-8.95', 'row': 10, 'column': 4}, {'task': 'Density Estimation', 'dataset': 'BSDS300', 'metric': 'Log-likelihood', 'model': 'B-NAF', 'value': '157.36', 'row': 10, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Density Estimation', 'dataset': 'MNIST', 'metric': 'NLL', 'model': 'B-NAF', 'value': '83.59', 'row': 6, 'column': 1}, {'task': 'Density Estimation', 'dataset': 'MNIST', 'metric': 'Negative ELBO', 'model': 'B-NAF', 'value': '80.71', 'row': 6, 'column': 2}, {'task': 'Density Estimation', 'dataset': 'Freyfaces', 'metric': 'NLL', 'model': 'B-NAF', 'value': '4.42', 'row': 6, 'column': 3}, {'task': 'Density Estimation', 'dataset': 'Freyfaces', 'metric': 'Negative ELBO', 'model': 'B-NAF', 'value': '4.33', 'row': 6, 'column': 4}, {'task': 'Density Estimation', 'dataset': 'OMNIGLOT', 'metric': 'NLL', 'model': 'B-NAF', 'value': '100.08', 'row': 6, 'column': 5}, {'task': 'Density Estimation', 'dataset': 'OMNIGLOT', 'metric': 'Negative ELBO', 'model': 'B-NAF', 'value': '94.83', 'row': 6, 'column': 6}, {'task': 'Density Estimation', 'dataset': 'Caltech-101', 'metric': 'NLL', 'model': 'B-NAF', 'value': '105.42', 'row': 6, 'column': 7}, {'task': 'Density Estimation', 'dataset': 'Caltech-101', 'metric': 'Negative ELBO', 'model': 'B-NAF', 'value': '94.91', 'row': 6, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'mIoU', 'model': 'IRNet (ResNet-50)', 'value': '63.5', 'row': 11, 'column': 3}, {'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 test', 'metric': 'Mean IoU', 'model': 'IRNet (ResNet-50)', 'value': '64.8', 'row': 11, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Age Estimation', 'dataset': 'FGNET', 'metric': 'MAE', 'model': 'C3AE (WIKI-IMDB)', 'value': '0.0295', 'row': 16, 'column': 1}]}\n","{'index': 0, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Using 2D ground-truth joints', 'model': 'Stereoscopic View Synthesis Subnetwork', 'value': '37.6', 'row': 19, 'column': 16}]}\n","{'index': 3, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'MPI-INF-3DHP', 'metric': '3DPCK', 'model': 'Stereoscopic View Synthesis Subnetwork', 'value': '71.2', 'row': 1, 'column': 3}, {'task': '3D Human Pose Estimation', 'dataset': 'MPI-INF-3DHP', 'metric': 'AUC', 'model': 'Stereoscopic View Synthesis Subnetwork', 'value': '33.8', 'row': 2, 'column': 3}]}\n","{'index': 0, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Multimodal Mixture Density Networks', 'value': '42.6', 'row': 16, 'column': 16}]}\n","{'index': 2, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'FRCNN C-MIL', 'value': '53.1', 'row': 5, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Weakly Supervised Object Detection', 'dataset': 'PASCAL VOC 2012 test', 'metric': 'MAP', 'model': 'C-MIL', 'value': '46.7', 'row': 8, 'column': 1}]}\n","{'index': 6, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '38.08', 'row': 13, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.96', 'row': 13, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '34.09', 'row': 13, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.9209999999999999', 'row': 13, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSDS100 - 2x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '32.31', 'row': 13, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSDS100 - 2x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.9009999999999999', 'row': 13, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '32.92', 'row': 13, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.935', 'row': 13, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '39.28', 'row': 13, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.977', 'row': 13, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '32.65', 'row': 25, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.899', 'row': 25, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '29.03', 'row': 25, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.7909999999999999', 'row': 25, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSDS100 - 4x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '27.82', 'row': 25, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSDS100 - 4x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.7440000000000001', 'row': 25, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '27.08', 'row': 25, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.8140000000000001', 'row': 25, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '31.74', 'row': 25, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.9209999999999999', 'row': 25, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '27.51', 'row': 35, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.7929999999999999', 'row': 35, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '25.41', 'row': 35, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.657', 'row': 35, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSDS100 - 8x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '25.05', 'row': 35, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSDS100 - 8x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.607', 'row': 35, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '23.2', 'row': 35, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.652', 'row': 35, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'PSNR', 'model': 'DBPN-RES-MR64-3', 'value': '25.71', 'row': 35, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'SSIM', 'model': 'DBPN-RES-MR64-3', 'value': '0.813', 'row': 35, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Multimodal Emotion Recognition', 'dataset': 'Expressive hands and faces dataset (EHF).', 'metric': 'v2v error', 'model': 'SMPLify-X', 'value': '52.9', 'row': 4, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'MRR', 'model': '9xFGA (VGG)', 'value': '68.92', 'row': 15, 'column': 1}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@1', 'model': '9xFGA (VGG)', 'value': '55.16', 'row': 15, 'column': 2}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@5', 'model': '9xFGA (VGG)', 'value': '86.26', 'row': 15, 'column': 3}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@10', 'model': '9xFGA (VGG)', 'value': '92.95', 'row': 15, 'column': 4}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'Mean Rank', 'model': '9xFGA (VGG)', 'value': '3.39', 'row': 15, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'MRR', 'model': '5xFGA (F-RCNNx101)', 'value': '69.3', 'row': 9, 'column': 1}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@1', 'model': '5xFGA (F-RCNNx101)', 'value': '55.65', 'row': 9, 'column': 2}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@5', 'model': '5xFGA (F-RCNNx101)', 'value': '86.73', 'row': 9, 'column': 3}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@10', 'model': '5xFGA (F-RCNNx101)', 'value': '94.05', 'row': 9, 'column': 4}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'Mean Rank', 'model': '5xFGA (F-RCNNx101)', 'value': '3.14', 'row': 9, 'column': 5}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'NDCG', 'model': '5xFGA (F-RCNNx101)', 'value': '57.20', 'row': 9, 'column': 6}]}\n","{'index': 0, 'records': [{'task': '3D Multi-person Pose Estimation (absolute)', 'dataset': 'MuPoTS-3D', 'metric': 'MPJPE', 'model': 'Depth Prediction Network', 'value': '292', 'row': 4, 'column': 1}, {'task': '3D Multi-person Pose Estimation (root-relative)', 'dataset': 'MuPoTS-3D', 'metric': 'MPJPE', 'model': 'Depth Prediction Network', 'value': '120', 'row': 4, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'SUN - 0-Shot', 'metric': 'Accuracy', 'model': 'TAFE-Net', 'value': '60.9', 'row': 14, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB-200 - 0-Shot Learning', 'metric': 'Accuracy', 'model': 'TAFE-Net', 'value': '56.9', 'row': 14, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'AWA1 - 0-Shot', 'metric': 'Accuracy', 'model': 'TAFE-Net', 'value': '70.8', 'row': 14, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'AWA2 - 0-Shot', 'metric': 'Accuracy', 'model': 'TAFE-Net', 'value': '69.3', 'row': 14, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'aPY - 0-Shot', 'metric': 'Accuracy', 'model': 'TAFE-Net', 'value': '42.2', 'row': 14, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Image Retrieval', 'dataset': 'CUB-200-2011', 'metric': 'R@1', 'model': 'MS512', 'value': '65.7', 'row': 11, 'column': 1}, {'task': 'Image Retrieval', 'dataset': 'CARS196', 'metric': 'R@1', 'model': 'MS512', 'value': '84.1', 'row': 11, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Image Retrieval', 'dataset': 'In-Shop', 'metric': 'R@1', 'model': 'MS512', 'value': '89.7', 'row': 7, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Image Retrieval', 'dataset': 'SOP', 'metric': 'R@1', 'model': 'MS512', 'value': '78.2', 'row': 10, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Image Clustering', 'dataset': 'CIFAR-10', 'metric': 'NMI', 'model': 'DCCM', 'value': '0.496', 'row': 14, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'CIFAR-10', 'metric': 'Accuracy', 'model': 'DCCM', 'value': '0.623', 'row': 14, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'CIFAR-100', 'metric': 'NMI', 'model': 'DCCM', 'value': '0.285', 'row': 14, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'CIFAR-100', 'metric': 'Accuracy', 'model': 'DCCM', 'value': '0.327', 'row': 14, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'STL-10', 'metric': 'NMI', 'model': 'DCCM', 'value': '0.376', 'row': 14, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'STL-10', 'metric': 'Accuracy', 'model': 'DCCM', 'value': '0.48200000000000004', 'row': 14, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'ImageNet-10', 'metric': 'NMI', 'model': 'DCCM', 'value': '0.608', 'row': 14, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'ImageNet-10', 'metric': 'Accuracy', 'model': 'DCCM', 'value': '0.71', 'row': 14, 'column': 11}, {'task': 'Image Clustering', 'dataset': 'Imagenet-dog-15', 'metric': 'NMI', 'model': 'DCCM', 'value': '0.321', 'row': 14, 'column': 13}, {'task': 'Image Clustering', 'dataset': 'Imagenet-dog-15', 'metric': 'Accuracy', 'model': 'DCCM', 'value': '0.38299999999999995', 'row': 14, 'column': 14}, {'task': 'Image Clustering', 'dataset': 'Tiny-ImageNet', 'metric': 'NMI', 'model': 'DCCM', 'value': '0.22399999999999998', 'row': 14, 'column': 16}, {'task': 'Image Clustering', 'dataset': 'Tiny-ImageNet', 'metric': 'Accuracy', 'model': 'DCCM', 'value': '0.10800000000000001', 'row': 14, 'column': 17}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'MSMT17', 'metric': 'Rank-1', 'model': 'DG-Net', 'value': '77.2', 'row': 5, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'MSMT17', 'metric': 'mAP', 'model': 'DG-Net', 'value': '52.3', 'row': 5, 'column': 6}]}\n","{'index': 8, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'MAP', 'model': 'DG-Net', 'value': '61.1', 'row': 6, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Real-Time Object Detection', 'dataset': 'COCO', 'metric': 'MAP', 'model': 'NAS-FPN AmoebaNet (7 @ 384) + DropBlock', 'value': '48.3', 'row': 24, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'RIDNet', 'value': '31.81', 'row': 2, 'column': 10}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'RIDNet', 'value': '29.34', 'row': 3, 'column': 10}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'RIDNet', 'value': '26.4', 'row': 4, 'column': 10}]}\n","{'index': 3, 'records': [{'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'RIDNet', 'value': '34.01', 'row': 2, 'column': 8}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'RIDNet', 'value': '31.37', 'row': 3, 'column': 8}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'RIDNet', 'value': '28.14', 'row': 4, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR (sRGB)', 'model': 'RIDNet (blind)', 'value': '39.23', 'row': 18, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'SSIM (sRGB)', 'model': 'RIDNet (blind)', 'value': '0.9526', 'row': 18, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'Decouple-SSAD', 'value': '60.2', 'row': 16, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'Decouple-SSAD', 'value': '54.1', 'row': 16, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'Decouple-SSAD', 'value': '44.2', 'row': 16, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.6', 'model': 'Decouple-SSAD', 'value': '32.3', 'row': 16, 'column': 5}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': 'Decouple-SSAD', 'value': '19.1', 'row': 16, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Audio Source Separation', 'dataset': 'MUSIC (multi-source)', 'metric': 'SIR', 'model': 'Co-Separation', 'value': '13.8', 'row': 5, 'column': 5}, {'task': 'Audio Source Separation', 'dataset': 'MUSIC (multi-source)', 'metric': 'SAR', 'model': 'Co-Separation', 'value': '11.3', 'row': 5, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Audio Source Separation', 'dataset': 'AudioSet', 'metric': 'SDR', 'model': 'Co-Separation', 'value': '4.26', 'row': 5, 'column': 1}, {'task': 'Audio Source Separation', 'dataset': 'AudioSet', 'metric': 'SIR', 'model': 'Co-Separation', 'value': '7.07', 'row': 5, 'column': 2}, {'task': 'Audio Source Separation', 'dataset': 'AudioSet', 'metric': 'SAR', 'model': 'Co-Separation', 'value': '13', 'row': 5, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Audio Denoising', 'dataset': 'AV-Bench - Wooden Horse', 'metric': 'NSDR', 'model': 'Co-Separation', 'value': '14.5', 'row': 5, 'column': 1}, {'task': 'Audio Denoising', 'dataset': 'AV-Bench - Violin Yanni', 'metric': 'NSDR', 'model': 'Co-Separation', 'value': '8.53', 'row': 5, 'column': 2}, {'task': 'Audio Denoising', 'dataset': 'AV-Bench - Guitar Solo', 'metric': 'NSDR', 'model': 'Co-Separation', 'value': '11.9', 'row': 5, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'SAGPool_g', 'value': '74.06', 'row': 3, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'SAGPool_h', 'value': '76.45', 'row': 6, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'SAGPool_h', 'value': '71.86', 'row': 6, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'AdaFM-Net', 'value': '32.13', 'row': 1, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma15', 'metric': 'PSNR', 'model': 'AdaFM-Net', 'value': '34.1', 'row': 3, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'AdaFM-Net', 'value': '34.34', 'row': 1, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma75', 'metric': 'PSNR', 'model': 'AdaFM-Net', 'value': '26.35', 'row': 6, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Passage Re-Ranking', 'dataset': 'TREC-PM', 'metric': 'mAP', 'model': 'BERT + Doc2query', 'value': '36.5', 'row': 11, 'column': 1}, {'task': 'Passage Re-Ranking', 'dataset': 'MS MARCO', 'metric': 'MRR', 'model': 'BERT + Doc2query', 'value': '0.368', 'row': 11, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'F1', 'model': 'KD-LSTMreg', 'value': '88.9', 'row': 13, 'column': 3}, {'task': 'Document Classification', 'dataset': 'AAPD', 'metric': 'F1', 'model': 'KD-LSTMreg', 'value': '72.9', 'row': 13, 'column': 5}, {'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'KD-LSTMreg', 'value': '53.7', 'row': 13, 'column': 7}, {'task': 'Document Classification', 'dataset': 'Yelp-14', 'metric': 'Accuracy', 'model': 'KD-LSTMreg', 'value': '69.4', 'row': 13, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Salient Object Detection', 'dataset': 'ECSSD', 'metric': 'F-measure', 'model': 'CPD-R (ResNet50)', 'value': '91.7', 'row': 14, 'column': 4}, {'task': 'Salient Object Detection', 'dataset': 'ECSSD', 'metric': 'MAE', 'model': 'CPD-R (ResNet50)', 'value': '0.037', 'row': 14, 'column': 5}, {'task': 'Salient Object Detection', 'dataset': 'HKU-IS', 'metric': 'F-measure', 'model': 'CPD-R (ResNet50)', 'value': '89.1', 'row': 14, 'column': 7}, {'task': 'Salient Object Detection', 'dataset': 'HKU-IS', 'metric': 'MAE', 'model': 'CPD-R (ResNet50)', 'value': '0.034', 'row': 14, 'column': 8}, {'task': 'Salient Object Detection', 'dataset': 'DUT-OMRON', 'metric': 'F-measure', 'model': 'CPD-R (ResNet50)', 'value': '74.7', 'row': 14, 'column': 10}, {'task': 'Salient Object Detection', 'dataset': 'DUT-OMRON', 'metric': 'MAE', 'model': 'CPD-R (ResNet50)', 'value': '0.056', 'row': 14, 'column': 11}, {'task': 'Salient Object Detection', 'dataset': 'DUTS-test', 'metric': 'F-measure', 'model': 'CPD-R (ResNet50)', 'value': '80.5', 'row': 14, 'column': 13}, {'task': 'Salient Object Detection', 'dataset': 'DUTS-test', 'metric': 'MAE', 'model': 'CPD-R (ResNet50)', 'value': '0.043', 'row': 14, 'column': 14}, {'task': 'Salient Object Detection', 'dataset': 'PASCAL-S', 'metric': 'F-measure', 'model': 'CPD-R (ResNet50)', 'value': '82.4', 'row': 14, 'column': 16}, {'task': 'Salient Object Detection', 'dataset': 'PASCAL-S', 'metric': 'MAE', 'model': 'CPD-R (ResNet50)', 'value': '0.072', 'row': 14, 'column': 17}]}\n","{'index': 4, 'records': [{'task': 'Salient Object Detection', 'dataset': 'SBU', 'metric': 'Balanced Error Rate', 'model': 'CPD', 'value': '4.19', 'row': 10, 'column': 1}, {'task': 'Salient Object Detection', 'dataset': 'ISTD', 'metric': 'Balanced Error Rate', 'model': 'CPD', 'value': '6.76', 'row': 10, 'column': 2}, {'task': 'Salient Object Detection', 'dataset': 'UCF', 'metric': 'Balanced Error Rate', 'model': 'CPD', 'value': '7.21', 'row': 10, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'edGNN (avg)', 'value': '86.9', 'row': 4, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'edGNN (max)', 'value': '88.8', 'row': 5, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'LAS (no LM)', 'value': '3.2', 'row': 13, 'column': 3}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'LAS (no LM)', 'value': '7.7', 'row': 13, 'column': 4}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'LAS (no LM)', 'value': '2.7', 'row': 13, 'column': 5}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'LAS (no LM)', 'value': '6.5', 'row': 13, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'LAS + SpecAugment ', 'value': '2.5', 'row': 20, 'column': 3}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'LAS + SpecAugment', 'value': '5.8', 'row': 20, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Speech Recognition', 'dataset': \"Hub5'00 SwitchBoard\", 'metric': 'SwitchBoard', 'model': 'LAS + SpecAugment (with LM, Switchboard mild policy)', 'value': '6.8', 'row': 19, 'column': 3}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 SwitchBoard\", 'metric': 'CallHome', 'model': 'LAS + SpecAugment (with LM, Switchboard strong policy)', 'value': '14', 'row': 20, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'Pythia v0.3 + LoRRA', 'value': '69.21', 'row': 7, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VizWiz', 'metric': 'Accuracy', 'model': 'Pythia v0.3 (Ours)', 'value': '54.72', 'row': 11, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'TextVQA Val', 'metric': 'Accuracy', 'model': 'Pythia + LoRRA', 'value': '26.56', 'row': 8, 'column': 2}, {'task': 'Visual Question Answering', 'dataset': 'TextVQA Test', 'metric': 'Accuracy', 'model': 'Pythia + LoRRA', 'value': '27.63', 'row': 8, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'J-HMDB', 'metric': 'Accuracy (pose)', 'model': 'EHPI', 'value': '65.5', 'row': 3, 'column': 3}, {'task': 'Skeleton Based Action Recognition', 'dataset': 'JHMDB (2D poses only)', 'metric': 'Average accuracy of 3 splits', 'model': 'EHPI', 'value': '65.5', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Natural Language Inference', 'dataset': 'XNLI Chinese Dev', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '79.9', 'row': 2, 'column': 4}, {'task': 'Natural Language Inference', 'dataset': 'XNLI Chinese', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '78.4', 'row': 2, 'column': 5}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC Dev', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '89.7', 'row': 3, 'column': 4}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '87.4', 'row': 3, 'column': 5}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA Dev', 'metric': 'F1', 'model': 'ERNIE', 'value': '95', 'row': 4, 'column': 4}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'ERNIE', 'value': '93.8', 'row': 4, 'column': 5}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp Dev', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '95.2', 'row': 5, 'column': 4}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '95.4', 'row': 5, 'column': 5}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA Dev', 'metric': 'MRR', 'model': 'ERNIE', 'value': '0.95', 'row': 6, 'column': 4}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'MRR', 'model': 'ERNIE', 'value': '0.951', 'row': 6, 'column': 5}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA Dev', 'metric': 'F1', 'model': 'ERNIE', 'value': '82.3', 'row': 7, 'column': 4}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'F1', 'model': 'ERNIE', 'value': '82.7', 'row': 7, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Lung Nodule Segmentation', 'dataset': 'NIH', 'metric': 'Recall', 'model': 'U-Net+R+A4', 'value': '0.956', 'row': 34, 'column': 1}, {'task': 'Lung Nodule Segmentation', 'dataset': 'NIH', 'metric': 'Precision', 'model': 'U-Net+R+A4', 'value': '0.969', 'row': 34, 'column': 2}, {'task': 'Lung Nodule Segmentation', 'dataset': 'NIH', 'metric': 'Dice Score', 'model': 'U-Net+R+A4', 'value': '0.962', 'row': 34, 'column': 3}, {'task': 'Lung Nodule Segmentation', 'dataset': 'NIH', 'metric': 'AVD', 'model': 'U-Net+R+A4', 'value': '0.262', 'row': 34, 'column': 4}, {'task': 'Lung Nodule Segmentation', 'dataset': 'NIH', 'metric': 'VS', 'model': 'U-Net+R+A4', 'value': '0.985', 'row': 34, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Action Detection', 'dataset': 'UCF101-24', 'metric': 'Video-mAP 0.1', 'model': 'STEP', 'value': '83.1', 'row': 9, 'column': 3}, {'task': 'Action Detection', 'dataset': 'UCF101-24', 'metric': 'Video-mAP 0.2', 'model': 'STEP', 'value': '76.6', 'row': 9, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Salient Object Detection', 'dataset': 'ECSSD', 'metric': 'F-measure', 'model': 'PoolNet (VGG-16)', 'value': '0.945', 'row': 23, 'column': 3}, {'task': 'Salient Object Detection', 'dataset': 'ECSSD', 'metric': 'MAE', 'model': 'PoolNet (VGG-16)', 'value': '0.038', 'row': 23, 'column': 4}, {'task': 'Salient Object Detection', 'dataset': 'PASCAL-S', 'metric': 'F-measure', 'model': 'PoolNet (VGG-16)', 'value': '0.88', 'row': 23, 'column': 5}, {'task': 'Salient Object Detection', 'dataset': 'PASCAL-S', 'metric': 'MAE', 'model': 'PoolNet (VGG-16)', 'value': '0.065', 'row': 23, 'column': 6}, {'task': 'Salient Object Detection', 'dataset': 'DUT-OMRON', 'metric': 'F-measure', 'model': 'PoolNet (VGG-16)', 'value': '0.833', 'row': 23, 'column': 7}, {'task': 'Salient Object Detection', 'dataset': 'DUT-OMRON', 'metric': 'MAE', 'model': 'PoolNet (VGG-16)', 'value': '0.053', 'row': 23, 'column': 8}, {'task': 'Salient Object Detection', 'dataset': 'HKU-IS', 'metric': 'F-measure', 'model': 'PoolNet (VGG-16)', 'value': '0.935', 'row': 23, 'column': 9}, {'task': 'Salient Object Detection', 'dataset': 'HKU-IS', 'metric': 'MAE', 'model': 'PoolNet (VGG-16)', 'value': '0.03', 'row': 23, 'column': 10}, {'task': 'Salient Object Detection', 'dataset': 'SOD', 'metric': 'F-measure', 'model': 'PoolNet (VGG-16)', 'value': '0.882', 'row': 23, 'column': 11}, {'task': 'Salient Object Detection', 'dataset': 'SOD', 'metric': 'MAE', 'model': 'PoolNet (VGG-16)', 'value': '0.102', 'row': 23, 'column': 12}, {'task': 'Salient Object Detection', 'dataset': 'DUTS-TE', 'metric': 'F-measure', 'model': 'PoolNet (VGG-16)', 'value': '0.892', 'row': 23, 'column': 13}, {'task': 'Salient Object Detection', 'dataset': 'DUTS-TE', 'metric': 'MAE', 'model': 'PoolNet (VGG-16)', 'value': '0.036000000000000004', 'row': 23, 'column': 14}]}\n","{'index': 1, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'PFEfuse+match', 'value': '99.82', 'row': 12, 'column': 2}, {'task': 'Face Verification', 'dataset': 'YouTube Faces DB', 'metric': 'Accuracy', 'model': 'PFEfuse+match', 'value': '97.36', 'row': 12, 'column': 3}, {'task': 'Face Verification', 'dataset': 'MegaFace', 'metric': 'Accuracy', 'model': 'PFEfuse + match', 'value': '92.51', 'row': 12, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.001', 'model': 'PFEfuse + match', 'value': '95.25', 'row': 12, 'column': 2}, {'task': 'Face Verification', 'dataset': 'IJB-A', 'metric': 'TAR @ FAR=0.01', 'model': 'PFEfuse + match', 'value': '97.5', 'row': 12, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Face Verification', 'dataset': 'IJB-C', 'metric': 'TAR @ FAR=0.001', 'model': 'PFEfuse + match', 'value': '89.64', 'row': 8, 'column': 2}, {'task': 'Face Verification', 'dataset': 'IJB-C', 'metric': 'TAR @ FAR=0.001', 'model': 'PFEfuse + match', 'value': '93.25', 'row': 8, 'column': 3}, {'task': 'Face Verification', 'dataset': 'IJB-C', 'metric': 'TAR @ FAR=0.001', 'model': 'PFEfuse + match', 'value': '95.49', 'row': 8, 'column': 4}, {'task': 'Face Verification', 'dataset': 'IJB-C', 'metric': 'TAR @ FAR=0.01', 'model': 'PFEfuse + match', 'value': '97.17', 'row': 8, 'column': 5}]}\n","{'index': 0, 'records': [{'task': '3D Object Detection', 'dataset': 'SUN-RGBD val', 'metric': 'MAP', 'model': 'VoteNet (Geo only)', 'value': '57.7', 'row': 5, 'column': 12}]}\n","{'index': 1, 'records': [{'task': '3D Object Detection', 'dataset': 'ScanNetV2', 'metric': 'mAP@0.25', 'model': 'VoteNet', 'value': '46.8', 'row': 9, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'ScanNetV2', 'metric': 'mAP@0.5', 'model': 'VoteNet', 'value': '24.7', 'row': 9, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'AdaptSetNet-SWa', 'value': '35.7', 'row': 4, 'column': 20}]}\n","{'index': 5, 'records': [{'task': 'Group Activity Recognition', 'dataset': 'Volleyball', 'metric': 'Accuracy', 'model': 'GTT (VGG19)', 'value': '92.6', 'row': 12, 'column': 2}, {'task': 'Action Recognition In Videos', 'dataset': 'Volleyball', 'metric': 'Accuracy', 'model': 'GTT (VGG19)', 'value': '82.6', 'row': 12, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Group Activity Recognition', 'dataset': 'Collective Activity', 'metric': 'Accuracy', 'model': 'GT (Inception-v3)', 'value': '91', 'row': 8, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'Bidirectional Learning', 'value': '41.3', 'row': 12, 'column': 21}]}\n","{'index': 5, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'Bidirectional Learning', 'value': '39', 'row': 9, 'column': 18}]}\n","{'index': 0, 'records': [{'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma5', 'metric': 'PSNR', 'model': 'Spatial-CNN', 'value': '39.73', 'row': 1, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma10', 'metric': 'PSNR', 'model': 'Spatial-CNN', 'value': '35.92', 'row': 1, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma15', 'metric': 'PSNR', 'model': 'Spatial-CNN', 'value': '33.66', 'row': 1, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma25', 'metric': 'PSNR', 'model': 'Spatial-CNN', 'value': '30.99', 'row': 1, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma35', 'metric': 'PSNR', 'model': 'Spatial-CNN', 'value': '29.34', 'row': 1, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma50', 'metric': 'PSNR', 'model': 'Spatial-CNN', 'value': '27.63', 'row': 1, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'Deep Constrained Dominant Sets', 'value': '93.3', 'row': 14, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'Deep Constrained Dominant Sets', 'value': '95.4', 'row': 14, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'Deep Constrained Dominant Sets', 'value': '98.3', 'row': 14, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-1', 'model': 'Deep Constrained Dominant Sets', 'value': '95.8', 'row': 9, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03', 'metric': 'Rank-5', 'model': 'Deep Constrained Dominant Sets', 'value': '99.1', 'row': 9, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'Deep Constrained Dominant Sets', 'value': '86.1', 'row': 13, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'Deep Constrained Dominant Sets', 'value': '88.5', 'row': 13, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Multi-Task Learning', 'dataset': 'HVU', 'metric': 'Tags(Object, Scene, etc)', 'model': 'HATNet', 'value': '55.2', 'row': 3, 'column': 1}, {'task': 'Multi-Task Learning', 'dataset': 'HVU', 'metric': 'Action', 'model': 'HATNet', 'value': '50.1', 'row': 3, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'HATNet (32 frames)', 'value': '97.8', 'row': 24, 'column': 3}, {'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'HATNet (32 frames)', 'value': '76.5', 'row': 24, 'column': 4}, {'task': 'Action Classification', 'dataset': 'Kinetics-400', 'metric': 'Accuracy', 'model': 'HATNet (32 frames)', 'value': '77.6', 'row': 24, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Scene Graph Detection', 'dataset': 'VRD', 'metric': 'R@20', 'model': 'LimLabel (Categ. + Spat.)', 'value': '17.67', 'row': 14, 'column': 2}, {'task': 'Scene Graph Detection', 'dataset': 'ImageCLEF-DA', 'metric': 'R@50', 'model': 'LimLabel (Categ. + Spat.)', 'value': '18.69', 'row': 14, 'column': 3}, {'task': 'Scene Graph Detection', 'dataset': 'ImageCLEF-DA', 'metric': 'R@100', 'model': 'LimLabel (Categ. + Spat.)', 'value': '19.28', 'row': 14, 'column': 4}, {'task': 'Scene Graph Classification', 'dataset': 'ImageCLEF-DA', 'metric': 'R@20', 'model': 'LimLabel (Categ. + Spat.)', 'value': '20.91', 'row': 14, 'column': 5}, {'task': 'Scene Graph Classification', 'dataset': 'ImageCLEF-DA', 'metric': 'R@50', 'model': 'LimLabel (Categ. + Spat.)', 'value': '21.34', 'row': 14, 'column': 6}, {'task': 'Scene Graph Classification', 'dataset': 'ImageCLEF-DA', 'metric': 'R@100', 'model': 'LimLabel (Categ. + Spat.)', 'value': '21.44', 'row': 14, 'column': 7}, {'task': 'Predicate Classification', 'dataset': 'ImageCLEF-DA', 'metric': 'R@20', 'model': 'LimLabel (Categ. + Spat.)', 'value': '45.49', 'row': 14, 'column': 8}, {'task': 'Predicate Classification', 'dataset': 'ImageCLEF-DA', 'metric': 'R@50', 'model': 'LimLabel (Categ. + Spat.)', 'value': '47.04', 'row': 14, 'column': 9}, {'task': 'Predicate Classification', 'dataset': 'ImageCLEF-DA', 'metric': 'R@100', 'model': 'LimLabel (Categ. + Spat.)', 'value': '47.53', 'row': 14, 'column': 10}]}\n","{'index': 3, 'records': [{'task': 'Scene Graph Detection', 'dataset': 'Visual Genome', 'metric': 'R@20', 'model': 'LimLabel (Categ. + Spat.)', 'value': '4.04', 'row': 3, 'column': 1}, {'task': 'Scene Graph Detection', 'dataset': 'Visual Genome', 'metric': 'R@50', 'model': 'LimLabel (Categ. + Spat.)', 'value': '6.75', 'row': 3, 'column': 2}, {'task': 'Scene Graph Detection', 'dataset': 'Visual Genome', 'metric': 'R@100', 'model': 'LimLabel (Categ. + Spat.)', 'value': '8.64', 'row': 3, 'column': 3}, {'task': 'Scene Graph Classification', 'dataset': 'Visual Genome', 'metric': 'R@20', 'model': 'LimLabel (Categ. + Spat.)', 'value': '12.69', 'row': 3, 'column': 4}, {'task': 'Scene Graph Classification', 'dataset': 'Visual Genome', 'metric': 'R@50', 'model': 'LimLabel (Categ. + Spat.)', 'value': '13.91', 'row': 3, 'column': 5}, {'task': 'Scene Graph Classification', 'dataset': 'Visual Genome', 'metric': 'R@100', 'model': 'LimLabel (Categ. + Spat.)', 'value': '14.16', 'row': 3, 'column': 6}, {'task': 'Predicate Classification', 'dataset': 'Visual Genome', 'metric': 'R@20', 'model': 'LimLabel (Categ. + Spat.)', 'value': '24.72', 'row': 3, 'column': 7}, {'task': 'Predicate Classification', 'dataset': 'Visual Genome', 'metric': 'R@50', 'model': 'LimLabel (Categ. + Spat.)', 'value': '27.76', 'row': 3, 'column': 8}, {'task': 'Predicate Classification', 'dataset': 'Visual Genome', 'metric': 'R@100', 'model': 'LimLabel (Categ. + Spat.)', 'value': '28.53', 'row': 3, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 20M', 'metric': 'AUC', 'model': 'KGCN-sum', 'value': '0.978', 'row': 8, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 20M', 'metric': 'F1', 'model': 'KGCN-sum', 'value': '0.932', 'row': 8, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Book-Crossing', 'metric': 'AUC', 'model': 'KGCN-sum', 'value': '73.8', 'row': 8, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Book-Crossing', 'metric': 'F1', 'model': 'KGCN-sum', 'value': '0.688', 'row': 8, 'column': 4}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Last.FM', 'metric': 'AUC', 'model': 'KGCN-concat', 'value': '0.796', 'row': 9, 'column': 5}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Last.FM', 'metric': 'F1', 'model': 'KGCN-concat', 'value': '0.721', 'row': 9, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'NTU RGB+D', 'metric': 'Accuracy (CV)', 'model': 'AS-GCN', 'value': '94.2', 'row': 13, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'Kinetics-Skeleton dataset', 'metric': 'Accuracy', 'model': 'AS-GCN', 'value': '34.8', 'row': 5, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'BERT Finetune + UDA', 'value': '95.8', 'row': 15, 'column': 2}, {'task': 'Text Classification', 'dataset': 'Yelp-2', 'metric': 'Accuracy', 'model': 'BERT Finetune + UDA', 'value': '97.95', 'row': 15, 'column': 3}, {'task': 'Text Classification', 'dataset': 'Yelp-5', 'metric': 'Accuracy', 'model': 'BERT Finetune + UDA', 'value': '67.92', 'row': 15, 'column': 4}, {'task': 'Text Classification', 'dataset': 'Amazon-2', 'metric': 'Error', 'model': 'BERT Finetune + UDA', 'value': '3.5', 'row': 15, 'column': 5}, {'task': 'Text Classification', 'dataset': 'Amazon-5', 'metric': 'Error', 'model': 'BERT Finetune + UDA', 'value': '37.12', 'row': 15, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 4000 Labels', 'metric': 'Accuracy', 'model': 'UDA', 'value': '94.73', 'row': 12, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 1000 labels', 'metric': 'Accuracy', 'model': 'UDA', 'value': '97.54', 'row': 12, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'ImageNet - 10% labeled data', 'metric': 'Top 5 Accuracy', 'model': 'UDA', 'value': '88.52', 'row': 2, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'ResNet-50 (UDA)', 'value': '79.04', 'row': 3, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'Dyna. AdaCos', 'value': '99.73', 'row': 6, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Face Verification', 'dataset': 'MegaFace', 'metric': 'Accuracy', 'model': 'Dynamic AdaCos', 'value': '99.88', 'row': 6, 'column': 1}]}\n","{'index': 0, 'records': [{'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'AP', 'model': 'RRPN + R101 - F', 'value': '43', 'row': 4, 'column': 1}, {'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'AP50', 'model': 'RRPN + R101 - F', 'value': '64.9', 'row': 4, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'AP75', 'model': 'RRPN + R101 - F', 'value': '48.5', 'row': 4, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'AR', 'model': 'RRPN + R101 - F', 'value': '48.6', 'row': 4, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'ARs', 'model': 'RRPN + R101 - F', 'value': '4', 'row': 4, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'ARm', 'model': 'RRPN + R101 - F', 'value': '41.2', 'row': 4, 'column': 6}, {'task': '3D Object Detection', 'dataset': 'nuScenes-F', 'metric': 'ARI', 'model': 'RRPN + R101 - F', 'value': '58.2', 'row': 4, 'column': 7}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'AP', 'model': 'RRPN + R101 - FB', 'value': '35.5', 'row': 8, 'column': 1}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'AP50', 'model': 'RRPN + R101 - FB', 'value': '59', 'row': 8, 'column': 2}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'AP75', 'model': 'RRPN + R101 - FB', 'value': '37', 'row': 8, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'AR', 'model': 'RRPN + R101 - FB', 'value': '42.1', 'row': 8, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'ARs', 'model': 'RRPN + R101 - FB', 'value': '21.1', 'row': 8, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'ARm', 'model': 'RRPN + R101 - FB', 'value': '39.1', 'row': 8, 'column': 6}, {'task': '3D Object Detection', 'dataset': 'nuScenes-FB', 'metric': 'ARI', 'model': 'RRPN + R101 - FB', 'value': '51.4', 'row': 8, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Panoptic Segmentation', 'dataset': 'Cityscapes val', 'metric': 'PQth', 'model': 'TASCNet (ResNet-50, multi-scale)', 'value': '56.1', 'row': 9, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'EGNN + Transduction', 'value': '76.37', 'row': 12, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'EGNN+Transduction', 'value': '80.15', 'row': 9, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Entity Typing', 'dataset': 'Ontonotes v5 (English)', 'metric': 'Precision', 'model': 'ELMo (distant denoising data)', 'value': '51.5', 'row': 4, 'column': 1}, {'task': 'Entity Typing', 'dataset': 'Ontonotes v5 (English)', 'metric': 'Recall', 'model': 'ELMo (distant denoising data)', 'value': '33', 'row': 4, 'column': 2}, {'task': 'Entity Typing', 'dataset': 'Ontonotes v5 (English)', 'metric': 'F1', 'model': 'ELMo (distant denoising data)', 'value': '40.2', 'row': 4, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Link Prediction', 'dataset': 'Amazon', 'metric': 'ROC AUC', 'model': 'GATNE-T', 'value': '97.44', 'row': 12, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Amazon', 'metric': 'PR AUC', 'model': 'GATNE-T', 'value': '97.05', 'row': 12, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Amazon', 'metric': 'F1-Score', 'model': 'GATNE-T', 'value': '92.87', 'row': 12, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'YouTube', 'metric': 'ROC AUC', 'model': 'GATNE-T', 'value': '84.61', 'row': 12, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'YouTube', 'metric': 'PR AUC', 'model': 'GATNE-T', 'value': '81.93', 'row': 12, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'YouTube', 'metric': 'F1-Score', 'model': 'GATNE-T', 'value': '76.83', 'row': 12, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'Twitter', 'metric': 'ROC AUC', 'model': 'GATNE-T', 'value': '92.3', 'row': 12, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'Twitter', 'metric': 'PR AUC', 'model': 'GATNE-T', 'value': '91.77', 'row': 12, 'column': 8}, {'task': 'Link Prediction', 'dataset': 'Twitter', 'metric': 'F1-Score', 'model': 'GATNE-T', 'value': '84.96', 'row': 12, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'Alibaba-S', 'metric': 'ROC AUC', 'model': 'GATNE-T', 'value': '66.71', 'row': 12, 'column': 10}, {'task': 'Link Prediction', 'dataset': 'Alibaba-S', 'metric': 'PR AUC', 'model': 'GATNE-T', 'value': '67.55', 'row': 12, 'column': 11}, {'task': 'Link Prediction', 'dataset': 'Alibaba-S', 'metric': 'F1-Score', 'model': 'GATNE-T', 'value': '62.48', 'row': 12, 'column': 12}]}\n","{'index': 4, 'records': [{'task': 'Link Prediction', 'dataset': 'Alibaba', 'metric': 'ROC AUC', 'model': 'GATNE-I', 'value': '84.2', 'row': 5, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Alibaba', 'metric': 'PR AUC', 'model': 'GATNE-I', 'value': '95.04', 'row': 5, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Alibaba', 'metric': 'F1-Score', 'model': 'GATNE-I', 'value': '89.94', 'row': 5, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MobileNet V3-Large 1.0', 'value': '75.2', 'row': 1, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'MobileNet V3-Large 1.0', 'value': '5.4M', 'row': 1, 'column': 3}]}\n","{'index': 7, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'MobileNet V3-Large 1.0', 'value': '72.6', 'row': 1, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'MixMatch', 'value': '95.05', 'row': 3, 'column': 1}, {'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage correct', 'model': 'MixMatch', 'value': '74.12', 'row': 3, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'STL-10, 1000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '89.82', 'row': 5, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'STL-10, 5000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '94.41', 'row': 5, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 250 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.22', 'row': 1, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 500 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.36', 'row': 1, 'column': 2}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 1000 labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.73', 'row': 1, 'column': 3}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 2000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.96', 'row': 1, 'column': 4}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 4000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '97.11', 'row': 1, 'column': 5}, {'task': 'Image Classification', 'dataset': 'SVHN', 'metric': 'Percentage error', 'model': 'MixMatch', 'value': '2.59', 'row': 1, 'column': 6}]}\n","{'index': 5, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 250 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '88.92', 'row': 6, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 500 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '91.35', 'row': 6, 'column': 2}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 1000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '92.25', 'row': 6, 'column': 3}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 2000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '92.97', 'row': 6, 'column': 4}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 4000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '93.76', 'row': 6, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 250 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.22', 'row': 6, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 500 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.36', 'row': 6, 'column': 2}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 1000 labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.73', 'row': 6, 'column': 3}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 2000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '96.96', 'row': 6, 'column': 4}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 4000 Labels', 'metric': 'Accuracy', 'model': 'MixMatch', 'value': '97.11', 'row': 6, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU', 'model': 'MASS (6-layer Transformer)', 'value': '37.5', 'row': 6, 'column': 2}, {'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2014 French-English', 'metric': 'BLEU', 'model': 'MASS (6-layer Transformer)', 'value': '34.9', 'row': 6, 'column': 3}, {'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2016 English-German', 'metric': 'BLEU', 'model': 'MASS (6-layer Transformer)', 'value': '28.3', 'row': 6, 'column': 4}, {'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2016 German-English', 'metric': 'BLEU', 'model': 'MASS (6-layer Transformer)', 'value': '35.2', 'row': 6, 'column': 5}, {'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2016 English-Romanian', 'metric': 'BLEU', 'model': 'MASS (6-layer Transformer)', 'value': '35.2', 'row': 6, 'column': 6}, {'task': 'Unsupervised Machine Translation', 'dataset': 'WMT2016 Romanian-English', 'metric': 'BLEU', 'model': 'MASS (6-layer Transformer)', 'value': '33.1', 'row': 6, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Text Summarization', 'dataset': 'GigaWord', 'metric': 'ROUGE-1', 'model': 'MASS', 'value': '38.73', 'row': 3, 'column': 1}, {'task': 'Text Summarization', 'dataset': 'GigaWord', 'metric': 'ROUGE-2', 'model': 'MASS', 'value': '19.71', 'row': 3, 'column': 2}, {'task': 'Text Summarization', 'dataset': 'GigaWord', 'metric': 'ROUGE-L', 'model': 'MASS', 'value': '35.96', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Video Super-Resolution', 'dataset': 'Vid4 - 4x upscaling', 'metric': 'PSNR', 'model': 'EDVR', 'value': '27.35', 'row': 6, 'column': 9}]}\n","{'index': 3, 'records': [{'task': 'Deblurring', 'dataset': 'REDS', 'metric': 'Average PSNR', 'model': 'EDVR_Deblur', 'value': '34.8', 'row': 5, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Pose Tracking', 'dataset': 'PoseTrack2017', 'metric': 'MAP', 'model': 'GT Detections', 'value': '81.7', 'row': 2, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Emotion Recognition in Conversation', 'dataset': 'IEMOCAP', 'metric': 'Accuracy', 'model': 'DialogueRNN', 'value': '63.4', 'row': 9, 'column': 13}, {'task': 'Emotion Recognition in Conversation', 'dataset': 'IEMOCAP', 'metric': 'F1', 'model': 'DialogueRNN', 'value': '62.75%', 'row': 9, 'column': 14}]}\n","{'index': 3, 'records': [{'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'Hybrid model with Transformer rescoring', 'value': '2.3', 'row': 14, 'column': 7}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'Hybrid model with Transformer rescoring', 'value': '5.0', 'row': 14, 'column': 8}]}\n","{'index': 0, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Mesh Regression (Graph + SMPL)', 'value': '113.2', 'row': 4, 'column': 1}, {'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Mean Reconstruction Error (mm)', 'model': 'Mesh Regression (Graph + SMPL)', 'value': '61.3', 'row': 4, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'FERPlus', 'metric': 'Accuracy', 'model': 'RAN (VGG-16)', 'value': '89.16', 'row': 5, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'AffectNet', 'metric': 'Accuracy', 'model': 'RAN (ResNet-18+)', 'value': '59.5', 'row': 5, 'column': 3}]}\n","{'index': 7, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'SFEW', 'metric': 'Accuracy', 'model': 'RAN (VGG16+ResNet18)', 'value': '56.4', 'row': 5, 'column': 3}]}\n","{'index': 8, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'RAF-DB', 'metric': 'Accuracy', 'model': 'RAN (ResNet-18)', 'value': '86.9', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'Bundle Adjustment', 'value': '63.3', 'row': 7, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Recommendation Systems', 'dataset': 'MovieLens 20M', 'metric': 'Recall@2', 'model': 'KGNN-LS', 'value': '0.043', 'row': 8, 'column': 1}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 20M', 'metric': 'Recall@10', 'model': 'KGNN-LS', 'value': '0.155', 'row': 8, 'column': 2}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 20M', 'metric': 'Recall@50', 'model': 'KGNN-LS', 'value': '0.321', 'row': 8, 'column': 3}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 20M', 'metric': 'Recall@100', 'model': 'KGNN-LS', 'value': '0.458', 'row': 8, 'column': 4}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'Recall@2', 'model': 'KGNN-LS', 'value': '0.045', 'row': 8, 'column': 5}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'Recall@10', 'model': 'KGNN-LS', 'value': '0.082', 'row': 8, 'column': 6}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'Recall@50', 'model': 'KGNN-LS', 'value': '0.117', 'row': 8, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'Recall@100', 'model': 'KGNN-LS', 'value': '0.149', 'row': 8, 'column': 8}, {'task': 'Recommendation Systems', 'dataset': 'Last.FM', 'metric': 'Recall@2', 'model': 'KGNN-LS', 'value': '0.044', 'row': 8, 'column': 9}, {'task': 'Recommendation Systems', 'dataset': 'Last.FM', 'metric': 'Recall@10', 'model': 'KGNN-LS', 'value': '0.122', 'row': 8, 'column': 10}, {'task': 'Recommendation Systems', 'dataset': 'Last.FM', 'metric': 'Recall@50', 'model': 'KGNN-LS', 'value': '0.277', 'row': 8, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Last.FM', 'metric': 'Recall@100', 'model': 'KGNN-LS', 'value': '0.370', 'row': 8, 'column': 12}, {'task': 'Recommendation Systems', 'dataset': 'Dianping-Food', 'metric': 'Recall@2', 'model': 'KGNN-LS', 'value': '0.047', 'row': 8, 'column': 13}, {'task': 'Recommendation Systems', 'dataset': 'Dianping-Food', 'metric': 'Recall@10', 'model': 'KGNN-LS', 'value': '0.17', 'row': 8, 'column': 14}, {'task': 'Recommendation Systems', 'dataset': 'Dianping-Food', 'metric': 'Recall@50', 'model': 'KGNN-LS', 'value': '0.34', 'row': 8, 'column': 15}, {'task': 'Recommendation Systems', 'dataset': 'Dianping-Food', 'metric': 'Recall@100', 'model': 'KGNN-LS', 'value': '0.487', 'row': 8, 'column': 16}]}\n","{'index': 7, 'records': [{'task': 'One-Shot 3D Action Recognition', 'dataset': 'NTU RGB+D 120', 'metric': 'Accuracy', 'model': 'APSR', 'value': '45.3', 'row': 4, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'SSD (CutMix)', 'value': '76.7', 'row': 5, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'ResNet-50 (CutMix)', 'value': '78.4', 'row': 13, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'ResNet-50 (CutMix)', 'value': '94.10', 'row': 13, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'ResNeXt-101 (CutMix)', 'value': '81.53', 'row': 4, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'ResNeXt-101 (CutMix)', 'value': '94.97', 'row': 4, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage correct', 'model': 'PyramidNet-200 + Shakedrop + Cutmix', 'value': '86.19', 'row': 15, 'column': 1}]}\n","{'index': 6, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'PyramidNet-200 + CutMix', 'value': '97.12', 'row': 5, 'column': 1}]}\n","{'index': 9, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'SSD (ResNet-50, CutMix)', 'value': '77.6', 'row': 5, 'column': 2}]}\n","{'index': 13, 'records': [{'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'BLEU-1', 'model': 'NIC (ResNet-50, CutMix)', 'value': '64.2', 'row': 4, 'column': 1}, {'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'BLEU-2', 'model': 'NIC (ResNet-50, CutMix)', 'value': '46.3', 'row': 4, 'column': 2}, {'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'BLEU-3', 'model': 'NIC (ResNet-50, CutMix)', 'value': '33.6', 'row': 4, 'column': 3}, {'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'BLEU-4', 'model': 'NIC (ResNet-50, CutMix)', 'value': '24.9', 'row': 4, 'column': 4}, {'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'METEOR', 'model': 'NIC (ResNet-50, CutMix)', 'value': '23.1', 'row': 4, 'column': 5}, {'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'ROUGE', 'model': 'NIC (ResNet-50, CutMix)', 'value': '49', 'row': 4, 'column': 6}, {'task': 'Image Captioning', 'dataset': 'COCO', 'metric': 'CIDEr', 'model': 'NIC (ResNet-50, CutMix)', 'value': '77.6', 'row': 4, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Node Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'Graph U-Nets', 'value': '84.4', 'row': 6, 'column': 1}, {'task': 'Node Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'Graph U-Nets', 'value': '73.2', 'row': 6, 'column': 2}, {'task': 'Node Classification', 'dataset': 'Pubmed', 'metric': 'Accuracy', 'model': 'Graph U-Nets', 'value': '79.6', 'row': 6, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'Graph U-Nets', 'value': '82.43', 'row': 6, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'Graph U-Nets', 'value': '77.68', 'row': 6, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'Graph U-Nets', 'value': '77.56', 'row': 6, 'column': 3}]}\n","{'index': 7, 'records': [{'task': 'Node Classification', 'dataset': 'Cora: fixed 20 node per class', 'metric': 'Accuracy', 'model': 'g-U-Nets (Ours)', 'value': '75737', 'row': 2, 'column': 2}]}\n","{'index': 6, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'HSML', 'value': '50.38', 'row': 16, 'column': 1}]}\n","{'index': 5, 'records': [{'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'BERT-ITPT-FiT', 'value': '95.63', 'row': 13, 'column': 1}, {'task': 'Text Classification', 'dataset': 'Yelp-2', 'metric': 'Accuracy', 'model': 'BERT-ITPT-FiT', 'value': '98.08', 'row': 13, 'column': 2}, {'task': 'Text Classification', 'dataset': 'Yelp-5', 'metric': 'Accuracy', 'model': 'BERT-ITPT-FiT', 'value': '70.58', 'row': 13, 'column': 3}, {'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'BERT-ITPT-FiT', 'value': '3.2', 'row': 13, 'column': 4}, {'task': 'Text Classification', 'dataset': 'Yahoo! Answers', 'metric': 'Accuracy', 'model': 'BERT-ITPT-FiT', 'value': '77.62', 'row': 13, 'column': 5}, {'task': 'Text Classification', 'dataset': 'AG News', 'metric': 'Error', 'model': 'BERT-ITPT-FiT', 'value': '4.8', 'row': 13, 'column': 6}, {'task': 'Text Classification', 'dataset': 'DBpedia', 'metric': 'Error', 'model': 'BERT-ITPT-FiT', 'value': '0.68', 'row': 13, 'column': 7}, {'task': 'Text Classification', 'dataset': 'Sogou News', 'metric': 'Accuracy', 'model': 'BERT-ITPT-FiT', 'value': '98.07', 'row': 13, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Object Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'GMNN', 'value': '83.7', 'row': 9, 'column': 2}, {'task': 'Object Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'GMNN', 'value': '72.9', 'row': 9, 'column': 3}, {'task': 'Object Classification', 'dataset': 'Pubmed', 'metric': 'Accuracy', 'model': 'GMNN', 'value': '81.8', 'row': 9, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'TapNet', 'value': '98.07', 'row': 10, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'TapNet', 'value': '99.49', 'row': 10, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'TapNet', 'value': '61.65', 'row': 10, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'TapNet', 'value': '76.36', 'row': 10, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'TapNet', 'value': '63.08', 'row': 6, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'TapNet', 'value': '80.26', 'row': 6, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Entity Linking', 'dataset': 'FIGER', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '57.19', 'row': 4, 'column': 1}, {'task': 'Entity Linking', 'dataset': 'FIGER', 'metric': 'Macro F1', 'model': 'ERNIE', 'value': '76.51', 'row': 4, 'column': 2}, {'task': 'Entity Linking', 'dataset': 'FIGER', 'metric': 'Micro F1', 'model': 'ERNIE', 'value': '73.39', 'row': 4, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Entity Typing', 'dataset': ' Open Entity', 'metric': 'Precision', 'model': 'ERNIE', 'value': '78.42', 'row': 4, 'column': 1}, {'task': 'Entity Typing', 'dataset': ' Open Entity', 'metric': 'Recall', 'model': 'ERNIE', 'value': '72.9', 'row': 4, 'column': 2}, {'task': 'Entity Typing', 'dataset': ' Open Entity', 'metric': 'F1', 'model': 'ERNIE', 'value': '75.56', 'row': 4, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Relation Extraction', 'dataset': 'FewRel', 'metric': 'Precision', 'model': 'ERNIE', 'value': '88.49', 'row': 6, 'column': 1}, {'task': 'Relation Extraction', 'dataset': 'FewRel', 'metric': 'Recall', 'model': 'ERNIE', 'value': '88.44', 'row': 6, 'column': 2}, {'task': 'Relation Extraction', 'dataset': 'FewRel', 'metric': 'F1', 'model': 'ERNIE', 'value': '88.32', 'row': 6, 'column': 3}, {'task': 'Relation Extraction', 'dataset': 'TACRED', 'metric': 'Precision', 'model': 'ERNIE', 'value': '69.97', 'row': 6, 'column': 4}, {'task': 'Relation Extraction', 'dataset': 'TACRED', 'metric': 'Recall', 'model': 'ERNIE', 'value': '66.08', 'row': 6, 'column': 5}, {'task': 'Relation Extraction', 'dataset': 'TACRED', 'metric': 'F1', 'model': 'ERNIE', 'value': '67.97', 'row': 6, 'column': 6}]}\n","{'index': 5, 'records': [{'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'ERNIE', 'value': '84.0', 'row': 3, 'column': 1}, {'task': 'Paraphrase Identification', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '71.2', 'row': 3, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '91.3', 'row': 3, 'column': 3}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '93.5', 'row': 3, 'column': 4}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '52.3', 'row': 7, 'column': 1}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'ERNIE', 'value': '83.2', 'row': 7, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '88.2', 'row': 7, 'column': 3}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'ERNIE', 'value': '68.8', 'row': 7, 'column': 4}]}\n","{'index': 7, 'records': [{'task': 'Node Classification', 'dataset': 'Amazon2M', 'metric': 'F1', 'model': 'Cluster-GCN', 'value': '90.41', 'row': 4, 'column': 6}]}\n","{'index': 9, 'records': [{'task': 'Node Classification', 'dataset': 'PPI', 'metric': 'F1', 'model': 'Cluster-GCN', 'value': '99.36', 'row': 7, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Talking Head Generation', 'dataset': 'VoxCeleb1 - 32-shot learning', 'metric': 'FID', 'model': 'Few-shot Adversarial Model', 'value': '29.5', 'row': 10, 'column': 1}, {'task': 'Talking Head Generation', 'dataset': 'VoxCeleb2 - 32-shot learning', 'metric': 'FID', 'model': 'Few-shot Adversarial Model', 'value': '30.6', 'row': 17, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '94.14', 'row': 4, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '78.97', 'row': 4, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '73.56', 'row': 4, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '83.85', 'row': 4, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'IMDb-B', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '77.94', 'row': 4, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '54.52', 'row': 4, 'column': 6}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'sGIN', 'value': '80.71', 'row': 4, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'Wine', 'metric': 'Accuracy', 'model': 'sKNN-LDS', 'value': '98', 'row': 2, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'Cancer', 'metric': 'Accuracy', 'model': 'sKNN-LDS', 'value': '95.7', 'row': 2, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'Digits', 'metric': 'Accuracy', 'model': 'sKNN-LDS', 'value': '92.5', 'row': 2, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'sKNN-LDS', 'value': '73.7', 'row': 2, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'sKNN-LDS', 'value': '72.3', 'row': 2, 'column': 5}, {'task': 'Graph Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'sKNN-LDS', 'value': '47.9', 'row': 2, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AUC', 'model': 'sGraphite-VAE', 'value': '93.7', 'row': 4, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AUC', 'model': 'sGraphite-VAE', 'value': '94.1', 'row': 4, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AUC', 'model': 'sGraphite-VAE', 'value': '94.8', 'row': 4, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AP', 'model': 'sGraphite-VAE', 'value': '93.5', 'row': 4, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AP', 'model': 'sGraphite-VAE', 'value': '95.4', 'row': 4, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AP', 'model': 'sGraphite-VAE', 'value': '96.3', 'row': 4, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'NLPISA', 'value': '15.59', 'row': 1, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'NLPISA', 'value': '15.59', 'row': 1, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'CHEPEA', 'value': '14.75', 'row': 2, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'LyRE', 'value': '13.74', 'row': 2, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'GPLC', 'value': '14.06', 'row': 3, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'CHEPEA', 'value': '12.26', 'row': 3, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'LyRE', 'value': '13.74', 'row': 4, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'GPLC', 'value': '12.14', 'row': 4, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'UNSLA', 'value': '13.66', 'row': 5, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'UQAMD', 'value': '11.98', 'row': 5, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'UQAMD', 'value': '13.23', 'row': 6, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'UArizonaD', 'value': '10.23', 'row': 6, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'UArizonaB', 'value': '13.07', 'row': 7, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'FHDO-BCSGA', 'value': '9.69', 'row': 7, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'FHDO-BCSGB', 'value': '12.7', 'row': 8, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'UNSLA', 'value': '9.68', 'row': 8, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'SS3D', 'value': '12.7', 'row': 9, 'column': 1}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'SS3D', 'value': '7.72', 'row': 10, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA-CP', 'metric': 'Score', 'model': 'UpDn+SCR (VQA-X)', 'value': '49.45', 'row': 9, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Unsupervised Text Style Transfer', 'dataset': 'Yelp', 'metric': 'BLEU', 'model': 'DualRL', 'value': '55.2', 'row': 12, 'column': 2}, {'task': 'Unsupervised Text Style Transfer', 'dataset': 'GYAFC', 'metric': 'BLEU', 'model': 'DualRL', 'value': '41.9', 'row': 12, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Multi-Label Text Classification', 'dataset': 'AAPD', 'metric': 'P@1', 'model': 'LAHA', 'value': '84.48', 'row': 1, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'AAPD', 'metric': 'P@3', 'model': 'LAHA', 'value': '60.72', 'row': 2, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'AAPD', 'metric': 'P@5', 'model': 'LAHA', 'value': '41.19', 'row': 3, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'AAPD', 'metric': 'nDCG@3', 'model': 'LAHA', 'value': '80.11', 'row': 4, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'AAPD', 'metric': 'nDCG@5', 'model': 'LAHA', 'value': '83.7', 'row': 5, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Kan-Shan Cup', 'metric': 'P@1', 'model': 'LAHA', 'value': '54.38', 'row': 6, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Kan-Shan Cup', 'metric': 'P@3', 'model': 'LAHA', 'value': '34.6', 'row': 7, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Kan-Shan Cup', 'metric': 'P@5', 'model': 'LAHA', 'value': '25.88', 'row': 8, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Kan-Shan Cup', 'metric': 'nDCG@3', 'model': 'LAHA', 'value': '51.7', 'row': 9, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Kan-Shan Cup', 'metric': 'nDCG@5', 'model': 'LAHA', 'value': '54.65', 'row': 10, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'P@1', 'model': 'LAHA', 'value': '74.95', 'row': 11, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'P@3', 'model': 'LAHA', 'value': '61.48', 'row': 12, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'P@5', 'model': 'LAHA', 'value': '50.71', 'row': 13, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'nDCG@3', 'model': 'LAHA', 'value': '64.89', 'row': 14, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'nDCG@5', 'model': 'LAHA', 'value': '59.28', 'row': 15, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Amazon-12K', 'metric': 'P@1', 'model': 'LAHA', 'value': '94.87', 'row': 16, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Amazon-12K', 'metric': 'P@3', 'model': 'LAHA', 'value': '79.16', 'row': 17, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Amazon-12K', 'metric': 'P@5', 'model': 'LAHA', 'value': '63.16', 'row': 18, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Amazon-12K', 'metric': 'nDCG@3', 'model': 'LAHA', 'value': '89.13', 'row': 19, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Amazon-12K', 'metric': 'nDCG@5', 'model': 'LAHA', 'value': '87.57', 'row': 20, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Wiki-30K', 'metric': 'P@1', 'model': 'LAHA', 'value': '84.18', 'row': 21, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Wiki-30K', 'metric': 'P@3', 'model': 'LAHA', 'value': '73.14', 'row': 22, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Wiki-30K', 'metric': 'P@5', 'model': 'LAHA', 'value': '62.87', 'row': 23, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Wiki-30K', 'metric': 'nDCG@3', 'model': 'LAHA', 'value': '75.64', 'row': 24, 'column': 6}, {'task': 'Multi-Label Text Classification', 'dataset': 'Wiki-30K', 'metric': 'nDCG@5', 'model': 'LAHA', 'value': '67.82', 'row': 25, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Image Generation', 'dataset': 'MNIST', 'metric': 'FID', 'model': 'GLF+perceptual loss (ours)', 'value': '5.8', 'row': 9, 'column': 1}, {'task': 'Image Generation', 'dataset': 'Fashion-MNIST', 'metric': 'FID', 'model': 'GLF+perceptual loss (ours)', 'value': '10.3', 'row': 9, 'column': 2}, {'task': 'Image Generation', 'dataset': 'CIFAR-10', 'metric': 'FID', 'model': 'GLF+perceptual loss (ours)', 'value': '44.6', 'row': 9, 'column': 3}, {'task': 'Image Generation', 'dataset': 'CelebA 256x256', 'metric': 'FID', 'model': 'GLF+perceptual loss (ours)', 'value': '41.8', 'row': 9, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'SVNH-to-MNIST', 'metric': 'Accuracy', 'model': 'SRDA (RAN)', 'value': '98.91', 'row': 17, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'SYNSIG-to-GTSRB', 'metric': 'Accuracy', 'model': 'SRDA (RAN)', 'value': '93.61', 'row': 17, 'column': 2}, {'task': 'Domain Adaptation', 'dataset': 'MNIST-to-USPS', 'metric': 'Accuracy', 'model': 'SRDA (RAN)', 'value': '94.76', 'row': 17, 'column': 3}, {'task': 'Domain Adaptation', 'dataset': 'USPS-to-MNIST', 'metric': 'Accuracy', 'model': 'SRDA (RAN)', 'value': '95.03', 'row': 17, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'SRDA (RAN)', 'value': '73.5', 'row': 10, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'UCF-to-Olympic', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '98.15', 'row': 9, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'Olympic-to-HMDBsmall', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '92.92', 'row': 9, 'column': 2}, {'task': 'Domain Adaptation', 'dataset': 'UCF-to-HMDBsmall', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '99.33', 'row': 9, 'column': 3}, {'task': 'Domain Adaptation', 'dataset': 'HMDBsmall-to-UCF', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '99.47', 'row': 9, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'UCF-to-HMDBfull', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '78.33', 'row': 10, 'column': 2}, {'task': 'Domain Adaptation', 'dataset': 'HMDBfull-to-UCF', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '81.79', 'row': 10, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Video Prediction', 'dataset': 'CMU Mocap-1', 'metric': 'Test Error', 'model': 'ODE2VAE-KL', 'value': '15.99', 'row': 8, 'column': 1}, {'task': 'Video Prediction', 'dataset': 'CMU Mocap-2', 'metric': 'Test Error', 'model': 'ODE2VAE-KL', 'value': '8.09', 'row': 8, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '90.55', 'row': 22, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '66.17', 'row': 22, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '77.2', 'row': 22, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '83.19', 'row': 22, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '81.84', 'row': 22, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '80.16', 'row': 22, 'column': 6}, {'task': 'Graph Classification', 'dataset': 'IMDb-B', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '72.6', 'row': 22, 'column': 7}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'PPGN', 'value': '50', 'row': 22, 'column': 8}]}\n","{'index': 2, 'records': [{'task': 'Color Image Denoising', 'dataset': 'NTIRE 2019 Real Image Denoising Challenge (sRGB)', 'metric': 'PSNR', 'model': 'GRDN', 'value': '39.931743', 'row': 1, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'NTIRE 2019 Real Image Denoising Challenge (sRGB)', 'metric': 'SSIM', 'model': 'GRDN', 'value': '0.9735889999999999', 'row': 1, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Atrial Fibrillation Detection', 'dataset': 'PhysioNet Challenge 2017', 'metric': 'ROC-AUC', 'model': 'MINA', 'value': '0.9488', 'row': 6, 'column': 1}, {'task': 'Atrial Fibrillation Detection', 'dataset': 'PhysioNet Challenge 2017', 'metric': 'PR-AUC', 'model': 'MINA', 'value': '0.9436', 'row': 6, 'column': 2}, {'task': 'Atrial Fibrillation Detection', 'dataset': 'PhysioNet Challenge 2017', 'metric': 'F1', 'model': 'MINA', 'value': '0.8342', 'row': 6, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'IDeMe-Net', 'value': '59.14', 'row': 11, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'IDeMe-Net', 'value': '74.63', 'row': 11, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B0', 'value': '76.3', 'row': 1, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B0', 'value': '93.2', 'row': 1, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B0', 'value': '5.3M', 'row': 1, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B1', 'value': '78.8', 'row': 4, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B1', 'value': '94.4', 'row': 4, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B1', 'value': '7.8M', 'row': 4, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B2', 'value': '79.8', 'row': 9, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B2', 'value': '94.9', 'row': 9, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B2', 'value': '9.2M', 'row': 9, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B3', 'value': '81.1', 'row': 12, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B3', 'value': '95.5', 'row': 12, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B3', 'value': '12M', 'row': 12, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B4', 'value': '82.6', 'row': 15, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B4', 'value': '96.3', 'row': 15, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B4', 'value': '19M', 'row': 15, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B5', 'value': '83.3', 'row': 20, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B5', 'value': '96.7', 'row': 20, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B5', 'value': '30M', 'row': 20, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B6', 'value': '84', 'row': 22, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B6', 'value': '96.9', 'row': 22, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B6', 'value': '43M', 'row': 22, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'EfficientNet-B7', 'value': '84.4', 'row': 23, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'EfficientNet-B7', 'value': '97.1', 'row': 23, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'EfficientNet-B7', 'value': '66M', 'row': 23, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'EfficientNet-B7', 'value': '98.9', 'row': 2, 'column': 11}, {'task': 'Image Classification', 'dataset': 'CIFAR-100', 'metric': 'Percentage correct', 'model': 'EfficientNet-B7', 'value': '91.7', 'row': 3, 'column': 11}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Birdsnap', 'metric': 'Accuracy', 'model': 'EfficientNet-B7', 'value': '84.3', 'row': 4, 'column': 11}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Stanford Cars', 'metric': 'Accuracy', 'model': 'EfficientNet-B7', 'value': '94.7', 'row': 5, 'column': 11}, {'task': 'Image Classification', 'dataset': 'Flowers-102', 'metric': 'Accuracy', 'model': 'EfficientNet-B7', 'value': '98.8', 'row': 6, 'column': 11}, {'task': 'Fine-Grained Image Classification', 'dataset': 'FGVC Aircraft', 'metric': 'Accuracy', 'model': 'EfficientNet-B7', 'value': '92.9', 'row': 7, 'column': 11}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Oxford-IIIT Pets', 'metric': 'Accuracy', 'model': 'EfficientNet-B7', 'value': '95.4', 'row': 8, 'column': 11}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Food-101', 'metric': 'Accuracy', 'model': 'EfficientNet-B7', 'value': '93.0', 'row': 9, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Drug Discovery', 'dataset': 'BBBP', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.687', 'row': 14, 'column': 2}, {'task': 'Drug Discovery', 'dataset': 'Tox21', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.7809999999999999', 'row': 14, 'column': 3}, {'task': 'Drug Discovery', 'dataset': 'ToxCast', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.657', 'row': 14, 'column': 4}, {'task': 'Drug Discovery', 'dataset': 'SIDER', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.627', 'row': 14, 'column': 5}, {'task': 'Drug Discovery', 'dataset': 'ClinTox', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.726', 'row': 14, 'column': 6}, {'task': 'Drug Discovery', 'dataset': 'MUV', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.813', 'row': 14, 'column': 7}, {'task': 'Drug Discovery', 'dataset': 'HIV dataset', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.799', 'row': 14, 'column': 8}, {'task': 'Drug Discovery', 'dataset': 'BACE', 'metric': 'AUC', 'model': 'ContextPred', 'value': '0.845', 'row': 14, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Action Classification', 'dataset': 'Charades', 'metric': 'MAP', 'model': 'AssembleNet', 'value': '51.6', 'row': 12, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Action Classification', 'dataset': 'Moments in Time', 'metric': 'Top 5 Accuracy', 'model': 'AssembleNet', 'value': '57.38', 'row': 9, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Molecular Graph Generation', 'dataset': 'InterBioScreen', 'metric': 'Validity', 'model': 'Scaffold-based (MW)', 'value': '98.3', 'row': 2, 'column': 1}, {'task': 'Molecular Graph Generation', 'dataset': 'InterBioScreen', 'metric': 'Uniqueness', 'model': 'Scaffold-based (MW)', 'value': '83.2', 'row': 2, 'column': 2}, {'task': 'Molecular Graph Generation', 'dataset': 'InterBioScreen', 'metric': 'Novelty', 'model': 'Scaffold-based (MW)', 'value': '98.7', 'row': 2, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'MR', 'metric': 'Accuracy', 'model': 'STM+TSED+PT+2L', 'value': '80.09', 'row': 17, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'SST-5 Fine-grained classification', 'metric': 'Accuracy', 'model': 'STM+TSED+PT+2L', 'value': '49.14', 'row': 17, 'column': 3}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'STM+TSED+PT+2L', 'value': '86.95', 'row': 17, 'column': 4}, {'task': 'Subjectivity Analysis', 'dataset': 'SUBJ', 'metric': 'Accuracy', 'model': 'STM+TSED+PT+2L', 'value': '92.34', 'row': 17, 'column': 5}, {'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'STM+TSED+PT+2L', 'value': '7.04', 'row': 17, 'column': 6}, {'task': 'Sentiment Analysis', 'dataset': 'CR', 'metric': 'Accuracy', 'model': 'STM+TSED+PT+2L', 'value': '82.73', 'row': 17, 'column': 7}, {'task': 'Sentiment Analysis', 'dataset': 'MPQA', 'metric': 'Accuracy', 'model': 'STM+TSED+PT+2L', 'value': '89.83', 'row': 17, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'Caption VQA', 'value': '69.66', 'row': 8, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'LST', 'value': '70.1', 'row': 12, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'LST', 'value': '78.7', 'row': 12, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'LST', 'value': '77.7', 'row': 19, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'LST', 'value': '85.2', 'row': 19, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'WWL', 'value': '87.27', 'row': 5, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'WWL', 'value': '66.31', 'row': 5, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'WWL', 'value': '85.75', 'row': 5, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'WWL', 'value': '74.28', 'row': 5, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'WWL', 'value': '79.69', 'row': 5, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'WWL', 'value': '59.13', 'row': 5, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'Dispersion based Clustering', 'value': '69.2', 'row': 10, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'Dispersion based Clustering', 'value': '83', 'row': 10, 'column': 4}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-10', 'model': 'Dispersion based Clustering', 'value': '87.8', 'row': 10, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'Dispersion based Clustering', 'value': '41.3', 'row': 10, 'column': 6}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'Dispersion based Clustering', 'value': '51.5', 'row': 10, 'column': 7}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'Dispersion based Clustering', 'value': '64.6', 'row': 10, 'column': 8}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-10', 'model': 'Dispersion based Clustering', 'value': '70.1', 'row': 10, 'column': 9}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'Dispersion based Clustering', 'value': '30', 'row': 10, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Declicious', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.2586', 'row': 1, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Declicious', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.3786', 'row': 2, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Declicious', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.1475', 'row': 3, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Declicious', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.1781', 'row': 4, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Tradesy', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.3198', 'row': 5, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Tradesy', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.4505', 'row': 6, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Tradesy', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.1767', 'row': 7, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Tradesy', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.2095', 'row': 8, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Ciao', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.2292', 'row': 9, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Ciao', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.374', 'row': 10, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Ciao', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.1167', 'row': 11, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Ciao', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.1525', 'row': 12, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.3329', 'row': 13, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.4744', 'row': 14, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.1865', 'row': 15, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Book-Crossing', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.2221', 'row': 16, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Amazon C&A', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.3436', 'row': 17, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Amazon C&A', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.4658', 'row': 18, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Amazon C&A', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.2019', 'row': 19, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Amazon C&A', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.2323', 'row': 20, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Pinterest', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.5504', 'row': 21, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Pinterest', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.8108', 'row': 22, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Pinterest', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.258', 'row': 23, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Pinterest', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.3242', 'row': 24, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Flixster', 'metric': 'Hits@10', 'model': 'TransCF', 'value': '0.7309', 'row': 25, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Flixster', 'metric': 'Hits@20', 'model': 'TransCF', 'value': '0.8374', 'row': 26, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Flixster', 'metric': 'nDCG@10', 'model': 'TransCF', 'value': '0.4986', 'row': 27, 'column': 11}, {'task': 'Recommendation Systems', 'dataset': 'Flixster', 'metric': 'nDCG@20', 'model': 'TransCF', 'value': '0.5257', 'row': 28, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Brain Tumor Segmentation', 'dataset': 'BRATS 2018 val', 'metric': 'Dice Score', 'model': 'OM-Net + CGAp', 'value': '91.59', 'row': 12, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Brain Tumor Segmentation', 'dataset': 'BRATS-2015', 'metric': 'Dice Score', 'model': 'OM-Net + CGAp', 'value': '87', 'row': 5, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Brain Tumor Segmentation', 'dataset': 'BRATS-2017 val', 'metric': 'Dice Score', 'model': 'OM-Net + CGAp', 'value': '90.71', 'row': 8, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'RP@5', 'model': 'bert-base', 'value': '79.6', 'row': 13, 'column': 1}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'nDCG@5', 'model': 'bert-base', 'value': '82.3', 'row': 13, 'column': 2}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'Micro F1', 'model': 'bert-base', 'value': '73.2', 'row': 13, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Node Classification', 'dataset': 'Facebook', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '91.9', 'row': 9, 'column': 1}, {'task': 'Node Classification', 'dataset': 'Wiki-Vote', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '99.8', 'row': 9, 'column': 2}, {'task': 'Node Classification', 'dataset': 'BlogCatalog', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '84.9', 'row': 9, 'column': 3}, {'task': 'Node Classification', 'dataset': 'Flickr', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '65.6', 'row': 9, 'column': 4}, {'task': 'Node Classification', 'dataset': 'Brazil Air-Traffic', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '54.3', 'row': 9, 'column': 5}, {'task': 'Node Classification', 'dataset': 'Europe Air-Traffic', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '45.9', 'row': 9, 'column': 6}, {'task': 'Node Classification', 'dataset': 'USA Air-Traffic', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '64.7', 'row': 9, 'column': 7}]}\n","{'index': 5, 'records': [{'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '81.4', 'row': 8, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '57.2', 'row': 8, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '70.8', 'row': 8, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'DEMO-Net(weight)', 'value': '27.2', 'row': 8, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Common Sense Reasoning', 'dataset': 'CommonsenseQA', 'metric': 'Accuracy', 'model': 'CAGE-reasoning', 'value': '64.7', 'row': 4, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'P@1', 'model': 'NLP-Cap', 'value': '97.05', 'row': 1, 'column': 9}, {'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'P@3', 'model': 'NLP-Cap', 'value': '81.27', 'row': 2, 'column': 9}, {'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'P@5', 'model': 'NLP-Cap', 'value': '56.33', 'row': 3, 'column': 9}, {'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'nDCG@1', 'model': 'NLP-Cap', 'value': '97.05', 'row': 4, 'column': 9}, {'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'nDCG@3', 'model': 'NLP-Cap', 'value': '92.47', 'row': 5, 'column': 9}, {'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'nDCG@5', 'model': 'NLP-Cap', 'value': '93.11', 'row': 6, 'column': 9}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'P@1', 'model': 'NLP-Cap', 'value': '80.2', 'row': 7, 'column': 9}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'P@3', 'model': 'NLP-Cap', 'value': '65.48', 'row': 8, 'column': 9}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'P@5', 'model': 'NLP-Cap', 'value': '52.83', 'row': 9, 'column': 9}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'nDCG@1', 'model': 'NLP-Cap', 'value': '80.2', 'row': 10, 'column': 9}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'nDCG@3', 'model': 'NLP-Cap', 'value': '71.11', 'row': 11, 'column': 9}, {'task': 'Multi-Label Text Classification', 'dataset': 'EUR-Lex', 'metric': 'nDCG@5', 'model': 'NLP-Cap', 'value': '68.8', 'row': 12, 'column': 9}]}\n","{'index': 5, 'records': [{'task': 'Question Answering', 'dataset': 'TrecQA', 'metric': 'MAP', 'model': 'NLP-Capsule', 'value': '0.7773', 'row': 11, 'column': 1}, {'task': 'Question Answering', 'dataset': 'TrecQA', 'metric': 'MRR', 'model': 'NLP-Capsule', 'value': '0.7416', 'row': 11, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Medical Image Segmentation', 'dataset': 'CHAOS MRI Dataset', 'metric': 'Dice Score', 'model': 'MS-Dual-Guided', 'value': '86.75', 'row': 8, 'column': 1}, {'task': 'Medical Image Segmentation', 'dataset': 'CHAOS MRI Dataset', 'metric': 'VS', 'model': 'MS-Dual-Guided', 'value': '93.85', 'row': 8, 'column': 2}, {'task': 'Medical Image Segmentation', 'dataset': 'CHAOS MRI Dataset', 'metric': 'MSD', 'model': 'MS-Dual-Guided', 'value': '66', 'row': 8, 'column': 3}, {'task': 'Medical Image Segmentation', 'dataset': 'HSVM', 'metric': 'Dice Score', 'model': 'MS-Dual-Guided', 'value': '83.2', 'row': 17, 'column': 1}, {'task': 'Medical Image Segmentation', 'dataset': 'HSVM', 'metric': 'VS', 'model': 'MS-Dual-Guided', 'value': '94.45', 'row': 17, 'column': 2}, {'task': 'Medical Image Segmentation', 'dataset': 'HSVM', 'metric': 'MSD', 'model': 'MS-Dual-Guided', 'value': '1.19', 'row': 17, 'column': 3}, {'task': 'Brain Tumor Segmentation', 'dataset': 'BRATS 2018', 'metric': 'Dice Score', 'model': 'MS-Dual-Guided', 'value': '0.8037', 'row': 26, 'column': 1}, {'task': 'Brain Tumor Segmentation', 'dataset': 'BRATS 2018', 'metric': 'VS', 'model': 'MS-Dual-Guided', 'value': '93.08', 'row': 26, 'column': 2}, {'task': 'Brain Tumor Segmentation', 'dataset': 'BRATS 2018', 'metric': 'MSD', 'model': 'MS-Dual-Guided', 'value': '0.9', 'row': 26, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'CrossTask', 'metric': 'Recall', 'model': 'Text-Video Embedding', 'value': '33.6', 'row': 4, 'column': 19}]}\n","{'index': 4, 'records': [{'task': 'Video Retrieval', 'dataset': 'YouCook2', 'metric': 'text-to-video R@1', 'model': 'Text-Video Embedding', 'value': '8.2', 'row': 5, 'column': 2}, {'task': 'Video Retrieval', 'dataset': 'YouCook2', 'metric': 'text-to-video R@5', 'model': 'Text-Video Embedding', 'value': '24.5', 'row': 5, 'column': 3}, {'task': 'Video Retrieval', 'dataset': 'YouCook2', 'metric': 'text-to-video R@10', 'model': 'Text-Video Embedding', 'value': '35.3', 'row': 5, 'column': 4}, {'task': 'Video Retrieval', 'dataset': 'YouCook2', 'metric': 'text-to-video Median Rank', 'model': 'Text-Video Embedding', 'value': '24', 'row': 5, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Video Retrieval', 'dataset': 'MSR-VTT', 'metric': 'text-to-video R@1', 'model': 'Text-Video Embedding', 'value': '14.9', 'row': 10, 'column': 2}, {'task': 'Video Retrieval', 'dataset': 'MSR-VTT', 'metric': 'video-to-text R@5', 'model': 'Text-Video Embedding', 'value': '40.2', 'row': 10, 'column': 3}, {'task': 'Video Retrieval', 'dataset': 'MSR-VTT', 'metric': 'text-to-video R@10', 'model': 'Text-Video Embedding', 'value': '52.8', 'row': 10, 'column': 4}, {'task': 'Video Retrieval', 'dataset': 'MSR-VTT', 'metric': 'text-to-video Median Rank', 'model': 'Text-Video Embedding', 'value': '9', 'row': 10, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Video Retrieval', 'dataset': 'LSMDC', 'metric': 'text-to-video R@1', 'model': 'Text-Video Embedding', 'value': '7.2', 'row': 9, 'column': 2}, {'task': 'Video Retrieval', 'dataset': 'LSMDC', 'metric': 'text-to-video R@5', 'model': 'Text-Video Embedding', 'value': '19.6', 'row': 10, 'column': 3}, {'task': 'Video Retrieval', 'dataset': 'LSMDC', 'metric': 'text-to-video R@10', 'model': 'Text-Video Embedding', 'value': '27.9', 'row': 10, 'column': 4}, {'task': 'Video Retrieval', 'dataset': 'LSMDC', 'metric': 'text-to-video Median Rank', 'model': 'Text-Video Embedding', 'value': '40', 'row': 10, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'CADA-P', 'value': '89.5', 'row': 14, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'CADA', 'value': '70.2', 'row': 7, 'column': 13}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'CADA-P', 'value': '88.3', 'row': 9, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'DiCENet', 'value': '75.1', 'row': 11, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes val', 'metric': 'mIoU', 'model': 'DiCENet', 'value': '63.4', 'row': 10, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 val', 'metric': 'mIoU', 'model': 'DiCENet', 'value': '66.5', 'row': 8, 'column': 2}, {'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2012 test', 'metric': 'Mean IoU', 'model': 'DiCENet', 'value': '67.31', 'row': 9, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'DiCENet-512', 'value': '68.4', 'row': 7, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'Faster R-CNN (ResNet-101, feature imit)', 'value': '74.4', 'row': 5, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'Avito', 'metric': 'AUC', 'model': 'DSTN-I', 'value': '0.8395', 'row': 11, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avito', 'metric': 'Log Loss', 'model': 'DSTN-I', 'value': '0.054479999999999994', 'row': 11, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Multi-Person Pose Estimation', 'dataset': 'PoseTrack2017', 'metric': 'Mean mAP', 'model': 'PoseWarper', 'value': '77.9', 'row': 11, 'column': 9}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'PoseTrack2018', 'metric': 'Mean mAP', 'model': 'PoseWarper', 'value': '78', 'row': 17, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Pose Estimation', 'dataset': 'MPII Human Pose', 'metric': 'PCKh-0.5', 'model': 'Stacked Hourglass Networks', 'value': '90.9', 'row': 8, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'Avito', 'metric': 'AUC', 'model': 'DeepMCP', 'value': '0.7927', 'row': 10, 'column': 1}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avito', 'metric': 'Log Loss', 'model': 'DeepMCP', 'value': '0.05517999999999999', 'row': 10, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Company*', 'metric': 'AUC', 'model': 'DeepMCP', 'value': '0.7674', 'row': 10, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Company*', 'metric': 'Log Loss', 'model': 'DeepMCP', 'value': '0.2341', 'row': 10, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Action Classification', 'dataset': 'Kinetics-400', 'metric': 'Top-1 Accuracy', 'model': 'LGD-3D Two-stream (ResNet-101)', 'value': '81.2', 'row': 18, 'column': 2}, {'task': 'Action Classification', 'dataset': 'Kinetics-400', 'metric': 'Top-5 Accuracy', 'model': 'LGD-3D Two-stream (ResNet-101)', 'value': '95.2', 'row': 18, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Action Classification', 'dataset': 'Kinetics-600', 'metric': 'Top-1 Accuracy', 'model': 'LGD-3D Two-stream* (ResNet-101)', 'value': '82.7', 'row': 15, 'column': 2}, {'task': 'Action Classification', 'dataset': 'Kinetics-600', 'metric': 'Top-5 Accuracy', 'model': 'LGD-3D Two-stream* (ResNet-101)', 'value': '96', 'row': 15, 'column': 3}]}\n","{'index': 6, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric': '3-fold Accuracy', 'model': 'LGD-3D Two-stream', 'value': '98.2', 'row': 14, 'column': 2}, {'task': 'Action Recognition In Videos', 'dataset': 'HMDB-51', 'metric': 'Average accuracy of 3 splits', 'model': 'LGD-3D Two-stream', 'value': '80.5', 'row': 14, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Multi-Object Tracking', 'dataset': 'MOT17', 'metric': 'MOTA', 'model': 'DeepMOT-Tracktor', 'value': '53.7', 'row': 1, 'column': 2}, {'task': 'Multi-Object Tracking', 'dataset': 'MOT16', 'metric': 'MOTA', 'model': 'DeepMOT-Tracktor', 'value': '54.8', 'row': 12, 'column': 2}]}\n","{'index': 6, 'records': [{'task': 'Multi-Object Tracking', 'dataset': '2D MOT 2015', 'metric': 'MOTA', 'model': 'DeepMOT-Tracktor', 'value': '44.1', 'row': 1, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '38.13', 'row': 12, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.961', 'row': 12, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '33.78', 'row': 12, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.9209999999999999', 'row': 12, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '32.33', 'row': 12, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.902', 'row': 12, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '33.12', 'row': 12, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.938', 'row': 12, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '39.3', 'row': 12, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.9790000000000001', 'row': 12, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '32.55', 'row': 23, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.9', 'row': 23, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '28.67', 'row': 23, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.785', 'row': 23, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '27.77', 'row': 23, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.743', 'row': 23, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '27.3', 'row': 23, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.818', 'row': 23, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '31.57', 'row': 23, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.92', 'row': 23, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '27.17', 'row': 34, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.785', 'row': 34, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '24.96', 'row': 34, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.642', 'row': 34, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 8x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '24.93', 'row': 34, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 8x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.602', 'row': 34, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '23.04', 'row': 34, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.647', 'row': 34, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'PSNR', 'model': 'HBPN', 'value': '25.24', 'row': 34, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'SSIM', 'model': 'HBPN', 'value': '0.802', 'row': 34, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'VggFace2 - 8x upscaling', 'metric': 'PSNR', 'model': 'Full-GWAInet', 'value': '25.57', 'row': 8, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'WebFace - 8x upscaling', 'metric': 'PSNR', 'model': 'Full-GWAInet', 'value': '27.11', 'row': 8, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese) Dev', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '68.5', 'row': 7, 'column': 1}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese) Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '88.4', 'row': 7, 'column': 2}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese)', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '74.2', 'row': 7, 'column': 3}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese)', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '90.6', 'row': 7, 'column': 4}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese) Challenge', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '31.5', 'row': 7, 'column': 5}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese) Challenge', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '60.1', 'row': 7, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese) Dev', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '89.6', 'row': 7, 'column': 1}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese) Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '94.8', 'row': 7, 'column': 2}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese)', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '89.6', 'row': 7, 'column': 3}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese)', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '94.5', 'row': 7, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Chinese Reading Comprehension', 'dataset': 'CJRC Dev', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '62.1', 'row': 7, 'column': 1}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CJRC Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '82.4', 'row': 7, 'column': 2}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CJRC', 'metric': 'EM', 'model': 'RoBERTa-wwm-ext-large', 'value': '62.4', 'row': 7, 'column': 3}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CJRC', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '82.20', 'row': 7, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '82.1', 'row': 6, 'column': 1}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '81.2', 'row': 6, 'column': 2}]}\n","{'index': 7, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'ChnSentiCorp Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '95.8', 'row': 6, 'column': 1}, {'task': 'Sentiment Analysis', 'dataset': 'ChnSentiCorp', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '95.8', 'row': 6, 'column': 2}]}\n","{'index': 8, 'records': [{'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '90.4', 'row': 7, 'column': 1}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '87', 'row': 7, 'column': 2}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '86.3', 'row': 7, 'column': 3}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '85.8', 'row': 7, 'column': 4}]}\n","{'index': 9, 'records': [{'task': 'Chinese Document Classification', 'dataset': 'THUCNews Dev', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '98.3', 'row': 6, 'column': 1}, {'task': 'Chinese Document Classification', 'dataset': 'THUCNews', 'metric': 'F1', 'model': 'RoBERTa-wwm-ext-large', 'value': '97.8', 'row': 6, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Reading Comprehension', 'dataset': 'RACE', 'metric': 'Accuracy', 'model': 'XLNet', 'value': '85.4', 'row': 5, 'column': 1}, {'task': 'Reading Comprehension', 'dataset': 'RACE', 'metric': 'Accuracy (Middle)', 'model': 'XLNet', 'value': '88.6', 'row': 5, 'column': 2}, {'task': 'Reading Comprehension', 'dataset': 'RACE', 'metric': 'Accuracy (High)', 'model': 'XLNet', 'value': '84.0', 'row': 5, 'column': 3}, {'task': 'Document Ranking', 'dataset': 'ClueWeb09-B', 'metric': 'nDCG@20', 'model': 'XLNet', 'value': '31.10', 'row': 5, 'column': 5}, {'task': 'Document Ranking', 'dataset': 'ClueWeb09-B', 'metric': 'ERR@20', 'model': 'XLNet', 'value': '20.28', 'row': 5, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'EM', 'model': 'XLNet (single model)', 'value': '87.9', 'row': 4, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'XLNet (single model)', 'value': '90.6', 'row': 4, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'XLNet (single model)', 'value': '89.7', 'row': 4, 'column': 4}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'XLNet (single model)', 'value': '95.1', 'row': 4, 'column': 5}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0', 'metric': 'EM', 'model': 'XLNet (single model)', 'value': '87.926', 'row': 8, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0', 'metric': 'F1', 'model': 'XLNet (single model)', 'value': '90.689', 'row': 8, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1', 'metric': 'EM', 'model': 'XLNet (single model)', 'value': '89.898', 'row': 8, 'column': 4}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1', 'metric': 'F1', 'model': 'XLNet (single model)', 'value': '95.080', 'row': 8, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'XLNet', 'value': '96.8', 'row': 6, 'column': 1}, {'task': 'Text Classification', 'dataset': 'Yelp-2', 'metric': 'Accuracy', 'model': 'XLNet', 'value': '98.63', 'row': 6, 'column': 2}, {'task': 'Text Classification', 'dataset': 'Yelp-5', 'metric': 'Accuracy', 'model': 'XLNet', 'value': '72.95', 'row': 6, 'column': 3}, {'task': 'Text Classification', 'dataset': 'DBpedia', 'metric': 'Error', 'model': 'XLNet', 'value': '0.6', 'row': 6, 'column': 4}, {'task': 'Text Classification', 'dataset': 'AG News', 'metric': 'Error', 'model': 'XLNet', 'value': '4.45', 'row': 6, 'column': 5}, {'task': 'Text Classification', 'dataset': 'Amazon-2', 'metric': 'Error', 'model': 'XLNet', 'value': '2.11', 'row': 6, 'column': 6}, {'task': 'Text Classification', 'dataset': 'Amazon-5', 'metric': 'Error', 'model': 'XLNet', 'value': '31.67', 'row': 6, 'column': 7}]}\n","{'index': 4, 'records': [{'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'XLNet (single model)', 'value': '90.8', 'row': 4, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'XLNet (single model)', 'value': '94.9', 'row': 4, 'column': 2}, {'task': 'Question Answering', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'XLNet (single model)', 'value': '92.3', 'row': 4, 'column': 3}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'XLNet (single model)', 'value': '85.9', 'row': 4, 'column': 4}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'XLNet (single model)', 'value': '97', 'row': 4, 'column': 5}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'XLNet (single model)', 'value': '90.8', 'row': 4, 'column': 6}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'XLNet (single model)', 'value': '69', 'row': 4, 'column': 7}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'XLNet (single model)', 'value': '92.5', 'row': 4, 'column': 8}]}\n","{'index': 8, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'IBN-Net50-a', 'value': '88.2', 'row': 10, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'IBN-Net50-a', 'value': '79.1', 'row': 10, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Recommendation Systems', 'dataset': 'MovieLens 20M', 'metric': 'Recall@10', 'model': 'HGN', 'value': '0.1255', 'row': 2, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'Amazon-Book', 'metric': 'Recall@10', 'model': 'HGN', 'value': '0.0429', 'row': 3, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'Amazon-CDs', 'metric': 'Recall@10', 'model': 'HGN', 'value': '0.0426', 'row': 4, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'GoodReads-Children', 'metric': 'Recall@10', 'model': 'HGN', 'value': '0.1263', 'row': 5, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'GoodReads-Comics', 'metric': 'Recall@10', 'model': 'HGN', 'value': '0.1743', 'row': 6, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 20M', 'metric': 'nDCG@10', 'model': 'HGN', 'value': '0.1195', 'row': 8, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'Amazon-Book', 'metric': 'nDCG@10', 'model': 'HGN', 'value': '0.0298', 'row': 9, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'Amazon-CDs', 'metric': 'nDCG@10', 'model': 'HGN', 'value': '0.0233', 'row': 10, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'GoodReads-Children', 'metric': 'nDCG@10', 'model': 'HGN', 'value': '0.113', 'row': 11, 'column': 7}, {'task': 'Recommendation Systems', 'dataset': 'GoodReads-Comics', 'metric': 'nDCG@10', 'model': 'HGN', 'value': '0.1927', 'row': 12, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Recommendation Systems', 'dataset': 'Last.FM', 'metric': 'HR@10', 'model': 'Ekar*', 'value': '0.2483', 'row': 10, 'column': 1}, {'task': 'Recommendation Systems', 'dataset': 'Last.FM', 'metric': 'nDCG@10', 'model': 'Ekar*', 'value': '0.1766', 'row': 10, 'column': 2}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 1M', 'metric': 'HR@10', 'model': 'Ekar*', 'value': '0.1994', 'row': 10, 'column': 3}, {'task': 'Recommendation Systems', 'dataset': 'MovieLens 1M', 'metric': 'nDCG@10', 'model': 'Ekar*', 'value': '0.3699', 'row': 10, 'column': 4}, {'task': 'Recommendation Systems', 'dataset': 'DBbook2014', 'metric': 'HR@10', 'model': 'Ekar*', 'value': '0.1874', 'row': 10, 'column': 5}, {'task': 'Recommendation Systems', 'dataset': 'DBbook2014', 'metric': 'nDCG@10', 'model': 'Ekar*', 'value': '0.1371', 'row': 10, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA-CP', 'metric': 'Score', 'model': 'RUBi', 'value': '47.11', 'row': 10, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'RUBi (ours)', 'value': '63.18', 'row': 2, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 250 Labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '91.68', 'row': 11, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 500 Labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '93.5', 'row': 11, 'column': 2}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 1000 labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '94.41', 'row': 11, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 1000 Labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '82.12', 'row': 11, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 2000 Labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '85.78', 'row': 11, 'column': 2}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 4000 Labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '88.35', 'row': 11, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'cifar-100, 10000 Labels', 'metric': 'Accuracy', 'model': 'SESEMI SSL (ConvNet)', 'value': '61.29', 'row': 7, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'MCANed-6', 'value': '70.63', 'row': 6, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'MCANed-6', 'value': '70.9', 'row': 6, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Link Sign Prediction', 'dataset': 'Bitcoin-Alpha', 'metric': 'Accuracy', 'model': 'SiGAT', 'value': '0.9480', 'row': 2, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Bitcoin-Alpha', 'metric': 'AUC', 'model': 'SiGAT', 'value': '0.9727', 'row': 3, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Bitcoin-Alpha', 'metric': 'Macro-F1', 'model': 'SiGAT', 'value': '0.7138', 'row': 4, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Bitcoin-Alpha', 'metric': 'AUC', 'model': 'SiGAT', 'value': '0.8942', 'row': 5, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Slashdot', 'metric': 'Accuracy', 'model': 'SiGAT', 'value': '0.8482', 'row': 6, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Slashdot', 'metric': 'AUC', 'model': 'SiGAT', 'value': '0.9047', 'row': 7, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Slashdot', 'metric': 'Macro-F1', 'model': 'SiGAT', 'value': '0.7659999999999999', 'row': 8, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Slashdot', 'metric': 'AUC', 'model': 'SiGAT', 'value': '0.8864', 'row': 9, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Epinions', 'metric': 'Accuracy', 'model': 'SiGAT', 'value': '0.9293', 'row': 10, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Epinions', 'metric': 'AUC', 'model': 'SiGAT', 'value': '0.9593', 'row': 11, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Epinions', 'metric': 'Macro-F1', 'model': 'SiGAT', 'value': '0.8449', 'row': 12, 'column': 12}, {'task': 'Link Sign Prediction', 'dataset': 'Epinions', 'metric': 'AUC', 'model': 'SiGAT', 'value': '0.9333', 'row': 13, 'column': 12}]}\n","{'index': 0, 'records': [{'task': 'Instance Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Average Precision', 'model': 'Learnable Margin', 'value': '27.6', 'row': 9, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'NAS-FPN (AmoebaNet-D, learned aug)', 'value': '50.7', 'row': 4, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'NAS-FPN (AmoebaNet-D, learned aug)', 'value': '34.2', 'row': 4, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'NAS-FPN (AmoebaNet-D, learned aug)', 'value': '55.5', 'row': 4, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'NAS-FPN (AmoebaNet-D, learned aug)', 'value': '64.5', 'row': 4, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': 'MAP', 'model': 'Faster R-CNN (ResNet-101, learned aug)', 'value': '78.7', 'row': 2, 'column': 21}]}\n","{'index': 0, 'records': [{'task': 'Video Denoising', 'dataset': 'Set8 sigma10', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '36.08', 'row': 1, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma20', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '33.49', 'row': 2, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma30', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '31.79', 'row': 3, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma40', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '30.55', 'row': 4, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma50', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '29.56', 'row': 5, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Video Denoising', 'dataset': 'DAVIS sigma10', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '38.13', 'row': 1, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma20', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '35.7', 'row': 2, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma30', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '34.08', 'row': 3, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma40', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '32.86', 'row': 4, 'column': 1}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma50', 'metric': 'PSNR', 'model': 'DVDnet', 'value': '31.85', 'row': 5, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Text-Line Extraction', 'dataset': 'DIVA-HisDB', 'metric': 'Line IoU', 'model': 'Semantic Seg Preprocessing', 'value': '99.42', 'row': 5, 'column': 1}, {'task': 'Text-Line Extraction', 'dataset': 'DIVA-HisDB', 'metric': 'Pixel IoU', 'model': 'Semantic Seg Preprocessing', 'value': '96.11', 'row': 5, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '38.34', 'row': 15, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9619', 'row': 15, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '34.43', 'row': 15, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9247', 'row': 15, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '32.47', 'row': 15, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9032', 'row': 15, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '33.54', 'row': 15, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9402', 'row': 15, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '39.75', 'row': 15, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9792', 'row': 15, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '34.86', 'row': 28, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9307', 'row': 28, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '30.8', 'row': 28, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.8498', 'row': 28, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '29.4', 'row': 28, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.8125', 'row': 28, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '29.37', 'row': 28, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.8746', 'row': 28, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '34.94', 'row': 28, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9518', 'row': 28, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '32.74', 'row': 42, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9013', 'row': 42, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '29.02', 'row': 42, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.7914', 'row': 42, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '27.87', 'row': 42, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.7453', 'row': 42, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '27.14', 'row': 42, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.8149', 'row': 42, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '31.78', 'row': 42, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.9211', 'row': 42, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '27.46', 'row': 55, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.7916', 'row': 55, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '25.4', 'row': 55, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.6547', 'row': 55, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 8x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '25.06', 'row': 55, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 8x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.607', 'row': 55, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '23.24', 'row': 55, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.6523', 'row': 55, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'PSNR', 'model': 'DRLN+', 'value': '25.55', 'row': 55, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'SSIM', 'model': 'DRLN+', 'value': '0.8087', 'row': 55, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'CK+', 'metric': 'Accuracy (10-fold)', 'model': 'FAN', 'value': '99.69', 'row': 7, 'column': 3}]}\n","{'index': 3, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'MPI-INF-3DHP', 'metric': '3DPCK', 'model': 'XNect (SelecSLS)', 'value': '82.8', 'row': 12, 'column': 1}, {'task': '3D Human Pose Estimation', 'dataset': 'MPI-INF-3DHP', 'metric': 'AUC', 'model': 'XNect (SelecSLS)', 'value': '45.3', 'row': 12, 'column': 2}, {'task': '3D Human Pose Estimation', 'dataset': 'MPI-INF-3DHP', 'metric': 'MJPE', 'model': 'XNect (SelecSLS)', 'value': '98.4', 'row': 12, 'column': 3}]}\n","{'index': 4, 'records': [{'task': '3D Multi-Person Human Pose Estimation', 'dataset': 'MuPoTS-3D', 'metric': '3DPCK', 'model': 'SelecSLS', 'value': '75.8', 'row': 9, 'column': 21}]}\n","{'index': 5, 'records': [{'task': '3D Human Pose Estimation', 'dataset': 'Human3.6M', 'metric': 'Average MPJPE (mm)', 'model': 'SelecSLS', 'value': '63.6', 'row': 12, 'column': 16}]}\n","{'index': 1, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'DAVIS-2017', 'metric': 'Jaccard (Mean)', 'model': 'PTSNet', 'value': '71.6', 'row': 12, 'column': 3}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS-2017', 'metric': 'F-measure (Mean)', 'model': 'PTSNet', 'value': '77.7', 'row': 12, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'YouTube-VOS', 'metric': 'Jaccard (Seen)', 'model': 'PTSNet', 'value': '73.5', 'row': 9, 'column': 2}, {'task': 'Visual Object Tracking', 'dataset': 'YouTube-VOS', 'metric': 'Jaccard (Unseen)', 'model': 'PTSNet', 'value': '64.3', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Lane Detection', 'dataset': 'TuSimple', 'metric': 'Accuracy', 'model': 'End-to-end ERFNet', 'value': '95.24', 'row': 4, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Video Denoising', 'dataset': 'Set8 sigma10', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '36.43', 'row': 1, 'column': 6}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma20', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '33.37', 'row': 2, 'column': 6}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma30', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '31.6', 'row': 3, 'column': 6}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma40', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '30.37', 'row': 4, 'column': 6}, {'task': 'Video Denoising', 'dataset': 'Set8 sigma50', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '29.42', 'row': 5, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Video Denoising', 'dataset': 'DAVIS sigma10', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '38.97', 'row': 1, 'column': 5}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma20', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '35.86', 'row': 2, 'column': 5}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma30', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '34.06', 'row': 3, 'column': 5}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma40', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '32.8', 'row': 4, 'column': 5}, {'task': 'Video Denoising', 'dataset': 'DAVIS sigma50', 'metric': 'PSNR', 'model': 'FastDVDnet', 'value': '31.83', 'row': 5, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma5', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '37.25', 'row': 7, 'column': 2}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma10', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '33.47', 'row': 7, 'column': 3}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '31.35', 'row': 7, 'column': 4}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma20', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '29.88', 'row': 7, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '28.75', 'row': 7, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma30', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '27.82', 'row': 7, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma35', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '27.03', 'row': 7, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma40', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '26.31', 'row': 7, 'column': 9}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma45', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '25.67', 'row': 14, 'column': 2}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '25.1', 'row': 14, 'column': 3}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma55', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '24.55', 'row': 14, 'column': 4}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma60', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '24.05', 'row': 14, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma65', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '23.56', 'row': 14, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma70', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '23.1', 'row': 14, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma75', 'metric': 'PSNR', 'model': 'BUIFD75 (blind)', 'value': '22.67', 'row': 14, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma5', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '40.05', 'row': 7, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma10', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '35.98', 'row': 7, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma15', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '33.66', 'row': 7, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma20', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '32.02', 'row': 7, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma25', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '30.76', 'row': 7, 'column': 6}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma30', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '29.71', 'row': 7, 'column': 7}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma35', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '28.81', 'row': 7, 'column': 8}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma40', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '28.01', 'row': 7, 'column': 9}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma45', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '27.28', 'row': 14, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma50', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '26.6', 'row': 14, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma55', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '25.95', 'row': 14, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma60', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '25.34', 'row': 14, 'column': 5}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma65', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '24.75', 'row': 14, 'column': 6}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma70', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '24.18', 'row': 14, 'column': 7}, {'task': 'Color Image Denoising', 'dataset': 'CBSD68 sigma75', 'metric': 'PSNR', 'model': 'CBUIFD75', 'value': '23.63', 'row': 14, 'column': 8}]}\n","{'index': 0, 'records': [{'task': '3D Part Segmentation', 'dataset': 'ShapeNet-Part', 'metric': 'Instance Average IoU', 'model': 'PVCNN volumetric', 'value': '86.2', 'row': 10, 'column': 3}]}\n","{'index': 3, 'records': [{'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mAcc', 'model': 'PVCNN++ (1xC) volumetric', 'value': '87.12', 'row': 10, 'column': 3}, {'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mIoU', 'model': 'PVCNN++ (1xC) volumetric', 'value': '58.98', 'row': 10, 'column': 4}]}\n","{'index': 4, 'records': [{'task': '3D Object Detection', 'dataset': 'KITTI Cars Easy val', 'metric': 'AP', 'model': 'PVCNN', 'value': '84.02', 'row': 5, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Moderate val', 'metric': 'AP', 'model': 'PVCNN', 'value': '71.54', 'row': 5, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Hard val', 'metric': 'AP', 'model': 'PVCNN', 'value': '63.81', 'row': 5, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrian Easy val', 'metric': 'AP', 'model': 'PVCNN', 'value': '73.2', 'row': 5, 'column': 6}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrian Moderate val', 'metric': 'AP', 'model': 'PVCNN', 'value': '64.71', 'row': 5, 'column': 7}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrian Hard val', 'metric': 'AP', 'model': 'PVCNN', 'value': '56.78', 'row': 5, 'column': 8}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclist Easy val', 'metric': 'AP', 'model': 'PVCNN', 'value': '81.4', 'row': 5, 'column': 9}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclist Moderate val', 'metric': 'AP', 'model': 'PVCNN', 'value': '59.97', 'row': 5, 'column': 10}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclist Hard val', 'metric': 'AP', 'model': 'PVCNN', 'value': '56.24', 'row': 5, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'GQA test-std', 'metric': 'Accuracy', 'model': 'NSM', 'value': '63.17', 'row': 14, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA-CP', 'metric': 'Score', 'model': 'NSM', 'value': '45.8', 'row': 8, 'column': 1}]}\n","{'index': 4, 'records': [{'task': 'Visual Question Answering', 'dataset': 'GQA test-dev', 'metric': 'Accuracy', 'model': 'NSM', 'value': '62.95', 'row': 1, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'GMFN', 'value': '28.84', 'row': 7, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'GMFN', 'value': '27.74', 'row': 10, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'GMFN', 'value': '26.69', 'row': 13, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'GMFN', 'value': '31.24', 'row': 16, 'column': 11}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'MNIST', 'metric': 'Percentage error', 'model': 'LeNet 300-100 (Sparse Momentum)', 'value': '1.26', 'row': 15, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'WRN-22-8 (Sparse Momentum)', 'value': '95.04', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Congestive Heart Failure detection', 'dataset': 'CHF database', 'metric': 'Precision', 'model': 'Inclined Entropy (R-HessELM)', 'value': '98.05', 'row': 8, 'column': 2}, {'task': 'Congestive Heart Failure detection', 'dataset': 'CHF database', 'metric': 'Sensitivity', 'model': 'Inclined Entropy (R-HessELM)', 'value': '98.3', 'row': 8, 'column': 3}, {'task': 'Congestive Heart Failure detection', 'dataset': 'CHF database', 'metric': 'Accuracy', 'model': 'Inclined Entropy (R-HessELM)', 'value': '98.49', 'row': 8, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Multi-Person Pose Estimation', 'dataset': 'CrowdPose', 'metric': 'mAP @0.5:0.95', 'model': 'OccNet', 'value': '65.5', 'row': 3, 'column': 1}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'CrowdPose', 'metric': 'AP Easy', 'model': 'OccNet', 'value': '75.2', 'row': 3, 'column': 2}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'CrowdPose', 'metric': 'AP Medium', 'model': 'OccNet', 'value': '66.6', 'row': 3, 'column': 3}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'CrowdPose', 'metric': 'AP Hard', 'model': 'OccNet', 'value': '53.1', 'row': 3, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Left Atrium Segmentation', 'dataset': 'Atrial Segmentation Challenge', 'metric': 'Dice Score', 'model': 'UA-MT', 'value': '88.88', 'row': 11, 'column': 3}, {'task': 'Left Atrium Segmentation', 'dataset': 'Atrial Segmentation Challenge', 'metric': 'Jaccard', 'model': 'UA-MT', 'value': '80.21', 'row': 11, 'column': 4}, {'task': 'Left Atrium Segmentation', 'dataset': 'Atrial Segmentation Challenge', 'metric': 'ASD', 'model': 'UA-MT', 'value': '2.26', 'row': 11, 'column': 5}, {'task': 'Left Atrium Segmentation', 'dataset': 'Atrial Segmentation Challenge', 'metric': '95HD', 'model': 'UA-MT', 'value': '7.32', 'row': 11, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'DAOD', 'value': '85.4', 'row': 8, 'column': 14}, {'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'DAOD', 'value': '69.8', 'row': 21, 'column': 14}]}\n","{'index': 2, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma15', 'metric': 'PSNR', 'model': 'GCDN', 'value': '33.14', 'row': 1, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma25', 'metric': 'PSNR', 'model': 'GCDN', 'value': '30.78', 'row': 2, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma50', 'metric': 'PSNR', 'model': 'GCDN', 'value': '27.6', 'row': 3, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'GCDN', 'value': '31.83', 'row': 4, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'GCDN', 'value': '29.35', 'row': 5, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'GCDN', 'value': '26.38', 'row': 6, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma15', 'metric': 'PSNR', 'model': 'GCDN', 'value': '33.47', 'row': 7, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma25', 'metric': 'PSNR', 'model': 'GCDN', 'value': '30.95', 'row': 8, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Urban100 sigma50', 'metric': 'PSNR', 'model': 'GCDN', 'value': '27.41', 'row': 9, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Hand Gesture Recognition', 'dataset': 'DHG-14', 'metric': 'Accuracy', 'model': 'DG-STA', 'value': '91.9', 'row': 1, 'column': 4}, {'task': 'Hand Gesture Recognition', 'dataset': 'DHG-28', 'metric': 'Accuracy', 'model': 'DG-STA', 'value': '88', 'row': 2, 'column': 4}, {'task': 'Hand Gesture Recognition', 'dataset': 'SHREC 2017', 'metric': '14 gestures accuracy', 'model': 'DG-STA', 'value': '94.4', 'row': 3, 'column': 4}, {'task': 'Hand Gesture Recognition', 'dataset': 'SHREC 2017', 'metric': '28 gestures accuracy', 'model': 'DG-STA', 'value': '90.7', 'row': 4, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': 'HIV-fMRI-77', 'metric': 'Accuracy', 'model': 'IsoNN', 'value': '73.4', 'row': 2, 'column': 10}, {'task': 'Graph Classification', 'dataset': 'HIV-fMRI-77', 'metric': 'F1', 'model': 'IsoNN', 'value': '72.2', 'row': 3, 'column': 10}, {'task': 'Graph Classification', 'dataset': 'HIV-DTI-77', 'metric': 'Accuracy', 'model': 'IsoNN', 'value': '67.5', 'row': 4, 'column': 10}, {'task': 'Graph Classification', 'dataset': 'HIV-DTI-77', 'metric': 'F1', 'model': 'IsoNN', 'value': '68.3', 'row': 5, 'column': 10}, {'task': 'Graph Classification', 'dataset': 'BP-fMRI-97', 'metric': 'Accuracy', 'model': 'IsoNN', 'value': '64.9', 'row': 6, 'column': 10}, {'task': 'Graph Classification', 'dataset': 'BP-fMRI-97', 'metric': 'F1', 'model': 'IsoNN', 'value': '69.7', 'row': 7, 'column': 10}, {'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'Function Space Pooling', 'value': '83.3', 'row': 8, 'column': 9}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'IsoNN', 'value': '59.9', 'row': 10, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'MixNet-S', 'value': '4.1M', 'row': 17, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MixNet-S', 'value': '75.8', 'row': 17, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'MixNet-S', 'value': '92.8', 'row': 17, 'column': 5}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'MixNet-M', 'value': '5M', 'row': 18, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MixNet-M', 'value': '77', 'row': 18, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'MixNet-M', 'value': '93.3', 'row': 18, 'column': 5}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'MixNet-L', 'value': '7.3M', 'row': 19, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'MixNet-L', 'value': '78.9', 'row': 19, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'MixNet-L', 'value': '94.2', 'row': 19, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'SHREC 2017 track on 3D Hand Gesture Recognition', 'metric': '14 gestures accuracy', 'model': 'DD-Net', 'value': '94.6', 'row': 15, 'column': 2}, {'task': 'Skeleton Based Action Recognition', 'dataset': 'SHREC 2017 track on 3D Hand Gesture Recognition', 'metric': '28 gestures accuracy', 'model': 'DD-Net', 'value': '91.9', 'row': 15, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'JHMDB (2D poses only)', 'metric': 'Average accuracy of 3 splits', 'model': 'DD-Net', 'value': '77.2', 'row': 12, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Proposal Generation', 'dataset': 'ActivityNet-1.3', 'metric': 'AR@100', 'model': 'BMN', 'value': '75.01', 'row': 1, 'column': 6}, {'task': 'Temporal Action Proposal Generation', 'dataset': 'ActivityNet-1.3', 'metric': 'AUC (val)', 'model': 'BMN', 'value': '67.1', 'row': 2, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Temporal Action Proposal Generation', 'dataset': 'ActivityNet-1.3', 'metric': 'AUC (val)', 'model': 'BMN', 'value': '67.1', 'row': 5, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'BMN', 'value': '50.07', 'row': 6, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP', 'model': 'BMN', 'value': '36.42', 'row': 6, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'BMN', 'value': '32.2', 'row': 4, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Horizon Line Estimation', 'dataset': 'KITTI Horizon', 'metric': 'AUC', 'model': 'ConvLSTM (Huber Loss, naive residual path)', 'value': '74.55', 'row': 5, 'column': 1}, {'task': 'Horizon Line Estimation', 'dataset': 'KITTI Horizon', 'metric': 'MSE', 'model': 'ConvLSTM (Huber Loss, naive residual path)', 'value': '6.731', 'row': 5, 'column': 2}, {'task': 'Horizon Line Estimation', 'dataset': 'KITTI Horizon', 'metric': 'ATV', 'model': 'ConvLSTM (Huber Loss, naive residual path)', 'value': '4.984', 'row': 5, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'RFN', 'value': '32.71', 'row': 19, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'RFN', 'value': '28.95', 'row': 19, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'RFN', 'value': '27.83', 'row': 19, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'RFN', 'value': '27.01', 'row': 19, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'RFN', 'value': '31.59', 'row': 19, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'S-RFN', 'value': '0.9022', 'row': 20, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'S-RFN', 'value': '0.7946', 'row': 20, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'S-RFN', 'value': '0.7515', 'row': 20, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'S-RFN', 'value': '0.8169', 'row': 20, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'S-RFN', 'value': '0.9211', 'row': 20, 'column': 10}]}\n","{'index': 2, 'records': [{'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'STD', 'value': '89.66', 'row': 12, 'column': 3}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'STD', 'value': '87.76', 'row': 12, 'column': 4}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'STD', 'value': '86.89', 'row': 12, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'STD', 'value': '86.61', 'row': 12, 'column': 6}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'STD', 'value': '77.63', 'row': 12, 'column': 7}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'STD', 'value': '76.06', 'row': 12, 'column': 8}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Pedestrians Easy', 'metric': 'AP', 'model': 'STD', 'value': '60.99', 'row': 19, 'column': 3}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Pedestrians Moderate', 'metric': 'AP', 'model': 'STD', 'value': '51.39', 'row': 19, 'column': 4}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Pedestrians Hard', 'metric': 'AP', 'model': 'STD', 'value': '45.89', 'row': 19, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Easy', 'metric': 'AP', 'model': 'STD', 'value': '53.08', 'row': 19, 'column': 6}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Moderate', 'metric': 'AP', 'model': 'STD', 'value': '44.24', 'row': 19, 'column': 7}, {'task': '3D Object Detection', 'dataset': 'KITTI Pedestrians Hard', 'metric': 'AP', 'model': 'STD', 'value': '41.97', 'row': 19, 'column': 8}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'STD', 'value': '81.04', 'row': 26, 'column': 3}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'STD', 'value': '65.32', 'row': 26, 'column': 4}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'STD', 'value': '57.85', 'row': 26, 'column': 5}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'STD', 'value': '78.89', 'row': 26, 'column': 6}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'STD', 'value': '62.53', 'row': 26, 'column': 7}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'STD', 'value': '55.77', 'row': 26, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD1.1', 'metric': 'EM', 'model': 'SpanBERT (single model)', 'value': '88.8', 'row': 6, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1', 'metric': 'F1', 'model': 'SpanBERT (single model)', 'value': '94.6', 'row': 6, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0', 'metric': 'EM', 'model': 'SpanBERT', 'value': '85.7', 'row': 6, 'column': 3}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0', 'metric': 'F1', 'model': 'SpanBERT', 'value': '88.7', 'row': 6, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Question Answering', 'dataset': 'NewsQA', 'metric': 'F1', 'model': 'SpanBERT', 'value': '73.6', 'row': 4, 'column': 1}, {'task': 'Question Answering', 'dataset': 'TriviaQA', 'metric': 'F1', 'model': 'SpanBERT', 'value': '83.6', 'row': 4, 'column': 2}, {'task': 'Open-Domain Question Answering', 'dataset': 'SearchQA', 'metric': 'F1', 'model': 'SpanBERT', 'value': '84.8', 'row': 4, 'column': 3}, {'task': 'Question Answering', 'dataset': 'HotpotQA', 'metric': 'Joint F1', 'model': 'SpanBERT', 'value': '83', 'row': 4, 'column': 4}, {'task': 'Question Answering', 'dataset': 'NaturalQA', 'metric': 'F1', 'model': 'SpanBERT', 'value': '82.5', 'row': 4, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Coreference Resolution', 'dataset': 'OntoNotes', 'metric': 'F1', 'model': 'SpanBERT', 'value': '79.6', 'row': 6, 'column': 10}]}\n","{'index': 3, 'records': [{'task': 'Relation Extraction', 'dataset': 'TACRED', 'metric': 'Precision', 'model': 'SpanBERT', 'value': '70.8', 'row': 6, 'column': 1}, {'task': 'Relation Extraction', 'dataset': 'TACRED', 'metric': 'Recall', 'model': 'SpanBERT', 'value': '70.9', 'row': 6, 'column': 2}, {'task': 'Relation Extraction', 'dataset': 'TACRED', 'metric': 'F1', 'model': 'SpanBERT', 'value': '70.8', 'row': 6, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'SpanBERT', 'value': '64.3', 'row': 4, 'column': 1}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'SpanBERT', 'value': '94.8', 'row': 4, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'SpanBERT', 'value': '90.9', 'row': 4, 'column': 3}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'SpanBERT', 'value': '0.899', 'row': 4, 'column': 4}, {'task': 'Paraphrase Identification', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'SpanBERT', 'value': '71.9', 'row': 4, 'column': 5}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'SpanBERT', 'value': '88.1', 'row': 4, 'column': 6}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'SpanBERT', 'value': '94.3', 'row': 4, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'SpanBERT', 'value': '79.0', 'row': 4, 'column': 8}]}\n","{'index': 6, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'SpanBERT', 'value': '86.8', 'row': 3, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'CD3A', 'value': '79.5', 'row': 11, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'horse2zebra', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '7.06', 'row': 1, 'column': 2}, {'task': 'Image-to-Image Translation', 'dataset': 'cat2dog', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '7.07', 'row': 1, 'column': 3}, {'task': 'Image-to-Image Translation', 'dataset': 'photo2portrait', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '1.79', 'row': 1, 'column': 4}, {'task': 'Image-to-Image Translation', 'dataset': 'photo2vangogh', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '4.28', 'row': 1, 'column': 5}, {'task': 'Image-to-Image Translation', 'dataset': 'zebra2horse', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '7.47', 'row': 9, 'column': 2}, {'task': 'Image-to-Image Translation', 'dataset': 'dog2cat', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '8.15', 'row': 9, 'column': 3}, {'task': 'Image-to-Image Translation', 'dataset': 'portrait2photo', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '1.69', 'row': 9, 'column': 4}, {'task': 'Image-to-Image Translation', 'dataset': 'vangogh2photo', 'metric': 'Kernel Inception Distance', 'model': 'U-GAT-IT', 'value': '5.61', 'row': 9, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Optic Disc Segmentation', 'dataset': 'REFUGE', 'metric': 'DiceOC', 'model': 'ET-Net', 'value': '0.8912', 'row': 7, 'column': 1}, {'task': 'Optic Disc Segmentation', 'dataset': 'REFUGE', 'metric': 'DiceOD', 'model': 'ET-Net', 'value': '0.9529', 'row': 7, 'column': 2}, {'task': 'Optic Disc Segmentation', 'dataset': 'REFUGE', 'metric': 'mIoU', 'model': 'ET-Net', 'value': '0.867', 'row': 7, 'column': 3}, {'task': 'Optic Disc Segmentation', 'dataset': 'Drishti-GS', 'metric': 'DiceOC', 'model': 'ET-Net', 'value': '0.9314', 'row': 7, 'column': 4}, {'task': 'Optic Disc Segmentation', 'dataset': 'Drishti-GS', 'metric': 'DiceOD', 'model': 'ET-Net', 'value': '0.9752', 'row': 7, 'column': 5}, {'task': 'Optic Disc Segmentation', 'dataset': 'Drishti-GS', 'metric': 'mIoU', 'model': 'ET-Net', 'value': '0.8792', 'row': 7, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Retinal Vessel Segmentation', 'dataset': 'DRIVE', 'metric': 'Accuracy', 'model': 'ET-Net', 'value': '0.956', 'row': 6, 'column': 1}, {'task': 'Retinal Vessel Segmentation', 'dataset': 'DRIVE', 'metric': 'mIoU', 'model': 'ET-Net', 'value': '0.7744', 'row': 6, 'column': 2}, {'task': 'Lung Nodule Segmentation', 'dataset': 'Montgomery County', 'metric': 'Accuracy', 'model': 'ET-Net', 'value': '0.9865', 'row': 6, 'column': 3}, {'task': 'Lung Nodule Segmentation', 'dataset': 'Montgomery County', 'metric': 'mIoU', 'model': 'ET-Net', 'value': '0.942', 'row': 6, 'column': 4}, {'task': 'Lung Nodule Segmentation', 'dataset': 'LUNA', 'metric': 'Accuracy', 'model': 'ET-Net', 'value': '0.9868', 'row': 6, 'column': 5}, {'task': 'Lung Nodule Segmentation', 'dataset': 'LUNA', 'metric': 'mIoU', 'model': 'ET-Net', 'value': '0.9623', 'row': 6, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Drug Discovery', 'dataset': 'QED', 'metric': 'Success', 'model': 'HierG2G', 'value': '76.9%', 'row': 9, 'column': 5}, {'task': 'Drug Discovery', 'dataset': 'QED', 'metric': 'Diversity', 'model': 'HierG2G', 'value': '0.477', 'row': 9, 'column': 6}, {'task': 'Drug Discovery', 'dataset': 'DRD2', 'metric': 'Success', 'model': 'HierG2G', 'value': '85.9%', 'row': 9, 'column': 7}, {'task': 'Drug Discovery', 'dataset': 'DRD2', 'metric': 'Diversity', 'model': 'HierG2G', 'value': '0.192', 'row': 9, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'RoBERTa', 'value': '88.2', 'row': 6, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'WNLI', 'metric': 'Accuracy', 'model': 'RoBERTa', 'value': '89.0', 'row': 7, 'column': 9}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'RoBERTa', 'value': '90.8', 'row': 9, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'RoBERTa', 'value': '98.9', 'row': 9, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'RoBERTa', 'value': '96.7', 'row': 9, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'EM', 'model': 'RoBERTa (no data aug)', 'value': '86.5', 'row': 5, 'column': 3}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'RoBERTa (no data aug)', 'value': '89.4', 'row': 5, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Reading Comprehension', 'dataset': 'RACE', 'metric': 'Accuracy', 'model': 'RoBERTa', 'value': '83.2', 'row': 4, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Natural Language Understanding', 'dataset': 'WNLI', 'metric': 'Accuracy', 'model': 'HNN', 'value': '83.6', 'row': 6, 'column': 1}, {'task': 'Natural Language Understanding', 'dataset': 'Wisconsin Sleep Cohort (WSC)', 'metric': 'Accuracy', 'model': 'HNN', 'value': '75.1', 'row': 6, 'column': 2}, {'task': 'Natural Language Understanding', 'dataset': 'PDP60', 'metric': 'Accuracy', 'model': 'HNN', 'value': '90', 'row': 6, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '64.93', 'row': 10, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '83.18', 'row': 10, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '73.71', 'row': 10, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '88.59', 'row': 10, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '80.68', 'row': 10, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 5-shot', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '90.85', 'row': 10, 'column': 6}, {'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR-FS 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '74.81', 'row': 10, 'column': 7}, {'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR-FS 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'S2M2R', 'value': '87.47', 'row': 10, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '55.2', 'row': 3, 'column': 2}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '63.5', 'row': 3, 'column': 7}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '95', 'row': 4, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'SST-5 Fine-grained classification', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '95.6', 'row': 4, 'column': 7}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '86.1', 'row': 5, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '87.4', 'row': 5, 'column': 7}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'ERNIE 2.0 Base', 'value': '0.876', 'row': 6, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'ERNIE 2.0 Large', 'value': '0.912', 'row': 6, 'column': 7}, {'task': 'Question Answering', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '89.8', 'row': 7, 'column': 2}, {'task': 'Question Answering', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '90.1', 'row': 7, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'ERNIE 2.0 Base', 'value': '86.1', 'row': 8, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'ERNIE 2.0 Large', 'value': '88.7', 'row': 8, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '92.9', 'row': 9, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '94.6', 'row': 9, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '74.8', 'row': 10, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '80.2', 'row': 10, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'WNLI', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '65.1', 'row': 11, 'column': 2}, {'task': 'Natural Language Inference', 'dataset': 'WNLI', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '67.8', 'row': 11, 'column': 7}]}\n","{'index': 5, 'records': [{'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese) Dev', 'metric': 'EM', 'model': 'ERNIE 2.0 Base', 'value': '69.1', 'row': 2, 'column': 6}, {'task': 'Chinese Reading Comprehension', 'dataset': 'CMRC 2018 (Simplified Chinese) Dev', 'metric': 'EM', 'model': 'ERNIE 2.0 Large', 'value': '28.5', 'row': 2, 'column': 8}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese) Dev', 'metric': 'EM', 'model': 'ERNIE 2.0 Base', 'value': '88.5', 'row': 3, 'column': 6}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese)', 'metric': 'EM', 'model': 'ERNIE 2.0 Base', 'value': '88.0', 'row': 3, 'column': 7}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese) Dev', 'metric': 'EM', 'model': 'ERNIE 2.0 Large', 'value': '89.7', 'row': 3, 'column': 8}, {'task': 'Chinese Reading Comprehension', 'dataset': 'DRCD (Traditional Chinese)', 'metric': 'EM', 'model': 'ERNIE 2.0 Large', 'value': '89', 'row': 3, 'column': 9}, {'task': 'Open-Domain Question Answering', 'dataset': 'DuReader', 'metric': 'EM', 'model': 'ERNIE 2.0 Base', 'value': '61.3', 'row': 4, 'column': 6}, {'task': 'Open-Domain Question Answering', 'dataset': 'DuReader', 'metric': 'EM', 'model': 'ERNIE 2.0 Large', 'value': '64.2', 'row': 4, 'column': 8}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA Dev', 'metric': 'F1', 'model': 'ERNIE 2.0 Base', 'value': '95.2', 'row': 5, 'column': 6}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'ERNIE 2.0 Base', 'value': '93.8', 'row': 5, 'column': 7}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA Dev', 'metric': 'F1', 'model': 'ERNIE 2.0 Large', 'value': '96.3', 'row': 5, 'column': 8}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'ERNIE 2.0 Large', 'value': '95', 'row': 5, 'column': 9}, {'task': 'Natural Language Inference', 'dataset': 'XNLI Chinese Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '81.2', 'row': 6, 'column': 6}, {'task': 'Natural Language Inference', 'dataset': 'XNLI Chinese', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '79.7', 'row': 6, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'XNLI Chinese Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '82.6', 'row': 6, 'column': 8}, {'task': 'Natural Language Inference', 'dataset': 'XNLI Chinese', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '81', 'row': 6, 'column': 9}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '95.7', 'row': 7, 'column': 6}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '95.5', 'row': 7, 'column': 7}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '96.1', 'row': 7, 'column': 8}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '95.8', 'row': 7, 'column': 9}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '90.9', 'row': 8, 'column': 6}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '87.9', 'row': 8, 'column': 7}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '90.9', 'row': 8, 'column': 8}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '87.9', 'row': 8, 'column': 9}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '86.4', 'row': 9, 'column': 6}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Base', 'value': '85.0', 'row': 9, 'column': 7}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ Dev', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '86.5', 'row': 9, 'column': 8}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'BQ', 'metric': 'Accuracy', 'model': 'ERNIE 2.0 Large', 'value': '85.2', 'row': 9, 'column': 9}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA Dev', 'metric': 'MRR', 'model': 'ERNIE 2.0 Base', 'value': '95.7', 'row': 10, 'column': 6}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'MRR', 'model': 'ERNIE 2.0 Base', 'value': '95.7', 'row': 10, 'column': 7}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA Dev', 'metric': 'MRR', 'model': 'ERNIE 2.0 Large', 'value': '95.9', 'row': 10, 'column': 8}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'NLPCC-DBQA', 'metric': 'MRR', 'model': 'ERNIE 2.0 Large', 'value': '95.8', 'row': 10, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'UCF --> HMDB (full)', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '78.33', 'row': 9, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'HMDB --> UCF (full)', 'metric': 'Accuracy', 'model': 'TA3N', 'value': '81.79', 'row': 9, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '38.94', 'row': 2, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '33.88', 'row': 3, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '35.61', 'row': 4, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '30.31', 'row': 5, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '33.83', 'row': 6, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '29.15', 'row': 7, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '35.24', 'row': 8, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '29.28', 'row': 9, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'DIV2K val - 2x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '38.26', 'row': 10, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'DIV2K val - 4x upscaling', 'metric': 'PSNR', 'model': 'CAR', 'value': '32.82', 'row': 11, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'VOT2017', 'metric': 'Expected Average Overlap (EAO)', 'model': 'GFS-DCF', 'value': '0.397', 'row': 1, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'TrackingNet', 'metric': 'Accuracy', 'model': 'GFS-DCF', 'value': '60.9', 'row': 4, 'column': 1}, {'task': 'Visual Object Tracking', 'dataset': 'TrackingNet', 'metric': 'Precision', 'model': 'GFS-DCF', 'value': '56.57', 'row': 4, 'column': 2}, {'task': 'Visual Object Tracking', 'dataset': 'TrackingNet', 'metric': 'Normalized Precision', 'model': 'GFS-DCF', 'value': '71.79', 'row': 4, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Online Multi-Object Tracking', 'dataset': 'MOT15', 'metric': 'MOTA', 'model': 'GMPHD Filter (Occlusion Group Management)', 'value': '30.7', 'row': 3, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Online Multi-Object Tracking', 'dataset': 'MOT17', 'metric': 'MOTA', 'model': 'GMPHD Filter (Occlusion Group Management)', 'value': '49.9', 'row': 4, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR (Raw)', 'model': 'PRIDNet (blind)', 'value': '48.48', 'row': 11, 'column': 1}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'SSIM (Raw)', 'model': 'PRIDNet (blind)', 'value': '0.9806', 'row': 11, 'column': 2}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'PSNR (sRGB)', 'model': 'PRIDNet (blind)', 'value': '39.42', 'row': 11, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Darmstadt Noise Dataset', 'metric': 'SSIM (sRGB)', 'model': 'PRIDNet (blind)', 'value': '0.9528', 'row': 11, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'ABD-Net (ResNet-50)', 'value': '95.6', 'row': 11, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'ABD-Net (ResNet-50)', 'value': '88.28', 'row': 11, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'ABD-Net (ResNet-50)', 'value': '78.59', 'row': 21, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Person Re-Identification', 'dataset': 'MSMT17', 'metric': 'mAP', 'model': 'ABD-Net (ResNet-50)', 'value': '60.8', 'row': 4, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'AOGNet-40M-AN', 'value': '81.87', 'row': 8, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'AOGNet-40M-AN', 'value': '95.74', 'row': 8, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'Mask R-CNN-FPN (AOGNet-40M)', 'value': '44.9', 'row': 17, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Mask R-CNN-FPN (AOGNet-40M)', 'value': '66.2', 'row': 17, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'Mask R-CNN-FPN (AOGNet-40M)', 'value': '49.1', 'row': 17, 'column': 6}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'mask AP', 'model': 'Mask R-CNN-FPN (AOGNet-40M)', 'value': '40.2', 'row': 17, 'column': 7}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Mask R-CNN-FPN (AOGNet-40M)', 'value': '63.2', 'row': 17, 'column': 8}, {'task': 'Instance Segmentation', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'Mask R-CNN-FPN (AOGNet-40M)', 'value': '43.3', 'row': 17, 'column': 9}]}\n","{'index': 5, 'records': [{'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-1', 'model': 'NVAN', 'value': '90', 'row': 10, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'mAP', 'model': 'NVAN', 'value': '82.8', 'row': 10, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'DELTA (CNN)', 'value': '7.8', 'row': 2, 'column': 4}, {'task': 'Text Classification', 'dataset': 'Yahoo! Answers', 'metric': 'Accuracy', 'model': 'DELTA (HAN)', 'value': '75.1', 'row': 3, 'column': 4}, {'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2003 (English)', 'metric': 'F1', 'model': 'DELTA(BLSTM-CRF)', 'value': '84.6', 'row': 5, 'column': 4}, {'task': 'Intent Detection', 'dataset': 'ATIS', 'metric': 'Accuracy', 'model': 'DELTA (BLSTM-CRF)', 'value': '97.4', 'row': 7, 'column': 4}, {'task': 'Intent Detection', 'dataset': 'ATIS', 'metric': 'F1', 'model': 'DELTA (BLSTM-CRF)', 'value': '95.2', 'row': 8, 'column': 4}, {'task': 'Natural Language Inference', 'dataset': 'SNLI', 'metric': '% Test Accuracy', 'model': 'DELTA (LSTM)', 'value': '80.7', 'row': 10, 'column': 4}, {'task': 'Abstractive Text Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'Rouge-L', 'model': 'DELTA (BLSTM)', 'value': '27.3', 'row': 12, 'column': 4}, {'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2003 (English)', 'metric': 'F1', 'model': ' DELTA (NER ELMO)', 'value': '92.2', 'row': 14, 'column': 4}, {'task': 'Named Entity Recognition', 'dataset': 'CoNLL 2003 (English)', 'metric': 'F1', 'model': 'DELTA (BERT)', 'value': '94.6', 'row': 15, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '70.8', 'row': 5, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '71', 'row': 5, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VCR (Q-A) dev', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '70.8', 'row': 6, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-A) test', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '71.6', 'row': 6, 'column': 2}, {'task': 'Visual Question Answering', 'dataset': 'VCR (QA-R) dev', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '73.2', 'row': 6, 'column': 3}, {'task': 'Visual Question Answering', 'dataset': 'VCR (QA-R) test', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '73.2', 'row': 6, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-AR) dev', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '52.2', 'row': 6, 'column': 5}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-AR) test', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '52.4', 'row': 6, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Visual Reasoning', 'dataset': 'NLVR', 'metric': 'Accuracy (Test-P)', 'model': 'VisualBERT', 'value': '67', 'row': 4, 'column': 2}, {'task': 'Visual Reasoning', 'dataset': 'NLVR', 'metric': 'Accuracy (Test-U)', 'model': 'VisualBERT', 'value': '67.3', 'row': 4, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Dev', 'metric': 'R@1', 'model': 'VisualBERT', 'value': '70.4', 'row': 5, 'column': 1}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'R@1', 'model': 'VisualBERT', 'value': '71.33', 'row': 5, 'column': 2}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Dev', 'metric': 'R@5', 'model': 'VisualBERT', 'value': '84.49', 'row': 5, 'column': 3}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'R@5', 'model': 'VisualBERT', 'value': '84.98', 'row': 5, 'column': 4}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Dev', 'metric': 'R@10', 'model': 'VisualBERT', 'value': '86.31', 'row': 5, 'column': 5}, {'task': 'Phrase Grounding', 'dataset': 'Flickr30k Entities Test', 'metric': 'R@10', 'model': 'VisualBERT', 'value': '86.51', 'row': 5, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Visual Reasoning', 'dataset': 'NLVR2 Dev', 'metric': 'Accuracy', 'model': 'VisualBERT', 'value': '66.7', 'row': 1, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Image Generation', 'dataset': 'CIFAR-10', 'metric': 'Inception score', 'model': 'AutoGAN', 'value': '8.55', 'row': 13, 'column': 1}, {'task': 'Image Generation', 'dataset': 'CIFAR-10', 'metric': 'FID', 'model': 'AutoGAN', 'value': '12.42', 'row': 13, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Image Generation', 'dataset': 'STL-10', 'metric': 'Inception score', 'model': 'AutoGAN', 'value': '9.16', 'row': 7, 'column': 1}, {'task': 'Image Generation', 'dataset': 'STL-10', 'metric': 'FID', 'model': 'AutoGAN', 'value': '31.01', 'row': 7, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-1', 'model': 'TKP', 'value': '54.6', 'row': 8, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-5', 'model': 'TKP', 'value': '79.4', 'row': 8, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-10', 'model': 'TKP', 'value': '86.9', 'row': 8, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'iLIDS-VID', 'metric': 'Rank-20', 'model': 'TKP', 'value': '93.5', 'row': 8, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-1', 'model': 'TKP', 'value': '84', 'row': 6, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-5', 'model': 'TKP', 'value': '93.7', 'row': 6, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'Rank-10', 'model': 'TKP', 'value': '95.7', 'row': 6, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'MARS', 'metric': 'mAP', 'model': 'TKP', 'value': '73.3', 'row': 6, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 1M', 'metric': 'AUC', 'model': 'KNI', 'value': '0.9449', 'row': 11, 'column': 3}, {'task': 'Click-Through Rate Prediction', 'dataset': 'MovieLens 20M', 'metric': 'AUC', 'model': 'KNI', 'value': '0.9704', 'row': 11, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'ResNet-50 (LIP Bottleneck-256)', 'value': '78.15', 'row': 8, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'ResNet-50 (LIP Bottleneck-256)', 'value': '94.02', 'row': 8, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'ResNet-50 (LIP Bottleneck-256)', 'value': '25.8M', 'row': 8, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'LIP-ResNet-101', 'value': '79.33', 'row': 4, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'LIP-ResNet-101', 'value': '94.6', 'row': 4, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'LIP-ResNet-101', 'value': '42.9M', 'row': 4, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'LIP-DenseNet-BC-121', 'value': '76.64', 'row': 7, 'column': 1}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'LIP-DenseNet-BC-121', 'value': '93.16', 'row': 7, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'LIP-DenseNet-BC-121', 'value': '8.7M', 'row': 7, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'box AP', 'model': 'Faster R-CNN (LIP-ResNet-101)', 'value': '41.7', 'row': 5, 'column': 1}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP50', 'model': 'Faster R-CNN (LIP-ResNet-101)', 'value': '63.6', 'row': 5, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'AP75', 'model': 'Faster R-CNN (LIP-ResNet-101)', 'value': '45.6', 'row': 5, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'Faster R-CNN (LIP-ResNet-101)', 'value': '25.2', 'row': 5, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'Faster R-CNN (LIP-ResNet-101)', 'value': '45.8', 'row': 5, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'Faster R-CNN (LIP-ResNet-101-MD w FPN)', 'value': '43.9', 'row': 9, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Faster R-CNN (LIP-ResNet-101-MD w FPN)', 'value': '65.7', 'row': 9, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'Faster R-CNN (LIP-ResNet-101-MD w FPN)', 'value': '48.1', 'row': 9, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'Faster R-CNN (LIP-ResNet-101-MD w FPN)', 'value': '25.4', 'row': 9, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Faster R-CNN (LIP-ResNet-101-MD w FPN)', 'value': '46.7', 'row': 9, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Faster R-CNN (LIP-ResNet-101-MD w FPN)', 'value': '56.3', 'row': 9, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Precision', 'model': 'PAN-640', 'value': '86.4', 'row': 14, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'Recall', 'model': 'PAN-640', 'value': '81.2', 'row': 14, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'SCUT-CTW1500', 'metric': 'F-Measure', 'model': 'PAN-640', 'value': '83.7', 'row': 14, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'PAN-640', 'value': '89.3', 'row': 14, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'PAN-640', 'value': '81', 'row': 14, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'PAN-640', 'value': '85', 'row': 14, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'PAN', 'value': '84', 'row': 17, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'PAN', 'value': '81.9', 'row': 17, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'PAN', 'value': '82.9', 'row': 17, 'column': 5}]}\n","{'index': 6, 'records': [{'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'PAN', 'value': '84.4', 'row': 12, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'Recall', 'model': 'PAN', 'value': '83.8', 'row': 12, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'MSRA-TD500', 'metric': 'F-Measure', 'model': 'PAN', 'value': '84.1', 'row': 12, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'Accuracy', 'model': 'N2D (UMAP)', 'value': '0.979', 'row': 9, 'column': 1}, {'task': 'Image Clustering', 'dataset': 'MNIST-full', 'metric': 'NMI', 'model': 'N2D (UMAP)', 'value': '0.942', 'row': 9, 'column': 2}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'Accuracy', 'model': 'N2D (UMAP)', 'value': '0.948', 'row': 9, 'column': 3}, {'task': 'Image Clustering', 'dataset': 'MNIST-test', 'metric': 'NMI', 'model': 'N2D (UMAP)', 'value': '0.882', 'row': 9, 'column': 4}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'Accuracy', 'model': 'N2D (UMAP)', 'value': '0.958', 'row': 9, 'column': 5}, {'task': 'Image Clustering', 'dataset': 'USPS', 'metric': 'NMI', 'model': 'N2D (UMAP)', 'value': '0.901', 'row': 9, 'column': 6}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'Accuracy', 'model': 'N2D (UMAP)', 'value': '0.672', 'row': 9, 'column': 7}, {'task': 'Image Clustering', 'dataset': 'Fashion-MNIST', 'metric': 'NMI', 'model': 'N2D (UMAP)', 'value': '0.684', 'row': 9, 'column': 8}, {'task': 'Image Clustering', 'dataset': 'pendigits', 'metric': 'Accuracy', 'model': 'N2D (UMAP)', 'value': '0.885', 'row': 9, 'column': 9}, {'task': 'Image Clustering', 'dataset': 'pendigits', 'metric': 'NMI', 'model': 'N2D (UMAP)', 'value': '0.863', 'row': 9, 'column': 10}, {'task': 'Image Clustering', 'dataset': 'HAR', 'metric': 'Accuracy', 'model': 'N2D (UMAP)', 'value': '0.801', 'row': 9, 'column': 11}, {'task': 'Image Clustering', 'dataset': 'HAR', 'metric': 'NMI', 'model': 'N2D (UMAP)', 'value': '0.683', 'row': 9, 'column': 12}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'SCARLET-A', 'value': '6.7M', 'row': 13, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'SCARLET-A', 'value': '76.9', 'row': 13, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'SCARLET-A', 'value': '93.4', 'row': 13, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'SCARLET-B', 'value': '6.5M', 'row': 14, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'SCARLET-B', 'value': '76.3', 'row': 14, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'SCARLET-B', 'value': '93', 'row': 14, 'column': 4}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'SCARLET-C', 'value': '6M', 'row': 15, 'column': 2}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'SCARLET-C', 'value': '75.6', 'row': 15, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'SCARLET-C', 'value': '92.6', 'row': 15, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Number of params', 'model': 'SCARLET-A4', 'value': '27.8M', 'row': 10, 'column': 5}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'SCARLET-A4', 'value': '82.3', 'row': 10, 'column': 6}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'SCARLET-A4', 'value': '96', 'row': 10, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'Accuracy', 'model': 'MPAD-path', 'value': '97.44', 'row': 16, 'column': 1}, {'task': 'Document Classification', 'dataset': 'BBCSport', 'metric': 'Accuracy', 'model': 'MPAD-path', 'value': '99.59', 'row': 16, 'column': 2}, {'task': 'Document Classification', 'dataset': 'MPQA', 'metric': 'Accuracy', 'model': 'MPAD-path', 'value': '89.81', 'row': 16, 'column': 5}, {'task': 'Text Classification', 'dataset': 'IMDb', 'metric': 'Accuracy', 'model': 'MPAD-path', 'value': '91.84', 'row': 16, 'column': 6}, {'task': 'Text Classification', 'dataset': 'TREC-6', 'metric': 'Error', 'model': 'MPAD-path', 'value': '6.2', 'row': 16, 'column': 7}, {'task': 'Sentiment Analysis', 'dataset': 'SST-5 Fine-grained classification', 'metric': 'Accuracy', 'model': 'MPAD-path', 'value': '49.68', 'row': 16, 'column': 8}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'MPAD-path', 'value': '87.75', 'row': 16, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Color Image Denoising', 'dataset': 'BSD300 sigma30', 'metric': 'PSNR', 'model': 'CNN (Median Layers)', 'value': '40.9', 'row': 13, 'column': 9}, {'task': 'Color Image Denoising', 'dataset': 'BSD300 sigma50', 'metric': 'PSNR', 'model': 'CNN (Median Layers)', 'value': '37.28', 'row': 14, 'column': 9}, {'task': 'Color Image Denoising', 'dataset': 'BSD300 sigma70', 'metric': 'PSNR', 'model': 'CNN (Median Layers)', 'value': '32.4', 'row': 15, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma30', 'metric': 'PSNR', 'model': 'CNN (Median Layers)', 'value': '36.39', 'row': 1, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma50', 'metric': 'PSNR', 'model': 'CNN (Median Layers)', 'value': '34.35', 'row': 2, 'column': 3}, {'task': 'Color Image Denoising', 'dataset': 'Kodak24 sigma70', 'metric': 'PSNR', 'model': 'CNN (Median Layers)', 'value': '31.56', 'row': 3, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Mean)', 'model': 'RANet+ (online learning)', 'value': '86.6', 'row': 8, 'column': 4}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Recall)', 'model': 'RANet+ (online learning)', 'value': '97', 'row': 8, 'column': 5}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Decay)', 'model': 'RANet+ (online learning)', 'value': '7.4', 'row': 8, 'column': 6}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Mean)', 'model': 'RANet+ (online learning)', 'value': '87.6', 'row': 8, 'column': 7}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Recall)', 'model': 'RANet+ (online learning)', 'value': '96.1', 'row': 8, 'column': 8}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Decay)', 'model': 'RANet+ (online learning)', 'value': '8.2', 'row': 8, 'column': 9}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Mean)', 'model': 'RANet', 'value': '85.5', 'row': 20, 'column': 4}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Recall)', 'model': 'RANet', 'value': '97.2', 'row': 20, 'column': 5}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Decay)', 'model': 'RANet', 'value': '6.2', 'row': 20, 'column': 6}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Mean)', 'model': 'RANet', 'value': '85.4', 'row': 20, 'column': 7}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Recall)', 'model': 'RANet', 'value': '94.9', 'row': 20, 'column': 8}, {'task': 'Visual Object Tracking', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Decay)', 'model': 'RANet', 'value': '5.1', 'row': 20, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'DAVIS-2017', 'metric': 'Jaccard (Mean)', 'model': 'RANet', 'value': '53.4', 'row': 13, 'column': 5}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'Pix2Pose', 'value': '72.4', 'row': 1, 'column': 14}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'Pix2Pose', 'value': '32', 'row': 9, 'column': 1}]}\n","{'index': 2, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'T-LESS', 'metric': 'Recall (VSD)', 'model': 'Pix2Pose without ICP', 'value': '29.5', 'row': 2, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'LXMERT', 'value': '72.5', 'row': 6, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'GQA test-std', 'metric': 'Accuracy', 'model': 'LXMERT', 'value': '60.3', 'row': 6, 'column': 7}, {'task': 'Visual Reasoning', 'dataset': 'NLVR2 Test', 'metric': 'Accuracy', 'model': 'LXMERT', 'value': '76.2', 'row': 6, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'LXMERT (Pre-train + scratch)', 'value': '69.9', 'row': 11, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'GQA test-dev', 'metric': 'Accuracy', 'model': 'LXMERT (Pre-train + scratch)', 'value': '60.0', 'row': 11, 'column': 2}, {'task': 'Visual Reasoning', 'dataset': 'NLVR2 Dev', 'metric': 'Accuracy', 'model': 'LXMERT (Pre-train + scratch)', 'value': '74.9', 'row': 11, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'Asymmetric ALNN', 'value': '81.3', 'row': 13, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'ADE20K val', 'metric': 'mIoU', 'model': 'Asymmetric ALNN', 'value': '45.24', 'row': 9, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL Context', 'metric': 'mIoU', 'model': 'Asymmetric ALNN', 'value': '52.8', 'row': 8, 'column': 2}]}\n","{'index': 7, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'COCO-Stuff test', 'metric': 'mIoU', 'model': 'Asymmetric ALNN', 'value': '37.2', 'row': 3, 'column': 2}, {'task': 'Semantic Segmentation', 'dataset': 'NYU Depth v2', 'metric': 'Mean IoU', 'model': 'Asymmetric ALNN', 'value': '44.4', 'row': 3, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'box AP', 'model': 'Cascade R-CNN-FPN (ResNet-101, map-guided)', 'value': '45.9', 'row': 9, 'column': 2}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Cascade R-CNN-FPN (ResNet-101, map-guided)', 'value': '64.2', 'row': 9, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'Cascade R-CNN-FPN (ResNet-101, map-guided)', 'value': '50', 'row': 9, 'column': 4}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'Cascade R-CNN-FPN (ResNet-101, map-guided)', 'value': '26.3', 'row': 9, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Cascade R-CNN-FPN (ResNet-101, map-guided)', 'value': '49', 'row': 9, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Cascade R-CNN-FPN (ResNet-101, map-guided)', 'value': '58.6', 'row': 9, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'mask AP', 'model': 'Cascade R-CNN (ResNet-101-FPN, map-guided)', 'value': '39.5', 'row': 9, 'column': 2}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Cascade R-CNN (ResNet-101-FPN, map-guided)', 'value': '61.4', 'row': 9, 'column': 3}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'Cascade R-CNN (ResNet-101-FPN, map-guided)', 'value': '42.9', 'row': 9, 'column': 4}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'Cascade R-CNN (ResNet-101-FPN, map-guided)', 'value': '21.2', 'row': 9, 'column': 5}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Cascade R-CNN (ResNet-101-FPN, map-guided)', 'value': '42.5', 'row': 9, 'column': 6}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Cascade R-CNN (ResNet-101-FPN, map-guided)', 'value': '52.1', 'row': 9, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': '3C-Net', 'value': '59.1', 'row': 12, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': '3C-Net', 'value': '53.5', 'row': 12, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': '3C-Net', 'value': '44.2', 'row': 12, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': '3C-Net', 'value': '34.1', 'row': 12, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': '3C-Net', 'value': '26.6', 'row': 12, 'column': 5}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': '3C-Net', 'value': '8.1', 'row': 12, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': '3C-Net', 'value': '37.2', 'row': 7, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.7', 'model': '3C-Net', 'value': '23.7', 'row': 7, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.9', 'model': '3C-Net', 'value': '9.2', 'row': 7, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP', 'model': '3C-Net', 'value': '21.7', 'row': 7, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Action Classification', 'dataset': 'THUMOS’14', 'metric': 'mAP', 'model': '3C-Net', 'value': '86.9', 'row': 8, 'column': 1}, {'task': 'Action Classification', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP', 'model': '3C-Net', 'value': '92.4', 'row': 8, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Face Alignment', 'dataset': 'CelebA Aligned', 'metric': 'PSNR', 'model': 'Progressive Face SR', 'value': '22.66', 'row': 7, 'column': 1}, {'task': 'Face Alignment', 'dataset': 'CelebA Aligned', 'metric': 'SSIM', 'model': 'Progressive Face SR', 'value': '0.685', 'row': 7, 'column': 2}, {'task': 'Face Alignment', 'dataset': 'CelebA Aligned', 'metric': 'MS-SSIM', 'model': 'Progressive Face SR', 'value': '0.902', 'row': 7, 'column': 3}, {'task': 'Face Alignment', 'dataset': 'CelebA Aligned', 'metric': 'MOS', 'model': 'Progressive Face SR', 'value': '3.73', 'row': 7, 'column': 4}, {'task': 'Face Alignment', 'dataset': 'CelebA + AFLW Unaligned', 'metric': 'PSNR', 'model': 'Progressive Face SR', 'value': '22.96', 'row': 7, 'column': 5}, {'task': 'Face Alignment', 'dataset': 'CelebA + AFLW Unaligned', 'metric': 'SSIM', 'model': 'Progressive Face SR', 'value': '0.695', 'row': 7, 'column': 6}, {'task': 'Face Alignment', 'dataset': 'CelebA + AFLW Unaligned', 'metric': 'MS-SSIM', 'model': 'Progressive Face SR', 'value': '0.897', 'row': 7, 'column': 7}, {'task': 'Face Alignment', 'dataset': 'CelebA + AFLW Unaligned', 'metric': 'MOS', 'model': 'Progressive Face SR', 'value': '3.73', 'row': 7, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VCR (Q-A) dev', 'metric': 'Accuracy', 'model': 'VL-BERTBASE', 'value': '73.8', 'row': 8, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VCR (QA-R) dev', 'metric': 'Accuracy', 'model': 'VL-BERTBASE', 'value': '74.4', 'row': 8, 'column': 3}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-AR) dev', 'metric': 'Accuracy', 'model': 'VL-BERTBASE', 'value': '55.2', 'row': 8, 'column': 5}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-A) dev', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '75.5', 'row': 9, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-A) test', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '75.8', 'row': 9, 'column': 2}, {'task': 'Visual Question Answering', 'dataset': 'VCR (QA-R) dev', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '77.9', 'row': 9, 'column': 3}, {'task': 'Visual Question Answering', 'dataset': 'VCR (QA-R) test', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '78.4', 'row': 9, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-AR) dev', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '58.9', 'row': 9, 'column': 5}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-AR) test', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '59.7', 'row': 9, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'VL-BERTBASE', 'value': '71.16', 'row': 7, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '71.79', 'row': 8, 'column': 1}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'VL-BERTLARGE', 'value': '72.22', 'row': 8, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Multi-Domain Sentiment Classification', 'dataset': 'ARSC', 'metric': 'Accuracy', 'model': 'MTM', 'value': '90.01', 'row': 7, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Face Verification', 'dataset': 'AgeDB-30', 'metric': 'Accuracy', 'model': 'Seesaw-shuffleFaceNet', 'value': '0.9685', 'row': 11, 'column': 8}, {'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'Seesaw-shuffleFaceNet (mobi)', 'value': '99.65', 'row': 12, 'column': 6}, {'task': 'Face Verification', 'dataset': 'CFP-FP', 'metric': 'Accuracy', 'model': 'Seesaw-shuffleFaceNet (mobi)', 'value': '0.9307', 'row': 12, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Multi-Person Pose Estimation', 'dataset': 'MPII Multi-Person', 'metric': 'AP', 'model': 'SPM', 'value': '78.5', 'row': 9, 'column': 8}]}\n","{'index': 3, 'records': [{'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'SPM', 'value': '66.9', 'row': 7, 'column': 1}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'SPM', 'value': '88.5', 'row': 7, 'column': 2}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'SPM', 'value': '72.9', 'row': 7, 'column': 3}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'SPM', 'value': '62.6', 'row': 7, 'column': 4}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'SPM', 'value': '73.1', 'row': 7, 'column': 5}]}\n","{'index': 1, 'records': [{'task': '3D Object Detection', 'dataset': 'nuScenes', 'metric': 'MAP', 'model': 'MEGVII', 'value': '52.8', 'row': 6, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'nuScenes', 'metric': 'NDS', 'model': 'MEGVII', 'value': '63.3', 'row': 6, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'PyCDA (ResNet-38)', 'value': '48', 'row': 14, 'column': 21}]}\n","{'index': 1, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'PyCDA (ResNet-101)', 'value': '53.3', 'row': 15, 'column': 19}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'VisDA2017', 'metric': 'Mean Accuracy', 'model': 'MRKLD + LRENT', 'value': '78.1', 'row': 15, 'column': 13}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'MRKLD + LRENT', 'value': '86.8', 'row': 13, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'MRKLD-SP-MST (ResNet-38)', 'value': '49.8', 'row': 24, 'column': 21}]}\n","{'index': 4, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'LRENT (DeepLabv2)', 'value': '48.7', 'row': 13, 'column': 19}]}\n","{'index': 4, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'Index Network', 'value': '31.23', 'row': 24, 'column': 4}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'Index Network', 'value': '29.06', 'row': 24, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'Index Network', 'value': '26.34', 'row': 24, 'column': 6}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma15', 'metric': 'PSNR', 'model': 'Index Network', 'value': '32.82', 'row': 24, 'column': 7}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma30', 'metric': 'PSNR', 'model': 'Index Network', 'value': '30.43', 'row': 24, 'column': 8}, {'task': 'Grayscale Image Denoising', 'dataset': 'Set12 sigma50', 'metric': 'PSNR', 'model': 'Index Network', 'value': '27.29', 'row': 24, 'column': 9}]}\n","{'index': 5, 'records': [{'task': 'Scene Segmentation', 'dataset': 'SUN-RGBD', 'metric': 'Mean IoU', 'model': 'Index Network', 'value': '33.48', 'row': 22, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Monocular Depth Estimation', 'dataset': 'NYU-Depth V2', 'metric': 'RMSE', 'model': 'Index Network', 'value': '0.565', 'row': 23, 'column': 4}, {'task': 'Monocular Depth Estimation', 'dataset': 'NYU Depth v2', 'metric': 'Delta1', 'model': 'Index Network', 'value': '0.787', 'row': 23, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V1', 'metric': 'Top 1 Accuracy', 'model': 'TRG (Inception-V3)', 'value': '49.7', 'row': 15, 'column': 5}, {'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V2', 'metric': 'Top-1 Accuracy', 'model': 'TRG (Inception-V3)', 'value': '61.3', 'row': 15, 'column': 7}, {'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V2', 'metric': 'Top-5 Accuracy', 'model': 'TRG (Inception-V3)', 'value': '91.4', 'row': 15, 'column': 8}, {'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V1', 'metric': 'Top 1 Accuracy', 'model': 'TRG (ResNet-50)', 'value': '49.5', 'row': 18, 'column': 5}, {'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V1', 'metric': 'Top 5 Accuracy', 'model': 'TRG (ResNet-50)', 'value': '86.1', 'row': 18, 'column': 6}, {'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V2', 'metric': 'Top-1 Accuracy', 'model': 'TRG (ResNet-50)', 'value': '62.2', 'row': 18, 'column': 7}, {'task': 'Action Recognition In Videos', 'dataset': 'Something-Something V2', 'metric': 'Top-5 Accuracy', 'model': 'TRG (ResNet-50)', 'value': '90.3', 'row': 18, 'column': 8}]}\n","{'index': 1, 'records': [{'task': 'Action Classification', 'dataset': 'Charades', 'metric': 'MAP', 'model': 'TRG (ResNet-101)', 'value': '40.2', 'row': 22, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Hand Pose Estimation', 'dataset': 'NYU Hands', 'metric': 'Average 3D Error', 'model': 'A2J (Ours)', 'value': '105.06', 'row': 15, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Hand Pose Estimation', 'dataset': 'ICVL Hands', 'metric': 'Average 3D Error', 'model': 'A2J (Ours)', 'value': '105.06', 'row': 15, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Pose Estimation', 'dataset': 'ITOP front-view', 'metric': 'Mean mAP', 'model': 'A2J (Ours)', 'value': '99.2', 'row': 3, 'column': 8}]}\n","{'index': 6, 'records': [{'task': 'Depth Estimation', 'dataset': 'NYU-Depth V2', 'metric': 'RMS', 'model': 'A2J (Ours)', 'value': '0.0861', 'row': 4, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'Financial PhraseBank', 'metric': 'Accuracy', 'model': 'FinBERT', 'value': '86', 'row': 8, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'Financial PhraseBank', 'metric': 'F1 score', 'model': 'FinBERT', 'value': '84', 'row': 8, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Sentiment Analysis', 'dataset': 'FiQA', 'metric': 'MSE', 'model': 'FinBERT', 'value': '0.07', 'row': 3, 'column': 1}, {'task': 'Sentiment Analysis', 'dataset': 'FiQA', 'metric': 'R^2', 'model': 'FinBERT', 'value': '0.55', 'row': 3, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'HigherHRNet (HR-Net-48)', 'value': '70.5', 'row': 13, 'column': 5}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'HigherHRNet (HR-Net-48)', 'value': '89.3', 'row': 13, 'column': 6}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'HigherHRNet (HR-Net-48)', 'value': '77.2', 'row': 13, 'column': 7}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'HigherHRNet (HR-Net-48)', 'value': '66.6', 'row': 13, 'column': 8}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'HigherHRNet (HR-Net-48)', 'value': '75.8', 'row': 13, 'column': 9}]}\n","{'index': 1, 'records': [{'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'Micro F1', 'model': 'HiLAP (bow-CNN)', 'value': '83.3', 'row': 13, 'column': 2}, {'task': 'Text Classification', 'dataset': 'RCV1', 'metric': 'Macro F1', 'model': 'HiLAP (bow-CNN)', 'value': '60.1', 'row': 13, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Named Entity Recognition', 'dataset': 'Long-tail emerging entities', 'metric': 'Precision', 'model': 'Cross-BiLSTM-CNN', 'value': '58.28', 'row': 6, 'column': 4}, {'task': 'Named Entity Recognition', 'dataset': 'Long-tail emerging entities', 'metric': 'Recall', 'model': 'Cross-BiLSTM-CNN', 'value': '33.92', 'row': 6, 'column': 5}, {'task': 'Named Entity Recognition', 'dataset': 'Long-tail emerging entities', 'metric': 'F1', 'model': 'Cross-BiLSTM-CNN', 'value': '42.85', 'row': 6, 'column': 6}, {'task': 'Named Entity Recognition', 'dataset': 'Ontonotes v5 (English)', 'metric': 'Precision', 'model': 'Att-BiLSTM-CNN', 'value': '88.71', 'row': 7, 'column': 1}, {'task': 'Named Entity Recognition', 'dataset': 'Ontonotes v5 (English)', 'metric': 'Recall', 'model': 'Att-BiLSTM-CNN', 'value': '88.11', 'row': 7, 'column': 2}, {'task': 'Named Entity Recognition', 'dataset': 'Ontonotes v5 (English)', 'metric': 'F1', 'model': 'Att-BiLSTM-CNN', 'value': '88.4', 'row': 7, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MRR', 'model': 'Meta-KGR (ConvE)', 'value': '0.469', 'row': 8, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@1', 'model': 'Meta-KGR (ConvE)', 'value': '0.412', 'row': 8, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@10', 'model': 'Meta-KGR (ConvE)', 'value': '0.588', 'row': 8, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'NELL-995', 'metric': 'MRR', 'model': 'Meta-KGR (ConvE)', 'value': '0.253', 'row': 8, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'NELL-995', 'metric': 'Hits@1', 'model': 'Meta-KGR (ConvE)', 'value': '0.197', 'row': 8, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'NELL-995', 'metric': 'Hits@10', 'model': 'Meta-KGR (ConvE)', 'value': '0.347', 'row': 8, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Emotion Recognition in Conversation', 'dataset': 'IEMOCAP', 'metric': 'Accuracy', 'model': 'DialogueGCN', 'value': '65.25', 'row': 10, 'column': 13}, {'task': 'Emotion Recognition in Conversation', 'dataset': 'IEMOCAP', 'metric': 'F1', 'model': 'DialogueGCN', 'value': '64.18%', 'row': 10, 'column': 14}]}\n","{'index': 0, 'records': [{'task': 'Chinese Spam Detection', 'dataset': 'SMS', 'metric': 'Accuracy', 'model': 'StoneSkipping', 'value': '85.1', 'row': 17, 'column': 2}, {'task': 'Chinese Spam Detection', 'dataset': 'SMS', 'metric': 'F1-Score', 'model': 'StoneSkipping', 'value': '83.2', 'row': 17, 'column': 3}, {'task': 'Chinese Spam Detection', 'dataset': 'Product Review', 'metric': 'Accuracy', 'model': 'StoneSkipping', 'value': '85.4', 'row': 17, 'column': 4}, {'task': 'Chinese Spam Detection', 'dataset': 'Product Review', 'metric': 'F1-Score', 'model': 'StoneSkipping', 'value': '82.2', 'row': 17, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Recipe Generation', 'dataset': 'Food.com', 'metric': 'BPE Perplexity', 'model': 'Prior Name', 'value': '9.516', 'row': 5, 'column': 1}, {'task': 'Recipe Generation', 'dataset': 'Food.com', 'metric': 'BLEU-1', 'model': 'Prior Name', 'value': '28.046', 'row': 5, 'column': 2}, {'task': 'Recipe Generation', 'dataset': 'Food.com', 'metric': 'BLEU-4', 'model': 'Prior Name', 'value': '3.211', 'row': 5, 'column': 3}, {'task': 'Recipe Generation', 'dataset': 'Food.com', 'metric': 'Rouge-L', 'model': 'Prior Name', 'value': '24.794', 'row': 5, 'column': 4}, {'task': 'Recipe Generation', 'dataset': 'Food.com', 'metric': 'D-1', 'model': 'Prior Name', 'value': '0.233', 'row': 5, 'column': 5}, {'task': 'Recipe Generation', 'dataset': 'Food.com', 'metric': 'D-2', 'model': 'Prior Name', 'value': '2.08', 'row': 5, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Retinal Vessel Segmentation', 'dataset': 'DRIVE', 'metric': 'F1 score', 'model': 'BCDU-Net (d=3)', 'value': '0.8224', 'row': 8, 'column': 1}, {'task': 'Retinal Vessel Segmentation', 'dataset': 'DRIVE', 'metric': 'AUC', 'model': 'BCDU-Net (d=3)', 'value': '0.9789', 'row': 8, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Lesion Segmentation', 'dataset': 'ISIC 2018', 'metric': 'F1-Score', 'model': 'BCDU-Net (d=3)', 'value': '0.851', 'row': 6, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Lung Nodule Segmentation', 'dataset': 'LUNA', 'metric': 'F1 score', 'model': 'BCDU-Net (d=3)', 'value': '0.9904', 'row': 5, 'column': 1}, {'task': 'Lung Nodule Segmentation', 'dataset': 'LUNA', 'metric': 'AUC', 'model': 'BCDU-Net (d=3)', 'value': '0.9946', 'row': 5, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'GNNets', 'value': '86.71', 'row': 18, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'GNNets', 'value': '90.41', 'row': 18, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'GNNets', 'value': '88.52', 'row': 18, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'GNNets', 'value': '70.06', 'row': 18, 'column': 5}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'GNNets', 'value': '79.63', 'row': 18, 'column': 6}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'GNNets', 'value': '74.54', 'row': 18, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Sentence Fusion', 'dataset': 'DiscoFuse', 'metric': 'Exact', 'model': 'LaserTaggerAR', 'value': '53.8', 'row': 5, 'column': 1}, {'task': 'Sentence Fusion', 'dataset': 'DiscoFuse', 'metric': 'SARI', 'model': 'LaserTaggerAR', 'value': '85.5', 'row': 5, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Split and Rephrase', 'dataset': 'WikiSplit1.0', 'metric': 'BLEU score', 'model': 'LaserTaggerAR', 'value': '76.3', 'row': 4, 'column': 1}, {'task': 'Split and Rephrase', 'dataset': 'WikiSplit1.0', 'metric': 'Exact', 'model': 'LaserTaggerAR', 'value': '15.2', 'row': 4, 'column': 2}, {'task': 'Split and Rephrase', 'dataset': 'WikiSplit1.0', 'metric': 'SARI', 'model': 'LaserTaggerAR', 'value': '61.7', 'row': 4, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'NABoE-full', 'value': '86.8', 'row': 5, 'column': 1}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'F-measure', 'model': 'NABoE-full', 'value': '86.2', 'row': 5, 'column': 2}, {'task': 'Text Classification', 'dataset': 'R8', 'metric': 'Accuracy', 'model': 'NABoE-full', 'value': '97.1', 'row': 5, 'column': 3}, {'task': 'Text Classification', 'dataset': 'R8', 'metric': 'F-measure', 'model': 'NABoE-full', 'value': '91.7', 'row': 5, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 1000 Labels', 'metric': 'Accuracy', 'model': 'Dual Student (600)', 'value': '85.83', 'row': 11, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 2000 Labels', 'metric': 'Accuracy', 'model': 'Dual Student (600)', 'value': '89.28', 'row': 11, 'column': 2}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-10, 4000 Labels', 'metric': 'Accuracy', 'model': 'Dual Student (600)', 'value': '91.11', 'row': 11, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'cifar-100, 10000 Labels', 'metric': 'Accuracy', 'model': 'Dual Student (480)', 'value': '67.23', 'row': 9, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 250 Labels', 'metric': 'Accuracy', 'model': 'Dual Student', 'value': '95.76', 'row': 3, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 500 Labels', 'metric': 'Accuracy', 'model': 'Dual Student', 'value': '96.04', 'row': 3, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'ImageNet - 10% labeled data', 'metric': 'Top 1 Accuracy', 'model': 'Dual Student', 'value': '63.52', 'row': 3, 'column': 1}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'ImageNet - 10% labeled data', 'metric': 'Top 5 Accuracy', 'model': 'Dual Student', 'value': '83.58', 'row': 3, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'FlowSeq-base', 'value': '18.55', 'row': 5, 'column': 1}, {'task': 'Machine Translation', 'dataset': 'WMT2014 German-English', 'metric': 'BLEU score', 'model': 'FlowSeq-base', 'value': '23.36', 'row': 5, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2016 English-Romanian', 'metric': 'BLEU score', 'model': 'FlowSeq-base', 'value': '29.26', 'row': 5, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'WMT2016 Romanian-English', 'metric': 'BLEU score', 'model': 'FlowSeq-base', 'value': '30.16', 'row': 5, 'column': 4}, {'task': 'Machine Translation', 'dataset': 'IWSLT2015 German-English', 'metric': 'BLEU score', 'model': 'FlowSeq-base', 'value': '24.75', 'row': 5, 'column': 5}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'FlowSeq-large', 'value': '20.85', 'row': 6, 'column': 1}, {'task': 'Machine Translation', 'dataset': 'WMT2014 German-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large', 'value': '25.4', 'row': 6, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2016 English-Romanian', 'metric': 'BLEU score', 'model': 'FlowSeq-large', 'value': '29.86', 'row': 6, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'WMT2016 Romanian-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large', 'value': '30.69', 'row': 6, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'FlowSeq-large (IWD n = 15)', 'value': '22.94', 'row': 11, 'column': 1}, {'task': 'Machine Translation', 'dataset': 'WMT2014 German-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large (IWD n=15)', 'value': '27.16', 'row': 11, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2016 English-Romanian', 'metric': 'BLEU score', 'model': 'FlowSeq-large (IWD n = 15)', 'value': '31.08', 'row': 11, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'WMT2016 Romanian-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large (IWD n = 15)', 'value': '32.03', 'row': 11, 'column': 4}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 15)', 'value': '23.14', 'row': 12, 'column': 1}, {'task': 'Machine Translation', 'dataset': 'WMT2014 German-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 15)', 'value': '27.71', 'row': 12, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2016 English-Romanian', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n=15)', 'value': '31.97', 'row': 12, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'WMT2016 Romanian-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 15)', 'value': '32.46', 'row': 12, 'column': 4}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 30)', 'value': '23.64', 'row': 13, 'column': 1}, {'task': 'Machine Translation', 'dataset': 'WMT2014 German-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 30)', 'value': '28.29', 'row': 13, 'column': 2}, {'task': 'Machine Translation', 'dataset': 'WMT2016 English-Romanian', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 30)', 'value': '32.35', 'row': 13, 'column': 3}, {'task': 'Machine Translation', 'dataset': 'WMT2016 Romanian-English', 'metric': 'BLEU score', 'model': 'FlowSeq-large (NPD n = 30)', 'value': '32.91', 'row': 13, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'P-GCN', 'value': '69.5', 'row': 21, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': 'P-GCN', 'value': '67.8', 'row': 21, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'P-GCN', 'value': '63.6', 'row': 21, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'P-GCN', 'value': '57.8', 'row': 21, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'P-GCN', 'value': '49.1', 'row': 21, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'P-GCN*', 'value': '48.26', 'row': 10, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.75', 'model': 'P-GCN*', 'value': '33.16', 'row': 10, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.95', 'model': 'P-GCN*', 'value': '3.27', 'row': 10, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP', 'model': 'P-GCN*', 'value': '31.11', 'row': 10, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'LCSCNet', 'value': '33.99', 'row': 5, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'LCSCNet', 'value': '29.87', 'row': 5, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'LCSCNet', 'value': '28.87', 'row': 5, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'LCSCNet', 'value': '27.24', 'row': 5, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)', 'value': '71.9', 'row': 22, 'column': 3}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)', 'value': '35.5', 'row': 22, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA-CP', 'metric': 'Score', 'model': 'Learned-Mixin +H', 'value': '52.05', 'row': 5, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Multiple Object Tracking', 'dataset': 'KITTI Tracking test', 'metric': 'MOTA', 'model': 'mmMOT-normal', 'value': '84.77', 'row': 7, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 5-way', 'metric': 'Accuracy', 'model': 'iMAML, Hessian-Free', 'value': '99.50', 'row': 5, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 5-way', 'metric': 'Accuracy', 'model': 'iMAML, Hessian-Free', 'value': '99.74', 'row': 5, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 1-Shot, 20-way', 'metric': 'Accuracy', 'model': 'iMAML, Hessian-Free', 'value': '96.18', 'row': 5, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'OMNIGLOT - 5-Shot, 20-way', 'metric': 'Accuracy', 'model': 'iMAML, Hessian-Free', 'value': '99.14', 'row': 5, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'iMAML HF', 'value': '49.30', 'row': 5, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-German', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '91.62', 'row': 6, 'column': 1}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Spanish', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '79.1', 'row': 6, 'column': 2}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '89.42', 'row': 6, 'column': 3}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Italian', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '76.02', 'row': 6, 'column': 4}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Japanese', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '69.57', 'row': 6, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Russian', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '67.83', 'row': 6, 'column': 6}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Chinese', 'metric': 'Accuracy', 'model': 'MultiFiT, pseudo', 'value': '82.48', 'row': 6, 'column': 7}]}\n","{'index': 6, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APS', 'model': 'FCOS (ResNet-50-FPN + improvements)', 'value': '22.3', 'row': 6, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'Edge-informed SR', 'value': '28.59', 'row': 5, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'Edge-informed SR', 'value': '25.19', 'row': 6, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'Edge-informed SR', 'value': '24.25', 'row': 7, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Celeb-HQ 4x upscaling', 'metric': 'PSNR', 'model': 'Edge-informed SR', 'value': '28.23', 'row': 8, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'Edge-informed SR', 'value': '0.965', 'row': 17, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'Edge-informed SR', 'value': '0.894', 'row': 18, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'Edge-informed SR', 'value': '0.851', 'row': 19, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Celeb-HQ 4x upscaling', 'metric': 'SSIM', 'model': 'Edge-informed SR', 'value': '0.912', 'row': 20, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Image Retrieval', 'dataset': 'Flickr30K 1K test', 'metric': 'R@1', 'model': 'CAMP', 'value': '51.5', 'row': 10, 'column': 4}, {'task': 'Image Retrieval', 'dataset': 'Flickr30K 1K test', 'metric': 'R@5', 'model': 'CAMP', 'value': '77.1', 'row': 10, 'column': 5}, {'task': 'Image Retrieval', 'dataset': 'Flickr30K 1K test', 'metric': 'R@10', 'model': 'CAMP', 'value': '85.3', 'row': 10, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma15', 'metric': 'PSNR', 'model': 'CSCNet', 'value': '33.83', 'row': 1, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma25', 'metric': 'PSNR', 'model': 'CSCNet', 'value': '31.18', 'row': 2, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma50', 'metric': 'PSNR', 'model': 'CSCNet', 'value': '28', 'row': 3, 'column': 4}, {'task': 'Color Image Denoising', 'dataset': 'BSD68 sigma75', 'metric': 'PSNR', 'model': 'CSCNet', 'value': '26.32', 'row': 4, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'DGCNet (ResNet-101)', 'value': '82', 'row': 16, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL Context', 'metric': 'mIoU', 'model': 'DGCNet (MS, ResNet-101)', 'value': '53.7', 'row': 16, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'Transformer', 'value': '5.7', 'row': 2, 'column': 4}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'Transformer', 'value': '2.6', 'row': 4, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'VOT2017', 'metric': 'Expected Average Overlap (EAO)', 'model': 'GradNet', 'value': '0.247', 'row': 1, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Visual Object Tracking', 'dataset': 'OTB-2015', 'metric': 'Precision', 'model': 'GradNet', 'value': '0.861', 'row': 1, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Cross-Lingual Sentiment Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '5.95', 'row': 10, 'column': 2}, {'task': 'Cross-Lingual Sentiment Classification', 'dataset': 'MLDoc Zero-Shot English-to-German', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '6.12', 'row': 10, 'column': 3}, {'task': 'Cross-Lingual Sentiment Classification', 'dataset': 'MLDoc Zero-Shot English-to-Chinese', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '7.74', 'row': 10, 'column': 4}, {'task': 'Cross-Lingual Sentiment Classification', 'dataset': 'Dianping (Yelp train)', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '4.64', 'row': 10, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-French', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '3.95', 'row': 11, 'column': 2}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-German', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '3.05', 'row': 11, 'column': 3}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Spanish', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '3.2', 'row': 11, 'column': 4}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Chinese', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '6.68', 'row': 11, 'column': 5}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'MLDoc Zero-Shot English-to-Russian', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '10.3', 'row': 11, 'column': 6}]}\n","{'index': 7, 'records': [{'task': 'Cross-Domain Document Classification', 'dataset': 'Yelp (Amazon en train)', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '3.34', 'row': 10, 'column': 2}, {'task': 'Cross-Domain Document Classification', 'dataset': 'Amazon en (Yelp train)', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '7.57', 'row': 10, 'column': 3}, {'task': 'Cross-Domain Document Classification', 'dataset': 'Dianping (Amazon cn train)', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '4.64', 'row': 10, 'column': 4}, {'task': 'Cross-Domain Document Classification', 'dataset': 'Amazon cn (Dianping train)', 'metric': 'Error rate', 'model': 'XLMft UDA', 'value': '7.74', 'row': 10, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Text-to-Image Generation', 'dataset': 'CUB', 'metric': 'Inception score', 'model': 'Attention-driven Generator (perceptual loss)', 'value': '4.58', 'row': 4, 'column': 1}, {'task': 'Text-to-Image Generation', 'dataset': 'COCO', 'metric': 'Inception score', 'model': 'Attention-driven Generator (perceptual loss)', 'value': '24.06', 'row': 4, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'GALDNet(+Mapillary)++', 'value': '83.3', 'row': 6, 'column': 2}]}\n","{'index': 11, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'PASCAL VOC 2007', 'metric': 'Mean IoU', 'model': 'GALDNet', 'value': '83', 'row': 5, 'column': 21}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'MNIST-to-USPS', 'metric': 'Accuracy', 'model': '3CATN', 'value': '96.1', 'row': 9, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'USPS-to-MNIST', 'metric': 'Accuracy', 'model': '3CATN', 'value': '98.3', 'row': 9, 'column': 2}, {'task': 'Domain Adaptation', 'dataset': 'SVNH-to-MNIST', 'metric': 'Accuracy', 'model': '3CATN', 'value': '92.5', 'row': 9, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Speech Recognition', 'dataset': 'WSJ eval92', 'metric': 'Word Error Rate (WER)', 'model': 'Espresso', 'value': '3.4', 'row': 9, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-clean', 'metric': 'Word Error Rate (WER)', 'model': 'Espresso', 'value': '2.8', 'row': 9, 'column': 3}, {'task': 'Speech Recognition', 'dataset': 'LibriSpeech test-other', 'metric': 'Word Error Rate (WER)', 'model': 'Espresso', 'value': '8.7', 'row': 9, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Speech Recognition', 'dataset': \"Hub5'00 SwitchBoard\", 'metric': 'Word Error Rate (WER)', 'model': 'Espresso', 'value': '9.2', 'row': 5, 'column': 1}, {'task': 'Speech Recognition', 'dataset': \"Hub5'00 CallHome\", 'metric': 'Word Error Rate (WER)', 'model': 'Espresso', 'value': '19.1', 'row': 5, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'MuJoCo Games', 'dataset': 'Point Maze', 'metric': 'Average Return', 'model': 'PEMIRL', 'value': '-7.37', 'row': 6, 'column': 1}, {'task': 'MuJoCo Games', 'dataset': 'Ant', 'metric': 'Average Return', 'model': 'PEMIRL', 'value': '846.18', 'row': 6, 'column': 2}, {'task': 'MuJoCo Games', 'dataset': 'Sweeper', 'metric': 'Average Return', 'model': 'PEMIRL', 'value': '-74.17', 'row': 6, 'column': 3}, {'task': 'MuJoCo Games', 'dataset': 'Sawyer Pusher', 'metric': 'Average Return', 'model': 'PEMIRL', 'value': '-27.16', 'row': 6, 'column': 4}]}\n","{'index': 8, 'records': [{'task': 'Text Classification', 'dataset': 'AG News', 'metric': 'Accuracy', 'model': 'ULMFiT (Small data)', 'value': '93.7', 'row': 8, 'column': 1}, {'task': 'Text Classification', 'dataset': 'DBpedia', 'metric': 'Accuracy', 'model': 'ULMFiT (Small data)', 'value': '99.2', 'row': 8, 'column': 2}, {'task': 'Text Classification', 'dataset': 'Sogou News', 'metric': 'Accuracy', 'model': 'ULMFiT (Small data)', 'value': '97', 'row': 8, 'column': 3}, {'task': 'Text Classification', 'dataset': 'Yelp-5', 'metric': 'Accuracy', 'model': 'ULMFiT (Small data)', 'value': '67.6', 'row': 8, 'column': 4}, {'task': 'Text Classification', 'dataset': 'Yelp-2', 'metric': 'Accuracy', 'model': 'ULMFiT (Small data)', 'value': '97.1', 'row': 8, 'column': 5}, {'task': 'Text Classification', 'dataset': 'Yahoo! Answers', 'metric': 'Accuracy', 'model': 'ULMFiT (Small data)', 'value': '74.3', 'row': 8, 'column': 6}, {'task': 'Text Classification', 'dataset': 'Amazon-2', 'metric': 'Error', 'model': 'ULMFiT (Small data)', 'value': '3.9', 'row': 8, 'column': 7}, {'task': 'Text Classification', 'dataset': 'Amazon-5', 'metric': 'Error', 'model': 'ULMFiT (Small data)', 'value': '35.9', 'row': 8, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'USR-248 - 4x upscaling', 'metric': 'PSNR', 'model': 'SRDRM-GAN', 'value': '24.62', 'row': 6, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'USR-248 - 4x upscaling', 'metric': 'SSIM', 'model': 'SRDRM-GAN', 'value': '0.69', 'row': 6, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'USR-248 - 4x upscaling', 'metric': 'UIQM', 'model': 'SRDRM-GAN', 'value': '2.48', 'row': 6, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Dice Score', 'model': 'StyleSegor (adjusted)', 'value': '0.825', 'row': 12, 'column': 1}, {'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Dice Score', 'model': 'StyleSegor (adjusted)', 'value': '0.934', 'row': 12, 'column': 2}, {'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Hausdorff Distance (mm)', 'model': 'StyleSegor (adjusted)', 'value': '4.633', 'row': 12, 'column': 3}, {'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Dice Score', 'model': 'StyleSegor (adjusted)', 'value': '0.923', 'row': 12, 'column': 4}, {'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Hausdorff Distance (mm)', 'model': 'StyleSegor (adjusted)', 'value': '1.073', 'row': 12, 'column': 5}, {'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Hausdorff Distance (mm)', 'model': 'StyleSegor (adjusted)', 'value': '7.435', 'row': 12, 'column': 6}, {'task': 'Cardiovascular MR Segmentaiton', 'dataset': 'HVSMR 2016', 'metric': 'Dice Score', 'model': 'StyleSegor (adjusted)', 'value': '-0.03', 'row': 12, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'TinyBERT', 'value': '82.5', 'row': 7, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Mismatched', 'model': 'TinyBERT', 'value': '81.8', 'row': 7, 'column': 2}, {'task': 'Paraphrase Identification', 'dataset': 'Quora Question Pairs', 'metric': 'Accuracy', 'model': 'TinyBERT', 'value': '71.3', 'row': 7, 'column': 3}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'TinyBERT', 'value': '92.6', 'row': 7, 'column': 4}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'TinyBERT', 'value': '87.7', 'row': 7, 'column': 5}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'TinyBERT', 'value': '86.4', 'row': 7, 'column': 6}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'TinyBERT', 'value': '62.9', 'row': 7, 'column': 7}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'TinyBERT', 'value': '43.3', 'row': 7, 'column': 8}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'TinyBERT', 'value': '0.799', 'row': 7, 'column': 9}]}\n","{'index': 3, 'records': [{'task': 'Natural Language Inference', 'dataset': 'MultiNLI Dev', 'metric': 'Matched', 'model': \"TinyBERT (M=6;d'=768;d'i=3072)\", 'value': '84.5', 'row': 7, 'column': 1}, {'task': 'Natural Language Inference', 'dataset': 'MultiNLI Dev', 'metric': 'Mismatched', 'model': \"TinyBERT (M=6;d'=768;d'i=3072)\", 'value': '84.5', 'row': 7, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC Dev', 'metric': 'Accuracy', 'model': \"TinyBERT (M=6;d'=768;d'i=3072)\", 'value': '86.3', 'row': 7, 'column': 3}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA Dev', 'metric': 'Accuracy', 'model': \"TinyBERT (M=6;d' =768;d'i=3072)\", 'value': '54', 'row': 7, 'column': 4}]}\n","{'index': 7, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': \"TinyBERT (M=6;d' =768;d'i=3072)\", 'value': '79.7', 'row': 10, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': \"TinyBERT (M=6;d' =768;d'i=3072)\", 'value': '87.5', 'row': 10, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'EM', 'model': \"TinyBERT (M=6;d' =768;d'i=3072)\", 'value': '69.9', 'row': 10, 'column': 3}, {'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': \"TinyBERT (M=6;d' =768;d'i=3072)\", 'value': '73.4', 'row': 10, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Image Captioning', 'dataset': 'COCO Captions test', 'metric': 'BLEU-4', 'model': 'Unified VLP', 'value': '36.5', 'row': 17, 'column': 1}, {'task': 'Image Captioning', 'dataset': 'COCO Captions test', 'metric': 'METEOR', 'model': 'Unified VLP', 'value': '28.4', 'row': 17, 'column': 2}, {'task': 'Image Captioning', 'dataset': 'COCO Captions test', 'metric': 'CIDEr', 'model': 'Unified VLP', 'value': '116.9', 'row': 17, 'column': 3}, {'task': 'Image Captioning', 'dataset': 'COCO Captions test', 'metric': 'SPICE', 'model': 'Unified VLP', 'value': '21.2', 'row': 17, 'column': 4}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'Unified VLP', 'value': '70.7', 'row': 17, 'column': 5}, {'task': 'Image Captioning', 'dataset': 'Flickr30k Captions test', 'metric': 'BLEU-4', 'model': 'Unified VLP', 'value': '30.1', 'row': 17, 'column': 9}, {'task': 'Image Captioning', 'dataset': 'Flickr30k Captions test', 'metric': 'METEOR', 'model': 'Unified VLP', 'value': '23', 'row': 17, 'column': 10}, {'task': 'Image Captioning', 'dataset': 'Flickr30k Captions test', 'metric': 'CIDEr', 'model': 'Unified VLP', 'value': '67.4', 'row': 17, 'column': 11}, {'task': 'Image Captioning', 'dataset': 'Flickr30k Captions test', 'metric': 'SPICE', 'model': 'Unified VLP', 'value': '17', 'row': 17, 'column': 12}]}\n","{'index': 3, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '73.24', 'row': 4, 'column': 9}, {'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-std', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '73.4', 'row': 5, 'column': 9}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-A) test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '77.3', 'row': 6, 'column': 9}, {'task': 'Visual Question Answering', 'dataset': 'VCR (QA-R) test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '80.8', 'row': 7, 'column': 9}, {'task': 'Visual Question Answering', 'dataset': 'VCR (Q-AR) test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '62.8', 'row': 8, 'column': 9}, {'task': 'Visual Reasoning', 'dataset': 'NLVR2 Test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '78.4', 'row': 9, 'column': 9}, {'task': 'Visual Reasoning', 'dataset': 'NLVR2 Test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '79.5', 'row': 10, 'column': 9}, {'task': 'Visual Entailment', 'dataset': 'SNLI-VE test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '79.28', 'row': 11, 'column': 9}, {'task': 'Visual Entailment', 'dataset': 'SNLI-VE test', 'metric': 'Accuracy', 'model': 'UNITER (Large)', 'value': '78.98', 'row': 12, 'column': 9}]}\n","{'index': 2, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'UDA-SA + CyCADA', 'value': '41.2', 'row': 5, 'column': 20}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '95.62', 'row': 5, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'IMDb-B', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '93.5', 'row': 5, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '74.8', 'row': 5, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'REDDIT-B', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '84.8', 'row': 5, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'REDDIT-MULTI-5k', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '77.25', 'row': 5, 'column': 6}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '77.84', 'row': 18, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'IMDb-B', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '79.4', 'row': 18, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '56.2', 'row': 18, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'REDDIT-B', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '80.25', 'row': 18, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'REDDIT-MULTI-5k', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '50.9', 'row': 18, 'column': 6}]}\n","{'index': 2, 'records': [{'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '95.67', 'row': 5, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '78.07', 'row': 5, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '81.34', 'row': 5, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'U2GNN (Unsupervised)', 'value': '84.59', 'row': 5, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '81.24', 'row': 18, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '78.53', 'row': 18, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '89.97', 'row': 18, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'PTC', 'metric': 'Accuracy', 'model': 'U2GNN', 'value': '79.36', 'row': 18, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '38.00', 'row': 14, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 2x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '33.63', 'row': 14, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '32.19', 'row': 14, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 2x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '32.17', 'row': 14, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 2x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '38.88', 'row': 14, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '34.36', 'row': 27, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 3x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '30.32', 'row': 27, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '29.09', 'row': 27, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 3x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '28.17', 'row': 27, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 3x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '33.61', 'row': 27, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '32.21', 'row': 40, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '28.58', 'row': 40, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '27.56', 'row': 40, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '26.04', 'row': 40, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'IMDN', 'value': '30.45', 'row': 40, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Medical Visual Question Answering', 'dataset': 'VQA-RAD', 'metric': 'Open-ended Accuracy', 'model': 'MEVF (finetuning)', 'value': '40.7', 'row': 8, 'column': 1}, {'task': 'Medical Visual Question Answering', 'dataset': 'VQA-RAD', 'metric': 'Close-ended Accuracy', 'model': 'MEVF (finetuning)', 'value': '74.1', 'row': 8, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Visual Question Answering', 'dataset': 'TDIUC', 'metric': 'Accuracy', 'model': 'BAN2-CTI', 'value': '87', 'row': 2, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v2 test-dev', 'metric': 'Accuracy', 'model': 'BAN2-CTI', 'value': '67.4', 'row': 5, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Visual Question Answering', 'dataset': 'Visual7W', 'metric': 'Percentage correct', 'model': 'CTI (with Boxes)', 'value': '72.3', 'row': 8, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'ALBERT xxlarge', 'value': '88.1', 'row': 6, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'ALBERT base', 'value': '79.1', 'row': 7, 'column': 4}]}\n","{'index': 8, 'records': [{'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'ALBERT', 'value': '99.2', 'row': 13, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'ALBERT', 'value': '97.1', 'row': 13, 'column': 5}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'Accuracy', 'model': 'ALBERT', 'value': '93.4', 'row': 13, 'column': 6}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'ALBERT', 'value': '0.925', 'row': 13, 'column': 8}]}\n","{'index': 10, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD2.0 dev', 'metric': 'F1', 'model': 'ALBERT large', 'value': '82.1', 'row': 5, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'BBG (ResNet-18)', 'value': '59.4', 'row': 9, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'BBG (ResNet-18)', 'value': '81.3', 'row': 9, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'BBG (ResNet-34)', 'value': '62.6', 'row': 5, 'column': 3}, {'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'BBG (ResNet-34)', 'value': '84.1', 'row': 5, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Multi-Object Tracking', 'dataset': 'MOT16', 'metric': 'MOTA', 'model': 'JDE', 'value': '64.4', 'row': 7, 'column': 5}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Accuracy', 'model': 'CullNet', 'value': '97.7%', 'row': 3, 'column': 14}, {'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'CullNet', 'value': '78.3', 'row': 12, 'column': 14}]}\n","{'index': 2, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'Occlusion LineMOD', 'metric': 'Mean ADD', 'model': 'CullNet', 'value': '24.48', 'row': 12, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'MLSL (SISC-PWL)', 'value': '49', 'row': 11, 'column': 21}]}\n","{'index': 0, 'records': [{'task': 'OpenAI Gym', 'dataset': 'Ant-v2', 'metric': 'Average Return', 'model': 'AWR', 'value': '5067', 'row': 1, 'column': 7}, {'task': 'OpenAI Gym', 'dataset': 'HalfCheetah-v2', 'metric': 'Average Return', 'model': 'AWR', 'value': '9136', 'row': 2, 'column': 7}, {'task': 'OpenAI Gym', 'dataset': 'Hopper-v2', 'metric': 'Average Return', 'model': 'AWR', 'value': '3405', 'row': 3, 'column': 7}, {'task': 'OpenAI Gym', 'dataset': 'Humanoid-v2', 'metric': 'Average Return', 'model': 'AWR', 'value': '4996', 'row': 4, 'column': 7}, {'task': 'OpenAI Gym', 'dataset': 'LunarLander-v2', 'metric': 'Average Return', 'model': 'AWR', 'value': '229', 'row': 5, 'column': 7}, {'task': 'OpenAI Gym', 'dataset': 'Walker2d-v2', 'metric': 'Average Return', 'model': 'AWR', 'value': '5813', 'row': 6, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'DistilBERT', 'value': '0.907', 'row': 3, 'column': 8}]}\n","{'index': 4, 'records': [{'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AUC', 'model': 'Node Feature Agg + Similarity Metric', 'value': '93.1', 'row': 4, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AP', 'model': 'Node Feature Agg + Similarity Metric', 'value': '93.2', 'row': 4, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AUC', 'model': 'Node Feature Agg + Similarity Metric', 'value': '90.9', 'row': 4, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AP', 'model': 'Node Feature Agg + Similarity Metric', 'value': '91.8', 'row': 4, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AUC', 'model': 'Node Feature Agg + Similarity Metric', 'value': '94.5', 'row': 4, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AP', 'model': 'Node Feature Agg + Similarity Metric', 'value': '94.2', 'row': 4, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'Patches', 'value': '87.87', 'row': 10, 'column': 2}, {'task': 'Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'Patches', 'value': '77.16', 'row': 10, 'column': 3}, {'task': 'Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'Patches', 'value': '68.91', 'row': 10, 'column': 4}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'Patches', 'value': '89.78', 'row': 10, 'column': 5}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'Patches', 'value': '86.55', 'row': 10, 'column': 6}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'Patches', 'value': '79.22', 'row': 10, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Image Generation', 'dataset': 'MNIST', 'metric': 'FID', 'model': 'PresGAN', 'value': '42.019', 'row': 4, 'column': 2}, {'task': 'Image Generation', 'dataset': 'Stacked MNIST', 'metric': 'FID', 'model': 'PresGAN', 'value': '23.965', 'row': 8, 'column': 2}, {'task': 'Image Generation', 'dataset': 'CIFAR-10', 'metric': 'FID', 'model': 'PresGAN', 'value': '52.202', 'row': 12, 'column': 2}, {'task': 'Image Generation', 'dataset': 'CelebA 128 x 128', 'metric': 'FID', 'model': 'PresGAN', 'value': '29.115', 'row': 16, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '32.69', 'row': 10, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.9', 'row': 10, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '28.94', 'row': 10, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 4x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.789', 'row': 10, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '27.82', 'row': 10, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.743', 'row': 10, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '27.06', 'row': 10, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 4x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.8109999999999999', 'row': 10, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '31.79', 'row': 10, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 4x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.9209999999999999', 'row': 10, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '27.25', 'row': 19, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 8x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.7859999999999999', 'row': 19, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '25.08', 'row': 19, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'Set14 - 8x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.638', 'row': 19, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 8x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '24.99', 'row': 19, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 8x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.604', 'row': 19, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '23.04', 'row': 19, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 8x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.6409999999999999', 'row': 19, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '25.29', 'row': 19, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 8x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.802', 'row': 19, 'column': 11}, {'task': 'Image Super-Resolution', 'dataset': 'DIV8K val - 16x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '26.71', 'row': 25, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'DIV8K val - 16x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.65', 'row': 25, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'DIV2K val - 16x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '24.38', 'row': 25, 'column': 4}, {'task': 'Image Super-Resolution', 'dataset': 'DIV2K val - 16x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.6409999999999999', 'row': 25, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 16x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '22.72', 'row': 25, 'column': 6}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 16x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.512', 'row': 25, 'column': 7}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 16x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '20.39', 'row': 25, 'column': 8}, {'task': 'Image Super-Resolution', 'dataset': 'Urban100 - 16x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.515', 'row': 25, 'column': 9}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 16x upscaling', 'metric': 'PSNR', 'model': 'ABPN', 'value': '21.25', 'row': 25, 'column': 10}, {'task': 'Image Super-Resolution', 'dataset': 'Manga109 - 16x upscaling', 'metric': 'SSIM', 'model': 'ABPN', 'value': '0.6729999999999999', 'row': 25, 'column': 11}]}\n","{'index': 3, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'VarGFaceNet', 'value': '99.85', 'row': 3, 'column': 1}, {'task': 'Face Verification', 'dataset': 'CFP-FP', 'metric': 'Accuracy', 'model': 'VarGFaceNet', 'value': '0.985', 'row': 3, 'column': 2}, {'task': 'Face Verification', 'dataset': 'AgeDB-30', 'metric': 'Accuracy', 'model': 'VarGFaceNet', 'value': '0.9815', 'row': 3, 'column': 3}]}\n","{'index': 3, 'records': [{'task': 'Glyph Image Generation', 'dataset': 'English Glyph', 'metric': 'Inception score', 'model': 'AGIS-Net', 'value': '3.8151', 'row': 3, 'column': 1}, {'task': 'Glyph Image Generation', 'dataset': 'English Glyph', 'metric': 'FID', 'model': 'AGIS-Net', 'value': '73.893', 'row': 3, 'column': 2}, {'task': 'Glyph Image Generation', 'dataset': 'English Glyph', 'metric': 'SSIM', 'model': 'AGIS-Net', 'value': '0.7217', 'row': 3, 'column': 3}, {'task': 'Glyph Image Generation', 'dataset': 'English Glyph', 'metric': 'Pixel Accuracy', 'model': 'AGIS-Net', 'value': '0.6249', 'row': 3, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Glyph Image Generation', 'dataset': 'Chinese Glyph', 'metric': 'Inception score', 'model': 'AGIS-Net', 'value': '2.1122', 'row': 2, 'column': 1}, {'task': 'Glyph Image Generation', 'dataset': 'Chinese Glyph', 'metric': 'FID', 'model': 'AGIS-Net', 'value': '70.875', 'row': 2, 'column': 2}, {'task': 'Glyph Image Generation', 'dataset': 'Chinese Glyph', 'metric': 'SSIM', 'model': 'AGIS-Net', 'value': '0.6116', 'row': 2, 'column': 3}, {'task': 'Glyph Image Generation', 'dataset': 'Chinese Glyph', 'metric': 'Pixel Accuracy', 'model': 'AGIS-Net', 'value': '0.7035', 'row': 2, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Click-Through Rate Prediction', 'dataset': 'Criteo', 'metric': 'AUC', 'model': 'Fi-GNN', 'value': '0.8082', 'row': 9, 'column': 2}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Criteo', 'metric': 'Log Loss', 'model': 'Fi-GNN', 'value': '0.4411', 'row': 9, 'column': 4}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avazu', 'metric': 'AUC', 'model': 'Fi-GNN', 'value': '0.812', 'row': 9, 'column': 6}, {'task': 'Click-Through Rate Prediction', 'dataset': 'Avazu', 'metric': 'Log Loss', 'model': 'Fi-GNN', 'value': '0.3817', 'row': 9, 'column': 8}]}\n","{'index': 5, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'DARK (extra data)', 'value': '77.4', 'row': 14, 'column': 5}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'DARK (extra data)', 'value': '92.6', 'row': 14, 'column': 6}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'DARK (extra data)', 'value': '84.6', 'row': 14, 'column': 7}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'DARK (extra data)', 'value': '73.6', 'row': 14, 'column': 8}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'DARK (extra data)', 'value': '83.7', 'row': 14, 'column': 9}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'DARK (extra data)', 'value': '82.3', 'row': 14, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'COCO-Stuff Labels-to-Photos', 'metric': 'mIoU', 'model': 'CC-FPSE', 'value': '41.6', 'row': 6, 'column': 1}, {'task': 'Image-to-Image Translation', 'dataset': 'COCO-Stuff Labels-to-Photos', 'metric': 'FID', 'model': 'CC-FPSE', 'value': '19.2', 'row': 6, 'column': 3}]}\n","{'index': 8, 'records': [{'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-1', 'model': 'OSNet-AIN', 'value': '61', 'row': 9, 'column': 8}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-5', 'model': 'OSNet-AIN', 'value': '77', 'row': 9, 'column': 9}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'Rank-10', 'model': 'OSNet-AIN', 'value': '82.5', 'row': 9, 'column': 10}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'DukeMTMC-reID->Market-1501', 'metric': 'MAP', 'model': 'OSNet-AIN', 'value': '30.6', 'row': 9, 'column': 11}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'OSNet-AIN', 'value': '70.1', 'row': 12, 'column': 3}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'OSNet-AIN', 'value': '84.1', 'row': 12, 'column': 4}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->DukeMTMC-reID', 'metric': 'Rank-10', 'model': 'OSNet-AIN', 'value': '88.6', 'row': 12, 'column': 5}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->DukeMTMC-reID', 'metric': 'mAP', 'model': 'OSNet-AIN', 'value': '43.3', 'row': 12, 'column': 6}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->Market-1501', 'metric': 'Rank-1', 'model': 'OSNet-AIN', 'value': '71.1', 'row': 12, 'column': 8}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->Market-1501', 'metric': 'Rank-5', 'model': 'OSNet-AIN', 'value': '83.3', 'row': 12, 'column': 9}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->Market-1501', 'metric': 'Rank-10', 'model': 'OSNet-AIN', 'value': '86.4', 'row': 12, 'column': 10}, {'task': 'Unsupervised Person Re-Identification', 'dataset': 'MSMT17->Market-1501', 'metric': 'mAP', 'model': 'OSNet-AIN', 'value': '52.7', 'row': 12, 'column': 11}]}\n","{'index': 1, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'S3DIS', 'metric': 'Mean IoU', 'model': 'ResGCN-28', 'value': '60', 'row': 7, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Node Classification', 'dataset': 'PPI', 'metric': 'F1', 'model': 'ResMRGCN-28', 'value': '99.41', 'row': 7, 'column': 1}, {'task': 'Node Classification', 'dataset': 'PPI', 'metric': 'F1', 'model': 'DenseMRGCN-14', 'value': '99.43', 'row': 8, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Freeway', 'metric': 'Score', 'model': 'SAC', 'value': '4.4', 'row': 1, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Ms. Pacman', 'metric': 'Score', 'model': 'SAC', 'value': '690.9', 'row': 2, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Enduro', 'metric': 'Score', 'model': 'SAC', 'value': '0.8', 'row': 3, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Battle Zone', 'metric': 'Score', 'model': 'SAC', 'value': '4386.7', 'row': 4, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Q*Bert', 'metric': 'Score', 'model': 'SAC', 'value': '280.5', 'row': 5, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Space Invaders', 'metric': 'Score', 'model': 'SAC', 'value': '160.8', 'row': 6, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': 'Score', 'model': 'SAC', 'value': '432.1', 'row': 7, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'SAC', 'value': '350.0', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Assault', 'metric': 'Score', 'model': 'SAC', 'value': '350', 'row': 8, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 James Bond', 'metric': 'Score', 'model': 'SAC', 'value': '68.3', 'row': 9, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Seaquest', 'metric': 'Score', 'model': 'SAC', 'value': '211.6', 'row': 10, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Score', 'model': 'SAC', 'value': '272', 'row': 11, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Kangaroo', 'metric': 'Score', 'model': 'SAC', 'value': '29.3', 'row': 12, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Score', 'model': 'SAC', 'value': '216.9', 'row': 13, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Road Runner', 'metric': 'Score', 'model': 'SAC', 'value': '305.3', 'row': 14, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Frostbite', 'metric': 'Score', 'model': 'SAC', 'value': '59.4', 'row': 15, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Amidar', 'metric': 'Score', 'model': 'SAC', 'value': '7.9', 'row': 16, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Crazy Climber', 'metric': 'Score', 'model': 'SAC', 'value': '3668.7', 'row': 17, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'Score', 'model': 'SAC', 'value': '0.7', 'row': 18, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Up and Down', 'metric': 'Score', 'model': 'SAC', 'value': '250.7', 'row': 19, 'column': 3}, {'task': 'Atari Games', 'dataset': 'Atari 2600 Pong', 'metric': 'Score', 'model': 'SAC', 'value': '-20.98', 'row': 20, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-50 (single-scale)', 'value': '89.7', 'row': 2, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-57 (single-scale)', 'value': '89.66', 'row': 4, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-88 (single-scale)', 'value': '90.97', 'row': 6, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CharNet H-50 (single-scale)', 'value': '88.3', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CharNet H-50 (single-scale)', 'value': '91.15', 'row': 6, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-50 (single-scale)', 'value': '89.7', 'row': 6, 'column': 4}]}\n","{'index': 3, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CharNet H-57 (single-scale)', 'value': '88.88', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CharNet H-57 (single-scale)', 'value': '90.45', 'row': 9, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-57', 'value': '89.66', 'row': 9, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CharNet H-88 (single-scale)', 'value': '89.99', 'row': 10, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CharNet H-88 (single-scale)', 'value': '91.98', 'row': 10, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-88', 'value': '90.97', 'row': 10, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CharNet H-50 (multi-scale)', 'value': '90.9', 'row': 14, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CharNet H-50 (multi-scale)', 'value': '89.44', 'row': 14, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-50 (multi-scale)', 'value': '90.16', 'row': 14, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CharNet H-57 (multi-scale)', 'value': '91.43', 'row': 15, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CharNet H-57 (multi-scale)', 'value': '88.74', 'row': 15, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-57 (multi-scale)', 'value': '90.06', 'row': 15, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'CharNet H-88 (multi-scale)', 'value': '90.47', 'row': 16, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-88 MS', 'value': '92.65', 'row': 16, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'CharNet H-88 (multi-scale)', 'value': '92.65', 'row': 16, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'CharNet H-88 (multi-scale)', 'value': '91.55', 'row': 16, 'column': 4}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'Charnet H-88', 'value': '91.55', 'row': 16, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'CharNet H-88', 'value': '81.7', 'row': 7, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'CharNet H-88', 'value': '89.9', 'row': 7, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'CharNet H-88', 'value': '85.6', 'row': 7, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Recall', 'model': 'CharNet H-88 (multi-scale)', 'value': '85', 'row': 9, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'Precision', 'model': 'CharNet H-88 (multi-scale)', 'value': '88', 'row': 9, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'Total-Text', 'metric': 'F-Measure', 'model': 'CharNet H-88 (multi-scale)', 'value': '86.5', 'row': 9, 'column': 3}]}\n","{'index': 5, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'CharNet R-50 ', 'value': '70.1', 'row': 5, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'CharNet R-50 ', 'value': '77.07', 'row': 5, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'CharNet R-50 ', 'value': '73.42', 'row': 5, 'column': 3}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'CharNet H-88', 'value': '70.97', 'row': 6, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'CharNet H-88', 'value': '81.27', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'CharNet H-88', 'value': '81.27', 'row': 6, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'CharNet H-88', 'value': '75.77', 'row': 6, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'FFHQ 1024 x 1024 - 4x upscaling', 'metric': 'PSNR', 'model': 'CAGFace', 'value': '34.1', 'row': 9, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'FFHQ 1024 x 1024 - 4x upscaling', 'metric': 'SSIM', 'model': 'CAGFace', 'value': '0.906', 'row': 9, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'FFHQ 1024 x 1024 - 4x upscaling', 'metric': 'MS-SSIM', 'model': 'CAGFace', 'value': '0.971', 'row': 9, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'FFHQ 1024 x 1024 - 4x upscaling', 'metric': 'FID', 'model': 'CAGFace', 'value': '12.4', 'row': 9, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'FFHQ 256 x 256 - 4x upscaling', 'metric': 'PSNR', 'model': 'CAGFace', 'value': '27.42', 'row': 9, 'column': 1}, {'task': 'Image Super-Resolution', 'dataset': 'FFHQ 256 x 256 - 4x upscaling', 'metric': 'SSIM', 'model': 'CAGFace', 'value': '0.816', 'row': 9, 'column': 2}, {'task': 'Image Super-Resolution', 'dataset': 'FFHQ 256 x 256 - 4x upscaling', 'metric': 'MS-SSIM', 'model': 'CAGFace', 'value': '0.958', 'row': 9, 'column': 3}, {'task': 'Image Super-Resolution', 'dataset': 'FFHQ 256 x 256 - 4x upscaling', 'metric': 'FID', 'model': 'CAGFace', 'value': '74.43', 'row': 9, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma10', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '36.36', 'row': 2, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma30', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '33.57', 'row': 3, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma50', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '32.48', 'row': 4, 'column': 5}, {'task': 'Grayscale Image Denoising', 'dataset': 'BSD200 sigma70', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '31.17', 'row': 5, 'column': 5}]}\n","{'index': 2, 'records': [{'task': 'Image Super-Resolution', 'dataset': 'Set5 - 2x upscaling', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '37.42', 'row': 2, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 3x upscaling', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '33.43', 'row': 3, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'Set5 - 4x upscaling', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '31.01', 'row': 4, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 2x upscaling', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '31.86', 'row': 5, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 3x upscaling', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '28.76', 'row': 6, 'column': 5}, {'task': 'Image Super-Resolution', 'dataset': 'BSD100 - 4x upscaling', 'metric': 'PSNR', 'model': 'RC-Net', 'value': '27.21', 'row': 7, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'P2-Net (triplet loss)', 'value': '95.2', 'row': 19, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'P2-Net (triplet loss)', 'value': '98.2', 'row': 19, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-10', 'model': 'P2-Net (triplet loss)', 'value': '99.1', 'row': 19, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'P2-Net (triplet loss)', 'value': '85.6', 'row': 19, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'P2-Net (triplet loss)', 'value': '86.5', 'row': 15, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'P2-Net (triplet loss)', 'value': '93.1', 'row': 15, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-10', 'model': 'P2-Net (triplet loss)', 'value': '95', 'row': 15, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'P2-Net (triplet loss)', 'value': '73.1', 'row': 15, 'column': 4}]}\n","{'index': 13, 'records': [{'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'T5-Base', 'value': '51.1', 'row': 4, 'column': 2}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'T5-Large', 'value': '61.2', 'row': 5, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'F1', 'model': 'T5-Large', 'value': '92.4', 'row': 5, 'column': 4}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'T5-3B', 'value': '67.1', 'row': 6, 'column': 2}, {'task': 'Sentiment Analysis', 'dataset': 'SST-2 Binary classification', 'metric': 'Accuracy', 'model': 'T5-3B', 'value': '97.4', 'row': 6, 'column': 3}, {'task': 'Semantic Textual Similarity', 'dataset': 'STS Benchmark', 'metric': 'Pearson Correlation', 'model': 'T5-11B', 'value': '0.925', 'row': 6, 'column': 4}, {'task': 'Linguistic Acceptability', 'dataset': 'CoLA', 'metric': 'Accuracy', 'model': 'T5-11B', 'value': '70.8', 'row': 7, 'column': 2}, {'task': 'Semantic Textual Similarity', 'dataset': 'MRPC', 'metric': 'F1', 'model': 'T5-11B', 'value': '91.9', 'row': 7, 'column': 4}]}\n","{'index': 14, 'records': [{'task': 'Natural Language Inference', 'dataset': 'MultiNLI', 'metric': 'Matched', 'model': 'T5-Small', 'value': '82.4', 'row': 3, 'column': 3}, {'task': 'Natural Language Inference', 'dataset': 'WNLI', 'metric': 'Accuracy', 'model': 'T5-Base', 'value': '78.8', 'row': 4, 'column': 7}, {'task': 'Natural Language Inference', 'dataset': 'RTE', 'metric': 'Accuracy', 'model': 'T5-3B', 'value': '91.1', 'row': 6, 'column': 6}, {'task': 'Natural Language Inference', 'dataset': 'QNLI', 'metric': 'Accuracy', 'model': 'T5-11B', 'value': '96.7', 'row': 7, 'column': 5}, {'task': 'Natural Language Inference', 'dataset': 'WNLI', 'metric': 'Accuracy', 'model': 'T5-11B', 'value': '93.2', 'row': 7, 'column': 7}]}\n","{'index': 15, 'records': [{'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'T5-Small', 'value': '79.1', 'row': 3, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'T5-Small', 'value': '87.24', 'row': 3, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'T5-Base', 'value': '85.44', 'row': 4, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'T5-Base', 'value': '92.08', 'row': 4, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'EM', 'model': 'T5-Large', 'value': '86.66', 'row': 5, 'column': 1}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'T5-Large', 'value': '93.79', 'row': 5, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'T5-3B', 'value': '94.95', 'row': 6, 'column': 2}, {'task': 'Question Answering', 'dataset': 'SQuAD1.1 dev', 'metric': 'F1', 'model': 'T5-11B', 'value': '95.64', 'row': 7, 'column': 2}]}\n","{'index': 16, 'records': [{'task': 'Question Answering', 'dataset': 'ReCoRD', 'metric': 'F1', 'model': 'T5-11B', 'value': '93.3', 'row': 7, 'column': 3}, {'task': 'Word Sense Disambiguation', 'dataset': 'Words in Context', 'metric': 'Accuracy', 'model': 'T5-11B', 'value': '76.1', 'row': 7, 'column': 6}]}\n","{'index': 17, 'records': [{'task': 'Machine Translation', 'dataset': 'WMT2014 English-German', 'metric': 'BLEU score', 'model': 'T5-11B', 'value': '32.1', 'row': 7, 'column': 1}, {'task': 'Machine Translation', 'dataset': 'WMT2014 English-French', 'metric': 'BLEU score', 'model': 'T5', 'value': '43.4', 'row': 7, 'column': 2}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-1', 'model': 'T5-11B', 'value': '43.52', 'row': 7, 'column': 4}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-2', 'model': 'T5-11B', 'value': '21.55', 'row': 7, 'column': 5}, {'task': 'Document Summarization', 'dataset': 'CNN / Daily Mail', 'metric': 'ROUGE-L', 'model': 'T5-11B', 'value': '40.69', 'row': 7, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Node Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'DFNet-ATT', 'value': '86', 'row': 16, 'column': 1}, {'task': 'Node Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'DFNet-ATT', 'value': '74.7', 'row': 16, 'column': 2}, {'task': 'Node Classification', 'dataset': 'Pubmed', 'metric': 'Accuracy', 'model': 'DFNet-ATT', 'value': '85.2', 'row': 16, 'column': 3}, {'task': 'Node Classification', 'dataset': 'NELL', 'metric': 'Accuracy', 'model': 'DFNet-ATT', 'value': '68.8', 'row': 16, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Meta-Learning', 'dataset': 'ML10', 'metric': 'Average Success Rate', 'model': 'Multi-task multi-head SAC', 'value': '88%', 'row': 5, 'column': 1}, {'task': 'Meta-Learning', 'dataset': 'MT50', 'metric': 'Average Success Rate', 'model': 'Multi-task multi-head SAC', 'value': '35.85%', 'row': 5, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'Cityscapes-to-Foggy Cityscapes', 'metric': 'mAP', 'model': 'Progressive Domain Adaptation', 'value': '36.9', 'row': 9, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Image Reconstruction', 'dataset': 'Edge-to-Handbags', 'metric': 'LPIPS', 'model': 'bFT', 'value': '0.161', 'row': 4, 'column': 1}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Handbags', 'metric': 'FID', 'model': 'bFT', 'value': '74.885', 'row': 4, 'column': 2}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Shoes', 'metric': 'LPIPS', 'model': 'bFT', 'value': '0.124', 'row': 4, 'column': 3}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Shoes', 'metric': 'FID', 'model': 'bFT', 'value': '121.241', 'row': 4, 'column': 4}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Clothes', 'metric': 'LPIPS', 'model': 'bFT', 'value': '0.067', 'row': 4, 'column': 5}, {'task': 'Image Reconstruction', 'dataset': 'Edge-to-Clothes', 'metric': 'FID', 'model': 'bFT', 'value': '58.407', 'row': 4, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'SSIM', 'model': 'bFT', 'value': '0.767', 'row': 6, 'column': 1}, {'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'IS', 'model': 'bFT', 'value': '3.22', 'row': 6, 'column': 2}, {'task': 'Pose Transfer', 'dataset': 'Deep-Fashion', 'metric': 'FID', 'model': 'bFT', 'value': '12.266', 'row': 6, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Graph Classification', 'dataset': '5pt. Bench-Easy', 'metric': 'Accuracy', 'model': 'NDP', 'value': '97.9', 'row': 1, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'Bench-hard', 'metric': 'Accuracy', 'model': 'NDP', 'value': '72.6', 'row': 2, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'Graph2Vec', 'value': '73.3', 'row': 3, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'NDP', 'value': '43.9', 'row': 4, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'NDP', 'value': '73.5', 'row': 5, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'MUTAG', 'metric': 'Accuracy', 'model': 'NDP', 'value': '84.7', 'row': 6, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'Mutagenicity', 'metric': 'Accuracy', 'model': 'NDP', 'value': '78.1', 'row': 7, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'NDP', 'value': '72', 'row': 8, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'NDP', 'value': '79.1', 'row': 9, 'column': 8}, {'task': 'Graph Classification', 'dataset': 'REDDIT-B', 'metric': 'Accuracy', 'model': 'NDP', 'value': '84.3', 'row': 10, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'CAG-UDA', 'value': '50.2', 'row': 13, 'column': 20}]}\n","{'index': 2, 'records': [{'task': 'Image-to-Image Translation', 'dataset': 'SYNTHIA-to-Cityscapes', 'metric': 'mIoU', 'model': 'CAG-UDA', 'value': '44.5', 'row': 8, 'column': 17}]}\n","{'index': 0, 'records': [{'task': 'Clinical Note Phenotyping', 'dataset': 'I2B2 2006: Smoking', 'metric': 'Micro F1', 'model': 'fLSTM', 'value': '98.1', 'row': 4, 'column': 1}, {'task': 'Clinical Note Phenotyping', 'dataset': 'I2B2 2008: Obesity', 'metric': 'Micro F1', 'model': 'fLSTM', 'value': '99.7', 'row': 4, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Chinese Word Segmentation', 'dataset': 'MSR', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '97.89', 'row': 12, 'column': 1}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5 Dev', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '96.12', 'row': 12, 'column': 2}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '95.82', 'row': 12, 'column': 3}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '93.24', 'row': 12, 'column': 4}, {'task': 'Chinese Document Classification', 'dataset': 'THUCNews Dev', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '97.2', 'row': 12, 'column': 5}, {'task': 'Chinese Document Classification', 'dataset': 'THUCNews', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '96.87', 'row': 12, 'column': 6}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp Dev', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '94.87', 'row': 12, 'column': 7}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '94.42', 'row': 12, 'column': 8}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC Dev', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '88.1', 'row': 12, 'column': 9}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '85.27', 'row': 12, 'column': 10}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI Dev', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '77.11', 'row': 12, 'column': 11}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI', 'metric': 'F1', 'model': 'ZEN (Random Init)', 'value': '77.03', 'row': 12, 'column': 12}, {'task': 'Chinese Word Segmentation', 'dataset': 'MSR', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '98.35', 'row': 13, 'column': 1}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5 Dev', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '97.43', 'row': 13, 'column': 2}, {'task': 'Chinese Part-of-Speech Tagging', 'dataset': 'CTB5', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '96.64', 'row': 13, 'column': 3}, {'task': 'Chinese Named Entity Recognition', 'dataset': 'MSRA', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '95.25', 'row': 13, 'column': 4}, {'task': 'Chinese Document Classification', 'dataset': 'THUCNews Dev', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '97.66', 'row': 13, 'column': 5}, {'task': 'Chinese Document Classification', 'dataset': 'THUCNews', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '97.64', 'row': 13, 'column': 6}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp Dev', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '95.66', 'row': 13, 'column': 7}, {'task': 'Chinese Sentiment Analysis', 'dataset': 'ChnSentiCorp', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '96.08', 'row': 13, 'column': 8}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC Dev', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '90.2', 'row': 13, 'column': 9}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'LCQMC', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '87.95', 'row': 13, 'column': 10}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI Dev', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '80.48', 'row': 13, 'column': 11}, {'task': 'Chinese Sentence Pair Classification', 'dataset': 'XNLI', 'metric': 'F1', 'model': 'ZEN (Init with Chinese BERT)', 'value': '79.2', 'row': 13, 'column': 12}]}\n","{'index': 1, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', 'metric': 'Accuracy', 'model': 'Dynamic MTL', 'value': '99.21', 'row': 11, 'column': 2}, {'task': 'Face Verification', 'dataset': 'YouTube Faces DB', 'metric': 'Accuracy', 'model': 'Dynamic MTL', 'value': '94.3', 'row': 11, 'column': 3}, {'task': 'Face Verification', 'dataset': 'CK+', 'metric': 'Accuracy', 'model': 'Dynamic MTL', 'value': '99', 'row': 11, 'column': 4}, {'task': 'Face Verification', 'dataset': 'Oulu-CASIA', 'metric': 'Accuracy', 'model': 'Dynamic MTL', 'value': '99.14', 'row': 11, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Facial Expression Recognition', 'dataset': 'Oulu-CASIA', 'metric': 'Accuracy (10-fold)', 'model': 'Dynamic MTL', 'value': '89.6', 'row': 8, 'column': 1}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'CIFAR-10', 'metric': 'Percentage correct', 'model': 'SA quadratic embedding', 'value': '93.8', 'row': 2, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Part-Of-Speech Tagging', 'dataset': 'French GSD', 'metric': 'UPOS', 'model': 'CamemBERT', 'value': '98.19', 'row': 5, 'column': 1}, {'task': 'Dependency Parsing', 'dataset': 'French GSD', 'metric': 'UAS', 'model': 'CamemBERT', 'value': '94.82', 'row': 5, 'column': 2}, {'task': 'Dependency Parsing', 'dataset': 'French GSD', 'metric': 'LAS', 'model': 'CamemBERT', 'value': '92.47', 'row': 5, 'column': 3}, {'task': 'Part-Of-Speech Tagging', 'dataset': 'Sequoia Treebank', 'metric': 'UPOS', 'model': 'CamemBERT', 'value': '99.21', 'row': 5, 'column': 4}, {'task': 'Dependency Parsing', 'dataset': 'Sequoia Treebank', 'metric': 'UAS', 'model': 'CamemBERT', 'value': '95.56', 'row': 5, 'column': 5}, {'task': 'Dependency Parsing', 'dataset': 'Sequoia Treebank', 'metric': 'LAS', 'model': 'CamemBERT', 'value': '94.39', 'row': 5, 'column': 6}, {'task': 'Part-Of-Speech Tagging', 'dataset': 'Spoken Corpus', 'metric': 'UPOS', 'model': 'CamemBERT', 'value': '96.68', 'row': 5, 'column': 7}, {'task': 'Dependency Parsing', 'dataset': 'Spoken Corpus', 'metric': 'UAS', 'model': 'CamemBERT', 'value': '86.05', 'row': 5, 'column': 8}, {'task': 'Dependency Parsing', 'dataset': 'Spoken Corpus', 'metric': 'LAS', 'model': 'CamemBERT', 'value': '80.07', 'row': 5, 'column': 9}, {'task': 'Part-Of-Speech Tagging', 'dataset': 'ParTUT', 'metric': 'UPOS', 'model': 'CamemBERT', 'value': '97.63', 'row': 5, 'column': 10}, {'task': 'Dependency Parsing', 'dataset': 'ParTUT', 'metric': 'UAS', 'model': 'CamemBERT', 'value': '95.21', 'row': 5, 'column': 11}, {'task': 'Dependency Parsing', 'dataset': 'ParTUT', 'metric': 'LAS', 'model': 'CamemBERT', 'value': '92.9', 'row': 5, 'column': 12}]}\n","{'index': 2, 'records': [{'task': 'Natural Language Inference', 'dataset': 'XNLI French', 'metric': 'Accuracy', 'model': 'CamemBERT', 'value': '81.2', 'row': 7, 'column': 1}]}\n","{'index': 3, 'records': [{'task': 'Named Entity Recognition', 'dataset': 'French Treebank', 'metric': 'Precision', 'model': 'CamemBERT (subword masking)', 'value': '88.35', 'row': 4, 'column': 1}, {'task': 'Named Entity Recognition', 'dataset': 'French Treebank', 'metric': 'Recall', 'model': 'CamemBERT (subword masking)', 'value': '87.46', 'row': 4, 'column': 2}, {'task': 'Named Entity Recognition', 'dataset': 'French Treebank', 'metric': 'F1', 'model': 'CamemBERT (subword masking)', 'value': '87.93', 'row': 4, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MRR', 'model': 'RESCAL + Decom', 'value': '0.457', 'row': 3, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 5 Accuracy', 'model': 'NoisyStudent (EfficientNet-L2)', 'value': '98.7', 'row': 22, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'SimpleShot (CL2N-DenseNet)', 'value': '64.29', 'row': 48, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'SimpleShot (CL2N-DenseNet)', 'value': '81.5', 'row': 48, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Traveling Salesman Problem', 'dataset': 'TSPLIB', 'metric': 'Optimality Gap', 'model': 'Graph Pointer Network', 'value': '9.35', 'row': 1, 'column': 2}, {'task': 'Traveling Salesman Problem', 'dataset': 'TSPLIB', 'metric': 'runtime (s)', 'model': 'Graph Pointer Network', 'value': '200', 'row': 2, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'HGP-SL', 'value': '68.79', 'row': 17, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'HGP-SL', 'value': '84.91', 'row': 17, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'HGP-SL', 'value': '80.96', 'row': 17, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'HGP-SL', 'value': '78.45', 'row': 17, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'HGP-SL', 'value': '80.67', 'row': 17, 'column': 6}, {'task': 'Graph Classification', 'dataset': 'Mutagenicity', 'metric': 'Accuracy', 'model': 'HGP-SL', 'value': '82.15', 'row': 17, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'AmdimNet', 'value': '76.82', 'row': 26, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'AmdimNet', 'value': '90.98', 'row': 26, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 1-shot', 'metric': 'Accuracy', 'model': 'AmdimNet', 'value': '77.09', 'row': 14, 'column': 2}, {'task': 'Few-Shot Image Classification', 'dataset': 'CUB 200 5-way 5-shot', 'metric': 'Accuracy', 'model': 'AmdimNet', 'value': '89.18', 'row': 14, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 't-SS3', 'value': '12.6', 'row': 1, 'column': 2}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 't-SS3', 'value': '7.7', 'row': 1, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE5', 'model': 'SS3', 'value': '12.6', 'row': 2, 'column': 2}, {'task': 'Depression Detection', 'dataset': 'eRisk 2017', 'metric': 'ERDE50', 'model': 'SS3', 'value': '8.12', 'row': 2, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE5', 'model': 't-SS3', 'value': '9.48', 'row': 5, 'column': 2}, {'task': 'Depression Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE50', 'model': 't-SS3', 'value': '6.17', 'row': 5, 'column': 3}, {'task': 'Depression Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE5', 'model': 'SS3', 'value': '9.54', 'row': 6, 'column': 2}, {'task': 'Depression Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE50', 'model': 'SS3', 'value': '6.35', 'row': 6, 'column': 3}, {'task': 'Anorexia Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE5', 'model': 't-SS3', 'value': '11.31', 'row': 9, 'column': 2}, {'task': 'Anorexia Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE50', 'model': 't-SS3', 'value': '6.26', 'row': 9, 'column': 3}, {'task': 'Anorexia Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE5', 'model': 'SS3', 'value': '11.56', 'row': 10, 'column': 2}, {'task': 'Anorexia Detection', 'dataset': 'eRisk 2018', 'metric': 'ERDE50', 'model': 'SS3', 'value': '6.69', 'row': 10, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'J-HMDB-21', 'metric': 'Frame-mAP', 'model': 'YOWO (16-frame)', 'value': '74.4', 'row': 9, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'J-HMDB-21', 'metric': 'Video-mAP 0.2', 'model': 'YOWO (16-frame)', 'value': '87.8', 'row': 9, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'J-HMDB-21', 'metric': 'Video-mAP 0.5', 'model': 'YOWO (16-frame)', 'value': '85.7', 'row': 9, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'J-HMDB-21', 'metric': 'Video-mAP 0.75', 'model': 'YOWO (16-frame)', 'value': '58.1', 'row': 9, 'column': 4}]}\n","{'index': 5, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'UCF101-24', 'metric': 'mAP', 'model': 'YOWO (16-frame)', 'value': '87.2', 'row': 9, 'column': 1}, {'task': 'Temporal Action Localization', 'dataset': 'UCF101-24', 'metric': 'mAP', 'model': 'YOWO (16-frame)', 'value': '82.5', 'row': 9, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'UCF101-24', 'metric': 'mAP', 'model': 'YOWO (16-frame)', 'value': '75.8', 'row': 9, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'UCF101-24', 'metric': 'mAP', 'model': 'YOWO (16-frame)', 'value': '48.8', 'row': 9, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'CenterMask + VoVNetV2-99 (single-scale)', 'value': '57.0', 'row': 1, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'Mask R-CNN (VoVNetV2-99, single-scale)', 'value': '48.1', 'row': 2, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'CenterMask+VoVNetV2-99 (single-scale)', 'value': '49.9', 'row': 3, 'column': 5}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'CenterMask+VoVNetV2-99 (single-scale)', 'value': '49.3', 'row': 3, 'column': 9}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'mask AP', 'model': 'CenterMask + VoVNetV2-99 (single-scale)', 'value': '40.6', 'row': 7, 'column': 6}, {'task': 'Panoptic Segmentation', 'dataset': 'COCO panoptic', 'metric': 'PQ', 'model': 'Panoptic-FPN-VoVNet57', 'value': '44.3', 'row': 8, 'column': 8}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'CenterMask + VoVNetV2-57 (single-scale)', 'value': '55.3', 'row': 9, 'column': 9}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'CenterMask + X-101-32x8d (single-scale)', 'value': '55.2', 'row': 10, 'column': 9}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'CenterMask + X101-32x8d (single-scale)', 'value': '55.2', 'row': 10, 'column': 9}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APL', 'model': 'CenterMask+VoVNetV2-57 (single-scale)', 'value': '57.3', 'row': 12, 'column': 9}]}\n","{'index': 4, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'CenterMask + X101-32x8d (single-scale)', 'value': '42.0', 'row': 2, 'column': 7}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Centermask + ResNet101', 'value': '46.1', 'row': 5, 'column': 9}, {'task': 'Real-Time Object Detection', 'dataset': 'COCO', 'metric': 'FPS', 'model': 'CenterMaskLite-MobileNetV2', 'value': '50.0', 'row': 7, 'column': 12}, {'task': 'Object Detection', 'dataset': 'COCO minival', 'metric': 'APM', 'model': 'CenterMask+X101-32x8d (single-scale)', 'value': '47.7', 'row': 10, 'column': 6}, {'task': 'Object Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'CenterMask+VoVNet2-57 (single-scale)', 'value': '47.1', 'row': 11, 'column': 6}]}\n","{'index': 0, 'records': [{'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'MRR', 'model': 'DualVD', 'value': '62.94', 'row': 12, 'column': 1}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@1', 'model': 'DualVD', 'value': '48.64', 'row': 12, 'column': 2}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@5', 'model': 'DualVD', 'value': '80.89', 'row': 12, 'column': 3}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'R@10', 'model': 'DualVD', 'value': '89.94', 'row': 12, 'column': 4}, {'task': 'Visual Dialog', 'dataset': 'VisDial v0.9 val', 'metric': 'Mean Rank', 'model': 'DualVD', 'value': '4.17', 'row': 12, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'MRR', 'model': 'DualVD', 'value': '63.23', 'row': 10, 'column': 1}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@1', 'model': 'DualVD', 'value': '49.25', 'row': 10, 'column': 2}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@5', 'model': 'DualVD', 'value': '80.23', 'row': 10, 'column': 3}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'R@10', 'model': 'DualVD', 'value': '89.7', 'row': 10, 'column': 4}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'Mean Rank', 'model': 'DualVD', 'value': '4.11', 'row': 10, 'column': 5}, {'task': 'Visual Dialog', 'dataset': 'VisDial v1.0 test-std', 'metric': 'NDCG', 'model': 'DualVD', 'value': '56.32', 'row': 10, 'column': 6}]}\n","{'index': 4, 'records': [{'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'DirectPose (ResNet-101)', 'value': '64.8', 'row': 18, 'column': 1}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'DirectPose (ResNet-101)', 'value': '87.8', 'row': 18, 'column': 2}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'DirectPose (ResNet-101)', 'value': '71.1', 'row': 18, 'column': 3}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'DirectPose (ResNet-101)', 'value': '60.4', 'row': 18, 'column': 4}, {'task': 'Keypoint Detection', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'DirectPose (ResNet-101)', 'value': '71.5', 'row': 18, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'HRNet + UDP (HRNet-W48)', 'value': '76.5', 'row': 26, 'column': 5}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'HRNet + UDP (HRNet-W48)', 'value': '92.7', 'row': 26, 'column': 6}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'HRNet + UDP (HRNet-W48)', 'value': '84', 'row': 26, 'column': 7}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'HRNet + UDP (HRNet-W48)', 'value': '73', 'row': 26, 'column': 8}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'HRNet + UDP (HRNet-W48)', 'value': '82.4', 'row': 26, 'column': 9}, {'task': 'Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'HRNet + UDP (HRNet-W48)', 'value': '81.6', 'row': 26, 'column': 10}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGBD', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'MaskedFusion', 'value': '96.9', 'row': 15, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'SCDV-MS', 'value': '86.19', 'row': 1, 'column': 1}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Precision', 'model': 'SCDV-MS', 'value': '86.2', 'row': 1, 'column': 2}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Recall', 'model': 'SCDV-MS', 'value': '86.18', 'row': 1, 'column': 3}, {'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'F-measure', 'model': 'SCDV-MS', 'value': '86.16', 'row': 1, 'column': 4}]}\n","{'index': 4, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'F1', 'model': 'SCDV-MS', 'value': '82.71', 'row': 6, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'ASAP', 'value': '76.87', 'row': 7, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'ASAP', 'value': '74.19', 'row': 7, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'ASAP', 'value': '71.48', 'row': 7, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI109', 'metric': 'Accuracy', 'model': 'ASAP', 'value': '70.07', 'row': 7, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'FRANKENSTEIN', 'metric': 'Accuracy', 'model': 'ASAP', 'value': '66.26', 'row': 7, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Caltech', 'metric': 'Average Accuracy', 'model': 'SPL', 'value': '93', 'row': 9, 'column': 13}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'SPL', 'value': '89.6', 'row': 11, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'SPL', 'value': '90.3', 'row': 7, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'SPL', 'value': '71', 'row': 7, 'column': 13}]}\n","{'index': 2, 'records': [{'task': 'Portrait Segmentation', 'dataset': 'EG1800', 'metric': 'F1-score', 'model': 'SINet+', 'value': '0.892', 'row': 12, 'column': 4}, {'task': 'Portrait Segmentation', 'dataset': 'EG1800', 'metric': 'mIoU', 'model': 'SINet+', 'value': '95.29', 'row': 12, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'SINet', 'value': '66.5', 'row': 6, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'MRR', 'model': 'HAKE', 'value': '0.49700000000000005', 'row': 8, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@1', 'model': 'HAKE', 'value': '0.452', 'row': 8, 'column': 2}, {'task': 'Knowledge Graph Completion', 'dataset': 'WN18RR', 'metric': 'Hits@3', 'model': 'HAKE', 'value': '0.516', 'row': 8, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'WN18RR', 'metric': 'Hits@10', 'model': 'HAKE', 'value': '0.5820000000000001', 'row': 8, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'MRR', 'model': 'HAKE', 'value': '0.34600000000000003', 'row': 8, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@1', 'model': 'HAKE', 'value': '0.25', 'row': 8, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'FB15k-237', 'metric': 'Hits@3', 'model': 'HAKE', 'value': '0.381', 'row': 8, 'column': 7}, {'task': 'Knowledge Graph Completion', 'dataset': 'FB15k-237', 'metric': 'Hits@10', 'model': 'HAKE', 'value': '0.542', 'row': 8, 'column': 8}, {'task': 'Link Prediction', 'dataset': 'YAGO3-10', 'metric': 'MRR', 'model': 'HAKE', 'value': '0.545', 'row': 8, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'YAGO3-10', 'metric': 'Hits@1', 'model': 'HAKE', 'value': '0.462', 'row': 8, 'column': 10}, {'task': 'Link Prediction', 'dataset': 'YAGO3-10', 'metric': 'Hits@3', 'model': 'HAKE', 'value': '0.596', 'row': 8, 'column': 11}, {'task': 'Link Prediction', 'dataset': 'YAGO3-10', 'metric': 'Hits@10', 'model': 'HAKE', 'value': '0.6940000000000001', 'row': 8, 'column': 12}]}\n","{'index': 1, 'records': [{'task': 'Audio Question Answering', 'dataset': 'DAQA', 'metric': 'Accuracy', 'model': 'MALiMo (6 Blocks)', 'value': '88.86', 'row': 32, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'BaS-Net', 'value': '58.2', 'row': 29, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.2', 'model': 'BaS-Net', 'value': '52.3', 'row': 29, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'BaS-Net', 'value': '44.6', 'row': 29, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.4', 'model': 'BaS-Net', 'value': '36', 'row': 29, 'column': 5}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'BaS-Net', 'value': '27', 'row': 29, 'column': 6}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.6', 'model': 'BaS-Net', 'value': '18.6', 'row': 29, 'column': 7}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': 'BaS-Net', 'value': '10.4', 'row': 29, 'column': 8}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.8', 'model': 'BaS-Net', 'value': '3.9', 'row': 29, 'column': 9}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.9', 'model': 'BaS-Net', 'value': '0.5', 'row': 29, 'column': 10}]}\n","{'index': 2, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.5', 'model': 'BaS-Net', 'value': '34.5', 'row': 15, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.75', 'model': 'BaS-Net', 'value': '22.5', 'row': 15, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP IOU@0.95', 'model': 'BaS-Net', 'value': '4.9', 'row': 15, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.3', 'metric': 'mAP', 'model': 'BaS-Net', 'value': '22.2', 'row': 15, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.5', 'model': 'BaS-Net', 'value': '38.5', 'row': 6, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.75', 'model': 'BaS-Net', 'value': '24.2', 'row': 6, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.95', 'model': 'BaS-Net', 'value': '5.6', 'row': 6, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP', 'model': 'BaS-Net', 'value': '24.3', 'row': 6, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AP', 'model': 'Identity Mapping Hourglass', 'value': '68.1', 'row': 11, 'column': 6}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'Identity Mapping Hourglass', 'value': '66.8', 'row': 11, 'column': 7}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'Identity Mapping Hourglass', 'value': '70.5', 'row': 11, 'column': 8}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR', 'model': 'Identity Mapping Hourglass', 'value': '72.1', 'row': 11, 'column': 9}, {'task': 'Multi-Person Pose Estimation', 'dataset': 'COCO test-dev', 'metric': 'AR50', 'model': 'Identity Mapping Hourglass', 'value': '88.2', 'row': 11, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '64.21', 'row': 18, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '87.75', 'row': 18, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '68.77', 'row': 18, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '86.75', 'row': 18, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR-FS 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '73.1', 'row': 9, 'column': 3}, {'task': 'Few-Shot Image Classification', 'dataset': 'CIFAR-FS 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '89.3', 'row': 9, 'column': 4}, {'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '41.6', 'row': 9, 'column': 5}, {'task': 'Few-Shot Image Classification', 'dataset': 'FC100 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'ACC + Amphibian', 'value': '66.9', 'row': 9, 'column': 6}]}\n","{'index': 1, 'records': [{'task': 'Facial Expression Translation', 'dataset': 'AR Face', 'metric': 'AMT', 'model': 'AttentionGAN', 'value': '12.8', 'row': 14, 'column': 2}, {'task': 'Facial Expression Translation', 'dataset': 'AR Face', 'metric': 'PSNR', 'model': 'AttentionGAN', 'value': '14.9187', 'row': 14, 'column': 3}, {'task': 'Facial Expression Translation', 'dataset': 'CelebA', 'metric': 'AMT', 'model': 'AttentionGAN', 'value': '38.9', 'row': 14, 'column': 4}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'DADA', 'value': '89', 'row': 14, 'column': 7}]}\n","{'index': 2, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'Syn2Real-C', 'metric': 'Accuracy', 'model': 'DADA', 'value': '79.8', 'row': 7, 'column': 13}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'MNIST-to-USPS', 'metric': 'Accuracy', 'model': 'CyCleGAN (Light-weight Calibrator)', 'value': '97.1', 'row': 10, 'column': 1}, {'task': 'Domain Adaptation', 'dataset': 'USPS-to-MNIST', 'metric': 'Accuracy', 'model': 'CyCleGAN (Light-weight Calibrator)', 'value': '98.3', 'row': 10, 'column': 2}, {'task': 'Domain Adaptation', 'dataset': 'SVHN-to-MNIST', 'metric': 'Accuracy', 'model': 'CyCleGAN (Light-weight Calibrator)', 'value': '97.5', 'row': 10, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Synthetic-to-Real Translation', 'dataset': 'GTAV-to-Cityscapes Labels', 'metric': 'mIoU', 'model': 'Light-weight Calibrator', 'value': '40.5', 'row': 3, 'column': 20}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'CAADA', 'value': '78.3', 'row': 13, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'CAADA', 'value': '48.19', 'row': 8, 'column': 13}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'CAADA', 'value': '80.2', 'row': 7, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Image Enhancement', 'dataset': 'MIT-Adobe 5k', 'metric': 'PSNR', 'model': 'DIFAR (MSCA, level 1)', 'value': '24.2', 'row': 1, 'column': 1}, {'task': 'Image Enhancement', 'dataset': 'MIT-Adobe 5k', 'metric': 'SSIM', 'model': 'DIFAR (MSCA, level 1)', 'value': '0.88', 'row': 1, 'column': 2}, {'task': 'Image Enhancement', 'dataset': 'MIT-Adobe 5k', 'metric': 'LPIPS', 'model': 'DIFAR (MSCA, level 1)', 'value': '0.108', 'row': 1, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Text Classification', 'dataset': '20NEWS', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '74.78', 'row': 1, 'column': 5}, {'task': 'Document Classification', 'dataset': 'Amazon', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '93.03', 'row': 2, 'column': 5}, {'task': 'Document Classification', 'dataset': 'BBCSport', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '95.18', 'row': 3, 'column': 5}, {'task': 'Document Classification', 'dataset': 'Classic', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '96.85', 'row': 4, 'column': 5}, {'task': 'Text Classification', 'dataset': 'Ohsumed', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '58.74', 'row': 5, 'column': 5}, {'task': 'Document Classification', 'dataset': 'Recipe', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '56.80', 'row': 6, 'column': 5}, {'task': 'Document Classification', 'dataset': 'Reuters-21578', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '95.61', 'row': 7, 'column': 5}, {'task': 'Document Classification', 'dataset': 'Twitter', 'metric': 'Accuracy', 'model': 'REL-RWMD k-NN', 'value': '71.05', 'row': 8, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AUC', 'model': 'GLACE', 'value': '98.6', 'row': 12, 'column': 1}, {'task': 'Link Prediction', 'dataset': 'Cora', 'metric': 'AP', 'model': 'GLACE', 'value': '98.52', 'row': 12, 'column': 2}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AUC', 'model': 'GLACE', 'value': '98.43', 'row': 12, 'column': 3}, {'task': 'Link Prediction', 'dataset': 'Citeseer', 'metric': 'AP', 'model': 'GLACE', 'value': '98.37', 'row': 12, 'column': 4}, {'task': 'Link Prediction', 'dataset': 'DBLP', 'metric': 'AUC', 'model': 'GLACE', 'value': '98.55', 'row': 12, 'column': 5}, {'task': 'Link Prediction', 'dataset': 'DBLP', 'metric': 'AP', 'model': 'GLACE', 'value': '98.4', 'row': 12, 'column': 6}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AUC', 'model': 'GLACE', 'value': '97.82', 'row': 12, 'column': 7}, {'task': 'Link Prediction', 'dataset': 'Pubmed', 'metric': 'AP', 'model': 'GLACE', 'value': '97.49', 'row': 12, 'column': 8}, {'task': 'Link Prediction', 'dataset': 'ACM', 'metric': 'AUC', 'model': 'GLACE', 'value': '98.34', 'row': 12, 'column': 9}, {'task': 'Link Prediction', 'dataset': 'ACM', 'metric': 'AP', 'model': 'GLACE', 'value': '98.24', 'row': 12, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'Viewpoint-Aware Loss', 'value': '95.43', 'row': 19, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'Viewpoint-Aware Loss', 'value': '96.79', 'row': 19, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-5', 'model': 'Viewpoint-Aware Loss', 'value': '98.31', 'row': 19, 'column': 4}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'Viewpoint-Aware Loss', 'value': '91.82', 'row': 19, 'column': 5}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'Viewpoint-Aware Loss', 'value': '93.85', 'row': 19, 'column': 6}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-5', 'model': 'Viewpoint-Aware Loss', 'value': '96.5', 'row': 19, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'mask AP', 'model': 'EmbedMask (ResNet-101-FPN)', 'value': '37.7', 'row': 10, 'column': 5}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'EmbedMask (ResNet-101-FPN)', 'value': '59.1', 'row': 10, 'column': 6}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'EmbedMask (ResNet-101-FPN)', 'value': '40.3', 'row': 10, 'column': 7}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'EmbedMask (ResNet-101-FPN)', 'value': '17.9', 'row': 10, 'column': 8}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'EmbedMask (ResNet-101-FPN)', 'value': '40.4', 'row': 10, 'column': 9}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'EmbedMask (ResNet-101-FPN)', 'value': '53', 'row': 10, 'column': 10}]}\n","{'index': 1, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MetaFun-Attention', 'value': '64.13', 'row': 23, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Mini-Imagenet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MetaFun-Attention', 'value': '80.82', 'row': 23, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (1-shot)', 'metric': 'Accuracy', 'model': 'MetaFun-Attention', 'value': '67.72', 'row': 11, 'column': 1}, {'task': 'Few-Shot Image Classification', 'dataset': 'Tiered ImageNet 5-way (5-shot)', 'metric': 'Accuracy', 'model': 'MetaFun-Kernel', 'value': '83.28', 'row': 12, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Multi-Modal Document Classification', 'dataset': 'RVL-CDIP', 'metric': 'Accuracy', 'model': 'VGG16 + BoW-300K', 'value': '93.03', 'row': 16, 'column': 3}]}\n","{'index': 0, 'records': [{'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'mask AP', 'model': 'SOLO (ResNet-DCN-101-FPN)', 'value': '40.4%', 'row': 16, 'column': 2}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP50', 'model': 'SOLO (ResNet-DCN-101-FPN)', 'value': '62.7%', 'row': 16, 'column': 3}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'AP75', 'model': 'SOLO (ResNet-DCN-101-FPN)', 'value': '43.3%', 'row': 16, 'column': 4}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APS', 'model': 'SOLO (ResNet-DCN-101-FPN)', 'value': '17.6%', 'row': 16, 'column': 5}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APM', 'model': 'SOLO (ResNet-DCN-101-FPN)', 'value': '43.3%', 'row': 16, 'column': 6}, {'task': 'Instance Segmentation', 'dataset': 'COCO test-dev', 'metric': 'APL', 'model': 'SOLO (ResNet-DCN-101-FPN)', 'value': '58.9%', 'row': 16, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Medical Image Segmentation', 'dataset': 'EM', 'metric': 'IoU', 'model': 'UNet++', 'value': '89.33', 'row': 9, 'column': 3}, {'task': 'Medical Image Segmentation', 'dataset': 'Cell', 'metric': 'IoU', 'model': 'UNet++', 'value': '91.21', 'row': 9, 'column': 4}, {'task': 'Brain Image Segmentation', 'dataset': 'Brain Tumor', 'metric': 'IoU', 'model': 'UNet++', 'value': '91.21', 'row': 9, 'column': 5}]}\n","{'index': 5, 'records': [{'task': 'Gesture-to-Gesture Translation', 'dataset': 'NTU Hand Digit', 'metric': 'PSNR', 'model': 'UniGAN', 'value': '32.6574', 'row': 7, 'column': 1}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'NTU Hand Digit', 'metric': 'IS', 'model': 'UniGAN', 'value': '2.3783', 'row': 7, 'column': 2}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'NTU Hand Digit', 'metric': 'AMT', 'model': 'UniGAN', 'value': '29.3', 'row': 7, 'column': 3}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'NTU Hand Digit', 'metric': 'FID', 'model': 'UniGAN', 'value': '6.7493', 'row': 7, 'column': 4}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'NTU Hand Digit', 'metric': 'FRD', 'model': 'UniGAN', 'value': '1.7401', 'row': 7, 'column': 5}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'Senz3D', 'metric': 'PSNR', 'model': 'UniGAN', 'value': '31.541999999999998', 'row': 7, 'column': 6}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'Senz3D', 'metric': 'IS', 'model': 'UniGAN', 'value': '2.2159', 'row': 7, 'column': 7}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'Senz3D', 'metric': 'AMT', 'model': 'UniGAN', 'value': '27.6', 'row': 7, 'column': 8}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'Senz3D', 'metric': 'FID', 'model': 'UniGAN', 'value': '12.4465', 'row': 7, 'column': 9}, {'task': 'Gesture-to-Gesture Translation', 'dataset': 'Senz3D', 'metric': 'FRD', 'model': 'UniGAN', 'value': '2.2104', 'row': 7, 'column': 10}]}\n","{'index': 6, 'records': [{'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'SSIM', 'model': 'UniGAN', 'value': '0.5064', 'row': 11, 'column': 9}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'PSNR', 'model': 'UniGAN', 'value': '23.3632', 'row': 11, 'column': 10}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'SD', 'model': 'UniGAN', 'value': '16.4788', 'row': 11, 'column': 11}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'KL', 'model': 'UniGAN', 'value': '2.16', 'row': 11, 'column': 12}]}\n","{'index': 7, 'records': [{'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'SSIM', 'model': 'UniGAN', 'value': '0.3357', 'row': 11, 'column': 9}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'PSNR', 'model': 'UniGAN', 'value': '22.0273', 'row': 11, 'column': 10}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'SD', 'model': 'UniGAN', 'value': '17.6542', 'row': 11, 'column': 11}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'KL', 'model': 'UniGAN', 'value': '5.17', 'row': 11, 'column': 12}]}\n","{'index': 8, 'records': [{'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'SSIM', 'model': 'UniGAN', 'value': '0.5366', 'row': 7, 'column': 8}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'PSNR', 'model': 'UniGAN', 'value': '22.8223', 'row': 7, 'column': 9}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'SD', 'model': 'UniGAN', 'value': '19.8276', 'row': 7, 'column': 10}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'KL', 'model': 'UniGAN', 'value': '2.6', 'row': 7, 'column': 11}]}\n","{'index': 9, 'records': [{'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'LPIPS', 'model': 'UniGAN', 'value': '0.1712', 'row': 2, 'column': 2}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'LPIPS', 'model': 'UniGAN', 'value': '0.3529', 'row': 2, 'column': 3}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64×64) - aerial-to-ground', 'metric': 'LPIPS', 'model': 'UniGAN', 'value': '0.3817', 'row': 2, 'column': 4}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64x64) - ground-to-aerial', 'metric': 'LPIPS', 'model': 'UniGAN', 'value': '0.2382', 'row': 4, 'column': 2}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (64x64) - ground-to-aerial', 'metric': 'LPIPS', 'model': 'UniGAN', 'value': '0.4527', 'row': 4, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Image Retrieval', 'dataset': 'SOP', 'metric': 'R@1', 'model': 'Cross-Batch Memory', 'value': '80.6', 'row': 16, 'column': 2}]}\n","{'index': 3, 'records': [{'task': 'Image Retrieval', 'dataset': 'In-Shop', 'metric': 'R@1', 'model': 'Cross-Batch Memory', 'value': '91.3', 'row': 11, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'Kinetics-Skeleton dataset', 'metric': 'Accuracy', 'model': 'MS-AAGCN', 'value': '37.8', 'row': 10, 'column': 1}]}\n","{'index': 6, 'records': [{'task': 'Skeleton Based Action Recognition', 'dataset': 'NTU RGB+D', 'metric': 'Accuracy (CS)', 'model': 'RNX3D101+MS-AAGCN-C', 'value': '96.1', 'row': 11, 'column': 3}, {'task': 'Skeleton Based Action Recognition', 'dataset': 'NTU RGB+D', 'metric': 'Accuracy (CV)', 'model': 'RNX3D101+MS-AAGCN-C', 'value': '99', 'row': 11, 'column': 4}]}\n","{'index': 6, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes val', 'metric': 'mIoU', 'model': 'SemanticFPN P2-P5 + PointRend', 'value': '78.6', 'row': 2, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Text-to-Image Generation', 'dataset': 'COCO', 'metric': 'Inception score', 'model': 'CPGAN', 'value': '52.73', 'row': 11, 'column': 1}]}\n","{'index': 2, 'records': [{'task': 'Node Classification', 'dataset': 'BlogCatalog', 'metric': 'Micro F1', 'model': 'DAOR', 'value': '33.05', 'row': 15, 'column': 1}, {'task': 'Node Classification', 'dataset': 'PPI', 'metric': 'Micro F1', 'model': 'DAOR', 'value': '19.07', 'row': 15, 'column': 2}, {'task': 'Node Classification', 'dataset': 'Wiki', 'metric': 'Micro F1', 'model': 'DAOR', 'value': '53.24', 'row': 15, 'column': 3}, {'task': 'Node Classification', 'dataset': 'DBLP', 'metric': 'Micro F1', 'model': 'DAOR', 'value': '87.86', 'row': 15, 'column': 4}, {'task': 'Node Classification', 'dataset': 'BlogCatalog', 'metric': 'Macro F1', 'model': 'DAOR', 'value': '17.25', 'row': 15, 'column': 5}, {'task': 'Node Classification', 'dataset': 'PPI', 'metric': 'Macro F1', 'model': 'DAOR', 'value': '13.94', 'row': 15, 'column': 6}, {'task': 'Node Classification', 'dataset': 'Wiki', 'metric': 'Macro F1', 'model': 'DAOR', 'value': '15.97', 'row': 15, 'column': 7}, {'task': 'Node Classification', 'dataset': 'DBLP', 'metric': 'Macro F1', 'model': 'DAOR', 'value': '87.64', 'row': 15, 'column': 8}]}\n","{'index': 9, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Recall', 'model': 'SBD', 'value': '88.2', 'row': 34, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'Precision', 'model': 'SBD', 'value': '92.1', 'row': 34, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2015', 'metric': 'F-Measure', 'model': 'SBD', 'value': '90.1', 'row': 34, 'column': 3}]}\n","{'index': 10, 'records': [{'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Recall', 'model': 'SBD', 'value': '76.44', 'row': 12, 'column': 1}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'Precision', 'model': 'SBD', 'value': '82.75', 'row': 12, 'column': 2}, {'task': 'Scene Text Detection', 'dataset': 'ICDAR 2017 MLT', 'metric': 'F-Measure', 'model': 'SBD', 'value': '79.47', 'row': 12, 'column': 3}]}\n","{'index': 0, 'records': [{'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mCov', 'model': 'JSNet', 'value': '54.1', 'row': 9, 'column': 2}, {'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mWCov', 'model': 'JSNet', 'value': '58', 'row': 9, 'column': 3}, {'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mRec', 'model': 'JSNet', 'value': '53.9', 'row': 9, 'column': 4}, {'task': '3D Instance Segmentation', 'dataset': 'S3DIS', 'metric': 'mPrec', 'model': 'JSNet', 'value': '66.9', 'row': 9, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'S3DIS', 'metric': 'mAcc', 'model': 'JSNet', 'value': '71.7', 'row': 12, 'column': 2}, {'task': 'Semantic Segmentation', 'dataset': 'S3DIS', 'metric': 'oAcc', 'model': 'JSNet', 'value': '88.7', 'row': 12, 'column': 3}, {'task': 'Semantic Segmentation', 'dataset': 'S3DIS', 'metric': 'Mean IoU', 'model': 'JSNet', 'value': '61.7', 'row': 12, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'ShapeNet', 'metric': 'Mean IoU', 'model': 'JSNet', 'value': '85.8', 'row': 4, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Graph Classification', 'dataset': 'D&D', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '76.6', 'row': 2, 'column': 1}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'DGCNN', 'value': '76.4', 'row': 2, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'DiffPool', 'value': '73.7', 'row': 3, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'NCI1', 'metric': 'Accuracy', 'model': 'GIN', 'value': '80', 'row': 5, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'GIN', 'value': '59.6', 'row': 5, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'PROTEINS', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '73', 'row': 6, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'ENZYMES', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '58.2', 'row': 6, 'column': 4}]}\n","{'index': 2, 'records': [{'task': 'Graph Classification', 'dataset': 'IMDb-B', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '68.8', 'row': 12, 'column': 2}, {'task': 'Graph Classification', 'dataset': 'IMDb-M', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '47.6', 'row': 12, 'column': 3}, {'task': 'Graph Classification', 'dataset': 'REDDIT-B', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '84.3', 'row': 12, 'column': 4}, {'task': 'Graph Classification', 'dataset': 'REDDIT-MULTI-5k', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '50', 'row': 12, 'column': 5}, {'task': 'Graph Classification', 'dataset': 'COLLAB', 'metric': 'Accuracy', 'model': 'GraphSAGE', 'value': '73.9', 'row': 12, 'column': 6}]}\n","{'index': 3, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'Cityscapes val', 'metric': 'mIoU', 'model': 'FasterSeg', 'value': '73.1', 'row': 8, 'column': 1}, {'task': 'Semantic Segmentation', 'dataset': 'Cityscapes test', 'metric': 'Mean IoU (class)', 'model': 'FasterSeg', 'value': '71.5', 'row': 8, 'column': 2}]}\n","{'index': 5, 'records': [{'task': 'Semantic Segmentation', 'dataset': 'BDD', 'metric': 'mIoU', 'model': 'FasterSeg', 'value': '55.1', 'row': 3, 'column': 1}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGBD', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'W-PoseNet', 'value': '98.2', 'row': 15, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'SSIM', 'model': 'LGGAN', 'value': '0.5457', 'row': 10, 'column': 8}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'PSNR', 'model': 'LGGAN', 'value': '22.9949', 'row': 10, 'column': 9}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'SD', 'model': 'LGGAN', 'value': '19.6145', 'row': 10, 'column': 10}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'Dayton (256×256) - aerial-to-ground', 'metric': 'KL', 'model': 'LGGAN', 'value': '2.18', 'row': 10, 'column': 11}]}\n","{'index': 1, 'records': [{'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'SSIM', 'model': 'LGGAN', 'value': '0.5238', 'row': 11, 'column': 8}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'PSNR', 'model': 'LGGAN', 'value': '22.5766', 'row': 11, 'column': 9}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'SD', 'model': 'LGGAN', 'value': '19.744', 'row': 11, 'column': 10}, {'task': 'Cross-View Image-to-Image Translation', 'dataset': 'cvusa', 'metric': 'KL', 'model': 'LGGAN', 'value': '2.55', 'row': 11, 'column': 11}]}\n","{'index': 0, 'records': [{'task': '3D Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '90.25', 'row': 15, 'column': 3}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '81.43', 'row': 15, 'column': 4}, {'task': '3D Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '76.82', 'row': 15, 'column': 5}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Easy', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '94.98', 'row': 15, 'column': 6}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Moderate', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '90.65', 'row': 15, 'column': 7}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cars Hard', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '86.14', 'row': 15, 'column': 8}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '78.60', 'row': 15, 'column': 9}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '63.71', 'row': 15, 'column': 10}, {'task': '3D Object Detection', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '57.65', 'row': 15, 'column': 11}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclists Easy', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '82.49', 'row': 15, 'column': 12}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclists Moderate', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '68.89', 'row': 15, 'column': 13}, {'task': 'Birds Eye View Object Detection', 'dataset': 'KITTI Cyclists Hard', 'metric': 'AP', 'model': 'PV-RCNN', 'value': '62.41', 'row': 15, 'column': 14}]}\n","{'index': 0, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'DADA', 'value': '88', 'row': 12, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'DADA', 'value': '89.3', 'row': 8, 'column': 7}]}\n","{'index': 9, 'records': [{'task': 'Panoptic Segmentation', 'dataset': 'COCO panoptic', 'metric': 'PQ', 'model': 'Panoptic-FPN-VoVNet57', 'value': '44.3', 'row': 4, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Semantic Contour Prediction', 'dataset': 'Sbd val', 'metric': 'APvol', 'model': 'Deep snake', 'value': '54.4', 'row': 4, 'column': 1}, {'task': 'Semantic Contour Prediction', 'dataset': 'Sbd val', 'metric': 'AP50', 'model': 'Deep snake', 'value': '62.1', 'row': 4, 'column': 2}, {'task': 'Semantic Contour Prediction', 'dataset': 'Sbd val', 'metric': 'AP70', 'model': 'Deep snake', 'value': '48.3', 'row': 4, 'column': 3}]}\n","{'index': 4, 'records': [{'task': 'Grayscale Video Denoising', 'dataset': 'Derf’s Test Media 960×540', 'metric': 'PSNR', 'model': 'VBM3D ST+OF+MS', 'value': '38.95', 'row': 7, 'column': 9}, {'task': 'Grayscale Video Denoising', 'dataset': 'Derf’s Test Media 960×540', 'metric': 'PSNR', 'model': 'VBM3D ST+OF+MS', 'value': '35.67', 'row': 14, 'column': 9}, {'task': 'Grayscale Video Denoising', 'dataset': 'Derf’s Test Media 960×540', 'metric': 'PSNR', 'model': 'VBM3D ST+OF+MS', 'value': '32.44', 'row': 21, 'column': 9}]}\n","{'index': 0, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'LineMOD', 'metric': 'Mean ADD', 'model': 'HybridPose', 'value': '94.5', 'row': 14, 'column': 7}]}\n","{'index': 1, 'records': [{'task': '6D Pose Estimation using RGB', 'dataset': 'Occlusion LineMOD', 'metric': 'Mean ADD', 'model': 'HybridPose', 'value': '79.2', 'row': 9, 'column': 7}]}\n","{'index': 0, 'records': [{'task': 'Video Super-Resolution', 'dataset': 'Vid4 - 4x upscaling', 'metric': 'PSNR', 'model': 'SOF-VSR', 'value': '26', 'row': 8, 'column': 1}, {'task': 'Video Super-Resolution', 'dataset': 'Vid4 - 4x upscaling', 'metric': 'SSIM', 'model': 'SOF-VSR', 'value': '0.772', 'row': 8, 'column': 2}]}\n","{'index': 4, 'records': [{'task': 'Action Detection', 'dataset': 'UCF101-24', 'metric': 'Video-mAP 0.2', 'model': 'MOC', 'value': '81.8', 'row': 13, 'column': 7}, {'task': 'Action Detection', 'dataset': 'UCF101-24', 'metric': 'Video-mAP 0.5', 'model': 'Ours (MOC)', 'value': '53.9', 'row': 13, 'column': 8}, {'task': 'Action Detection', 'dataset': 'UCF101-24', 'metric': 'Video-mAP 0.75', 'model': 'Ours (MOC)', 'value': '28.5', 'row': 13, 'column': 9}, {'task': 'Action Detection', 'dataset': 'UCF101-24', 'metric': 'mAP', 'model': 'Ours (MOC)', 'value': '27.7', 'row': 13, 'column': 10}]}\n","{'index': 0, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'Con-Text', 'metric': 'mAP', 'model': 'PHOC descriptor + Fisher Vector Encoding', 'value': '80.2', 'row': 5, 'column': 1}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Bottles', 'metric': 'mAP', 'model': 'PHOC descriptor + Fisher Vector Encoding', 'value': '77.4', 'row': 5, 'column': 2}]}\n","{'index': 0, 'records': [{'task': 'Image Classification', 'dataset': 'ImageNet', 'metric': 'Top 1 Accuracy', 'model': 'Assemble-ResNet152', 'value': '84.2', 'row': 6, 'column': 1}]}\n","{'index': 7, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'Food-101', 'metric': 'Top 1 Accuracy', 'model': 'Assemble-ResNet-FGVC-50', 'value': '92.47', 'row': 14, 'column': 4}]}\n","{'index': 8, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'Stanford Cars', 'metric': 'Accuracy', 'model': 'Assemble-ResNet-FGVC-50', 'value': '94.4', 'row': 2, 'column': 4}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Oxford 102 Flowers', 'metric': 'Accuracy', 'model': 'Assemble-ResNet-FGVC-50', 'value': '98.9', 'row': 3, 'column': 4}, {'task': 'Fine-Grained Image Classification', 'dataset': 'FGVC Aircraft', 'metric': 'Accuracy', 'model': 'Assemble-ResNet-FGVC-50', 'value': '92.4', 'row': 4, 'column': 4}, {'task': 'Fine-Grained Image Classification', 'dataset': 'Oxford-IIIT Pets', 'metric': 'Accuracy', 'model': 'Assemble-ResNet-FGVC-50', 'value': '94.3', 'row': 5, 'column': 4}]}\n","{'index': 9, 'records': [{'task': 'Fine-Grained Image Classification', 'dataset': 'SOP', 'metric': 'Recall@1', 'model': 'Assemble-ResNet-FGVC-50', 'value': '85.9', 'row': 9, 'column': 3}]}\n","{'index': 2, 'records': [{'task': 'Video Object Segmentation', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Mean)', 'model': 'COSNet', 'value': '80.5', 'row': 2, 'column': 15}, {'task': 'Video Object Segmentation', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Recall)', 'model': 'COSNet', 'value': '94', 'row': 3, 'column': 15}, {'task': 'Video Object Segmentation', 'dataset': 'DAVIS 2016', 'metric': 'Jaccard (Decay)', 'model': 'COSNet', 'value': '0', 'row': 4, 'column': 15}, {'task': 'Video Object Segmentation', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Mean)', 'model': 'COSNet', 'value': '79.4', 'row': 5, 'column': 15}, {'task': 'Video Object Segmentation', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Recall)', 'model': 'COSNet', 'value': '90.4', 'row': 6, 'column': 15}, {'task': 'Video Object Segmentation', 'dataset': 'DAVIS 2016', 'metric': 'F-measure (Mean)', 'model': 'COSNet', 'value': '0', 'row': 7, 'column': 15}]}\n","{'index': 3, 'records': [{'task': 'Video Object Segmentation', 'dataset': 'FBMS', 'metric': 'Jaccard (Mean)', 'model': 'COSNet', 'value': '75.6', 'row': 3, 'column': 5}]}\n","{'index': 4, 'records': [{'task': 'Video Object Segmentation', 'dataset': 'YouTube', 'metric': 'mIoU', 'model': 'COSNet', 'value': '70.5', 'row': 12, 'column': 8}]}\n","{'index': 0, 'records': [{'task': 'Low-Light Image Enhancement', 'dataset': 'NPE', 'metric': 'User Study Score', 'model': 'Zero-DCE', 'value': '3.81', 'row': 7, 'column': 1}, {'task': 'Low-Light Image Enhancement', 'dataset': 'LIME', 'metric': 'User Study Score', 'model': 'Zero-DCE', 'value': '3.8', 'row': 7, 'column': 2}, {'task': 'Low-Light Image Enhancement', 'dataset': 'MEF', 'metric': 'User Study Score', 'model': 'Zero-DCE', 'value': '4.13', 'row': 7, 'column': 3}, {'task': 'Low-Light Image Enhancement', 'dataset': 'DICM', 'metric': 'User Study Score', 'model': 'Zero-DCE', 'value': '3.52', 'row': 7, 'column': 4}, {'task': 'Low-Light Image Enhancement', 'dataset': 'VV', 'metric': 'User Study Score', 'model': 'Zero-DCE', 'value': '3.24', 'row': 7, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'MAP', 'model': 'PLR-OSNet', 'value': '88.9', 'row': 21, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'Market-1501', 'metric': 'Rank-1', 'model': 'PLR-OSNet', 'value': '95.6', 'row': 21, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'MAP', 'model': 'PLR-OSNet', 'value': '81.2', 'row': 18, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'DukeMTMC-reID', 'metric': 'Rank-1', 'model': 'PLR-OSNet', 'value': '91.6', 'row': 18, 'column': 2}]}\n","{'index': 2, 'records': [{'task': 'Person Re-Identification', 'dataset': 'CUHK03 labeled', 'metric': 'MAP', 'model': 'PLR-OSNet', 'value': '80.5', 'row': 14, 'column': 1}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03 labeled', 'metric': 'Rank-1', 'model': 'PLR-OSNet', 'value': '84.6', 'row': 14, 'column': 2}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03 detected', 'metric': 'MAP', 'model': 'PLR-OSNet', 'value': '77.2', 'row': 14, 'column': 3}, {'task': 'Person Re-Identification', 'dataset': 'CUHK03 detected', 'metric': 'Rank-1', 'model': 'PLR-OSNet', 'value': '80.4', 'row': 14, 'column': 4}]}\n","{'index': 0, 'records': [{'task': 'Left Ventricle Segmentation', 'dataset': 'SUN09', 'metric': 'Endocardium Dice', 'model': 'SAUNet', 'value': '0.952', 'row': 6, 'column': 1}, {'task': 'Left Ventricle Segmentation', 'dataset': 'SUN09', 'metric': 'Epicardium Dice', 'model': 'SAUNet', 'value': '0.962', 'row': 6, 'column': 2}]}\n","{'index': 1, 'records': [{'task': 'Left Ventricle Segmentation', 'dataset': 'AC17', 'metric': 'Dice Score', 'model': 'SAUNet', 'value': '0.938', 'row': 6, 'column': 1}, {'task': 'Right Ventricle Segmentation', 'dataset': 'AC17', 'metric': 'Dice Score', 'model': 'SAUNet', 'value': '0.914', 'row': 6, 'column': 2}, {'task': 'Myocardium Segmentation', 'dataset': 'AC17', 'metric': 'Dice Score', 'model': 'SAUNet', 'value': '0.887', 'row': 6, 'column': 3}]}\n","{'index': 1, 'records': [{'task': 'Semi-Supervised Image Classification', 'dataset': 'CIFAR-100, 400 Labels', 'metric': 'Percentage error', 'model': 'FixMatch (CTA)', 'value': '49.95', 'row': 9, 'column': 4}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 40 Labels', 'metric': 'Percentage error', 'model': 'FixMatch (CTA)', 'value': '7.65', 'row': 9, 'column': 7}, {'task': 'Semi-Supervised Image Classification', 'dataset': 'SVHN, 1000 labels', 'metric': 'Accuracy', 'model': 'FixMatch (CTA)', 'value': '97.64', 'row': 9, 'column': 9}]}\n","{'index': 0, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.1', 'model': 'DeepMetricLearner', 'value': '62.3', 'row': 15, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.3', 'model': 'DeepMetricLearner', 'value': '46.8', 'row': 15, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.5', 'model': 'DeepMetricLearner', 'value': '29.6', 'row': 15, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'THUMOS’14', 'metric': 'mAP IOU@0.7', 'model': 'DeepMetricLearner', 'value': '9.7', 'row': 15, 'column': 5}]}\n","{'index': 1, 'records': [{'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.1', 'model': 'DeepMetricLearner', 'value': '60.5', 'row': 7, 'column': 2}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.3', 'model': 'DeepMetricLearner', 'value': '48.4', 'row': 7, 'column': 3}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.5', 'model': 'DeepMetricLearner', 'value': '35.2', 'row': 7, 'column': 4}, {'task': 'Temporal Action Localization', 'dataset': 'ActivityNet-1.2', 'metric': 'mAP IOU@0.7', 'model': 'DeepMetricLearner', 'value': '16.3', 'row': 7, 'column': 5}]}\n","{'index': 3, 'records': [{'task': 'Node Clustering', 'dataset': 'IMDb', 'metric': 'NMI', 'model': 'MAGNN', 'value': '0.1558', 'row': 2, 'column': 10}, {'task': 'Node Clustering', 'dataset': 'IMDb', 'metric': 'ARI', 'model': 'MAGNN', 'value': '16.74', 'row': 3, 'column': 10}, {'task': 'Node Clustering', 'dataset': 'DBLP', 'metric': 'NMI', 'model': 'MAGNN', 'value': '0.8081', 'row': 4, 'column': 10}, {'task': 'Node Clustering', 'dataset': 'DBLP', 'metric': 'ARI', 'model': 'MAGNN', 'value': '85.54', 'row': 5, 'column': 10}]}\n","{'index': 4, 'records': [{'task': 'Link Prediction', 'dataset': 'Last.FM', 'metric': 'AUC', 'model': 'MAGNN', 'value': '98.91', 'row': 1, 'column': 11}, {'task': 'Link Prediction', 'dataset': 'Last.FM', 'metric': 'AP', 'model': 'MAGNN', 'value': '98.93', 'row': 2, 'column': 11}]}\n","{'index': 2, 'records': [{'task': 'Domain Adaptation', 'dataset': 'ImageCLEF-DA', 'metric': 'Accuracy', 'model': 'MEDM', 'value': '88.9', 'row': 6, 'column': 7}]}\n","{'index': 3, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-Home', 'metric': 'Accuracy', 'model': 'MEDM', 'value': '69.5', 'row': 7, 'column': 13}]}\n","{'index': 4, 'records': [{'task': 'Domain Adaptation', 'dataset': 'Office-31', 'metric': 'Average Accuracy', 'model': 'MEDM', 'value': '89.2', 'row': 8, 'column': 7}]}\n","{'index': 1, 'records': [{'task': 'Node Classification', 'dataset': 'Cora', 'metric': 'Accuracy', 'model': 'GCN-LPA', 'value': '88.5', 'row': 8, 'column': 1}, {'task': 'Node Classification', 'dataset': 'Citeseer', 'metric': 'Accuracy', 'model': 'GCN-LPA', 'value': '78.7', 'row': 8, 'column': 2}, {'task': 'Node Classification', 'dataset': 'Pubmed', 'metric': 'Accuracy', 'model': 'GCN-LPA', 'value': '87.8', 'row': 8, 'column': 3}, {'task': 'Node Classification', 'dataset': 'Coauthor CS', 'metric': 'Accuracy', 'model': 'GCN-LPA', 'value': '94.8', 'row': 8, 'column': 4}, {'task': 'Node Classification', 'dataset': 'Coauthor Phy', 'metric': 'Accuracy', 'model': 'GCN-LPA', 'value': '96.9', 'row': 8, 'column': 5}]}\n","{'index': 0, 'records': [{'task': 'Music Source Separation', 'dataset': 'MUSDB18', 'metric': 'SDR (drums)', 'model': 'Meta-TasNet', 'value': '5.91', 'row': 1, 'column': 1}]}\n","{'index': 1, 'records': [{'task': 'Music Source Separation', 'dataset': 'MUSDB18', 'metric': 'SDR (bass)', 'model': 'Meta-TasNet', 'value': '5.58', 'row': 6, 'column': 5}, {'task': 'Music Source Separation', 'dataset': 'MUSDB18', 'metric': 'SDR (vocals)', 'model': 'Meta-TasNet', 'value': '6.4', 'row': 7, 'column': 1}, {'task': 'Music Source Separation', 'dataset': 'MUSDB18', 'metric': 'SDR (other)', 'model': 'Meta-TasNet', 'value': '4.19', 'row': 7, 'column': 4}]}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnbewPdphmhx","executionInfo":{"status":"ok","timestamp":1636743671059,"user_tz":300,"elapsed":148,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"f2c20b89-1cee-42ee-9c90-e299f1587a5c"},"source":["a"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1278"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":665},"id":"TDuXxlj4e8hQ","executionInfo":{"status":"ok","timestamp":1636750905156,"user_tz":300,"elapsed":194,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"ee13acfb-822d-4c69-abf1-6ae38ab5c479"},"source":["pd.set_option('display.max_colwidth', 100)\n","pwc_leaderboards.head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>tables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1207.4708v2</td>\n","      <td>[{'index': 5, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1208.5092v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'm...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1312.5602v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1312.6173v4</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1404.4641v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1406.2199v2</td>\n","      <td>[{'index': 4, 'records': [{'task': 'Action Classification', 'dataset': 'HMDB51', 'metric': 'Accu...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1410.2455v3</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters En-De', 'metri...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1411.0589v3</td>\n","      <td>[{'index': 2, 'records': [{'task': 'Microarray Classification', 'dataset': 'ArrayCGH', 'metric':...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1412.6334v4</td>\n","      <td>[{'index': 1, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1502.00873v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1506.01911v3</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Gesture Recognition', 'dataset': 'Montalbano', 'metric': 'Ja...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1507.02159v1</td>\n","      <td>[{'index': 2, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric'...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1509.06461v3</td>\n","      <td>[{'index': 4, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1510.04935v2</td>\n","      <td>[{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@1', 'mo...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1511.02799v4</td>\n","      <td>[{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-dev', 'm...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1511.05952v4</td>\n","      <td>[{'index': 6, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Scor...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1511.06581v3</td>\n","      <td>[{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1512.01693v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'S...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1512.02325v5</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': '...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1512.04860v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        arxiv_id                                                                                               tables\n","0    1207.4708v2  [{'index': 5, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...\n","1    1208.5092v1  [{'index': 0, 'records': [{'task': 'Image Clustering', 'dataset': 'Coil-20', 'metric': 'NMI', 'm...\n","2    1312.5602v1  [{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Beam Rider', 'metric': ...\n","3    1312.6173v4  [{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters ...\n","4    1404.4641v1  [{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters ...\n","5    1406.2199v2  [{'index': 4, 'records': [{'task': 'Action Classification', 'dataset': 'HMDB51', 'metric': 'Accu...\n","6    1410.2455v3  [{'index': 0, 'records': [{'task': 'Document Classification', 'dataset': 'Reuters En-De', 'metri...\n","7    1411.0589v3  [{'index': 2, 'records': [{'task': 'Microarray Classification', 'dataset': 'ArrayCGH', 'metric':...\n","8    1412.6334v4  [{'index': 1, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters ...\n","9   1502.00873v1  [{'index': 0, 'records': [{'task': 'Face Verification', 'dataset': 'Labeled Faces in the Wild', ...\n","10  1506.01911v3  [{'index': 0, 'records': [{'task': 'Gesture Recognition', 'dataset': 'Montalbano', 'metric': 'Ja...\n","11  1507.02159v1  [{'index': 2, 'records': [{'task': 'Action Recognition In Videos', 'dataset': 'UCF101', 'metric'...\n","12  1509.06461v3  [{'index': 4, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...\n","13  1510.04935v2  [{'index': 2, 'records': [{'task': 'Link Prediction', 'dataset': 'WN18', 'metric': 'Hits@1', 'mo...\n","14  1511.02799v4  [{'index': 2, 'records': [{'task': 'Visual Question Answering', 'dataset': 'VQA v1 test-dev', 'm...\n","15  1511.05952v4  [{'index': 6, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Alien', 'metric': 'Scor...\n","16  1511.06581v3  [{'index': 1, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc...\n","17  1512.01693v1  [{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Breakout', 'metric': 'S...\n","18  1512.02325v5  [{'index': 0, 'records': [{'task': 'Object Detection', 'dataset': 'PASCAL VOC 2007', 'metric': '...\n","19  1512.04860v1  [{'index': 0, 'records': [{'task': 'Atari Games', 'dataset': 'Atari 2600 Asterix', 'metric': 'Sc..."]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"id":"CMARKYzPmDe-","executionInfo":{"status":"ok","timestamp":1636751102575,"user_tz":300,"elapsed":161,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"e927dc60-66ac-4fb3-9521-f383d3fcc369"},"source":["pd.set_option('display.max_colwidth', None)\n","segmented_tables_annotations.loc[segmented_tables_annotations.arxiv_id == '1404.4641v1']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>fold</th>\n","      <th>sha256</th>\n","      <th>tables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [arxiv_id, fold, sha256, tables]\n","Index: []"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"ZGHlgwNBnO25","executionInfo":{"status":"ok","timestamp":1636750940598,"user_tz":300,"elapsed":187,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"8400f910-2c3a-4b24-eb16-909b496081e1"},"source":["arxiv_papers.loc[arxiv_papers.arxiv_id == '1404.4641v1']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>archive_size</th>\n","      <th>sha256</th>\n","      <th>title</th>\n","      <th>sections</th>\n","      <th>tables</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6442</th>\n","      <td>1404.4641v1</td>\n","      <td>140411</td>\n","      <td>8d9b5f9b84e177f8e35cfd491a75ed19a1214f9881e3d9430f15d61dfb540906</td>\n","      <td>Multilingual Models for Compositional Distributed Semantics</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>success</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         arxiv_id  archive_size  ... tables   status\n","6442  1404.4641v1        140411  ...      4  success\n","\n","[1 rows x 7 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"QrJrrB1GpvxY","colab":{"base_uri":"https://localhost:8080/","height":97},"executionInfo":{"status":"ok","timestamp":1636751084439,"user_tz":300,"elapsed":167,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"1e288827-5c50-4cdb-9eef-faaafd185255"},"source":["pwc_leaderboards.loc[pwc_leaderboards.arxiv_id == '1404.4641v1']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>tables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>1404.4641v1</td>\n","      <td>[{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 English-to-German', 'metric': 'Accuracy', 'model': 'Bi+', 'value': '88.1', 'row': 14, 'column': 1}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 German-to-English', 'metric': 'Accuracy', 'model': 'Bi+', 'value': '79.2', 'row': 14, 'column': 2}]}]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      arxiv_id                                                                                                                                                                                                                                                                                                                                                                                               tables\n","4  1404.4641v1  [{'index': 0, 'records': [{'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 English-to-German', 'metric': 'Accuracy', 'model': 'Bi+', 'value': '88.1', 'row': 14, 'column': 1}, {'task': 'Cross-Lingual Document Classification', 'dataset': 'Reuters RCV1/RCV2 German-to-English', 'metric': 'Accuracy', 'model': 'Bi+', 'value': '79.2', 'row': 14, 'column': 2}]}]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"0UirHXQ1pvxZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636641616124,"user_tz":300,"elapsed":112,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"6db7300f-053d-4208-d30c-487bca10934a"},"source":["pwc_leaderboards['tables'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'index': 5,\n","  'records': [{'column': 3,\n","    'dataset': 'Atari 2600 Asterix',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 1,\n","    'task': 'Atari Games',\n","    'value': '987.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Beam Rider',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 2,\n","    'task': 'Atari Games',\n","    'value': '929.4'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Freeway',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 3,\n","    'task': 'Atari Games',\n","    'value': '19.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Seaquest',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 4,\n","    'task': 'Atari Games',\n","    'value': '664.8'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Space Invaders',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 5,\n","    'task': 'Atari Games',\n","    'value': '250.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Alien',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 6,\n","    'task': 'Atari Games',\n","    'value': '939.2'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Amidar',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 7,\n","    'task': 'Atari Games',\n","    'value': '103.4'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Assault',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 8,\n","    'task': 'Atari Games',\n","    'value': '628'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Asteroids',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 9,\n","    'task': 'Atari Games',\n","    'value': '907.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Atlantis',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 10,\n","    'task': 'Atari Games',\n","    'value': '62687'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Bank Heist',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 11,\n","    'task': 'Atari Games',\n","    'value': '190.8'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Battle Zone',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 12,\n","    'task': 'Atari Games',\n","    'value': '15819.7'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Berzerk',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 13,\n","    'task': 'Atari Games',\n","    'value': '501.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Bowling',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 14,\n","    'task': 'Atari Games',\n","    'value': '43.9'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Boxing',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 15,\n","    'task': 'Atari Games',\n","    'value': '44'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Breakout',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 16,\n","    'task': 'Atari Games',\n","    'value': '5.2'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Carnival',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 17,\n","    'task': 'Atari Games',\n","    'value': '2323.9'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Centipede',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 18,\n","    'task': 'Atari Games',\n","    'value': '8803.8'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Chopper Command',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 19,\n","    'task': 'Atari Games',\n","    'value': '1581.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Crazy Climber',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 20,\n","    'task': 'Atari Games',\n","    'value': '23410.6'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Demon Attack',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 21,\n","    'task': 'Atari Games',\n","    'value': '520.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Double Dunk',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 22,\n","    'task': 'Atari Games',\n","    'value': '-13.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Elevator Action',\n","    'metric': 'Action',\n","    'model': 'Best Learner',\n","    'row': 23,\n","    'task': 'Atari Games',\n","    'value': '3220.6'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Enduro',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 24,\n","    'task': 'Atari Games',\n","    'value': '129.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Fishing Derby',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 25,\n","    'task': 'Atari Games',\n","    'value': '-89.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Frostbite',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 26,\n","    'task': 'Atari Games',\n","    'value': '216.9'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Gopher',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 27,\n","    'task': 'Atari Games',\n","    'value': '1288.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Gravitar',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 28,\n","    'task': 'Atari Games',\n","    'value': '387.7'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 HERO',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 29,\n","    'task': 'Atari Games',\n","    'value': '6458.8'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Ice Hockey',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 30,\n","    'task': 'Atari Games',\n","    'value': '-9.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 James Bond',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 31,\n","    'task': 'Atari Games',\n","    'value': '202.8'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Journey Escape',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 32,\n","    'task': 'Atari Games',\n","    'value': '-8441'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Kangaroo',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 33,\n","    'task': 'Atari Games',\n","    'value': '1622.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Krull',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 34,\n","    'task': 'Atari Games',\n","    'value': '3371.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Kung-Fu Master',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 35,\n","    'task': 'Atari Games',\n","    'value': '19544'},\n","   {'column': 3,\n","    'dataset': \"Atari 2600 Montezuma's Revenge\",\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 36,\n","    'task': 'Atari Games',\n","    'value': '10.7'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Ms. Pacman',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 37,\n","    'task': 'Atari Games',\n","    'value': '1691.8'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Name This Game',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 38,\n","    'task': 'Atari Games',\n","    'value': '2500.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Pooyan',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 39,\n","    'task': 'Atari Games',\n","    'value': '1225.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Pong',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 40,\n","    'task': 'Atari Games',\n","    'value': '-19'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Private Eye',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 41,\n","    'task': 'Atari Games',\n","    'value': '684.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Q*Bert',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 42,\n","    'task': 'Atari Games',\n","    'value': '613.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 River Raid',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 43,\n","    'task': 'Atari Games',\n","    'value': '1904.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Road Runner',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 44,\n","    'task': 'Atari Games',\n","    'value': '67.7'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Robotank',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 45,\n","    'task': 'Atari Games',\n","    'value': '28.7'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Skiing',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 46,\n","    'task': 'Atari Games',\n","    'value': '0'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Star Gunner',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 47,\n","    'task': 'Atari Games',\n","    'value': '1069.5'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Tennis',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 48,\n","    'task': 'Atari Games',\n","    'value': '-0.1'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Time Pilot',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 49,\n","    'task': 'Atari Games',\n","    'value': '3741.2'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Tutankham',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 50,\n","    'task': 'Atari Games',\n","    'value': '114.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Up and Down',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 51,\n","    'task': 'Atari Games',\n","    'value': '3532.7'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Venture',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 52,\n","    'task': 'Atari Games',\n","    'value': '66'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Video Pinball',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 53,\n","    'task': 'Atari Games',\n","    'value': '16871.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Wizard of Wor',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 54,\n","    'task': 'Atari Games',\n","    'value': '1981.3'},\n","   {'column': 3,\n","    'dataset': 'Atari 2600 Zaxxon',\n","    'metric': 'Score',\n","    'model': 'Best Learner',\n","    'row': 55,\n","    'task': 'Atari Games',\n","    'value': '3365.1'}]}]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"ZqtG5SMgpvxa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636641618864,"user_tz":300,"elapsed":79,"user":{"displayName":"Shao-Chun Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00585104487603959617"}},"outputId":"aa965688-d85b-4f63-e3af-4eda0c85310a"},"source":["pwc_leaderboards['tables'][100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'index': 2,\n","  'records': [{'column': 9,\n","    'dataset': 'WOS-5736',\n","    'metric': 'Accuracy',\n","    'model': 'HDLTex',\n","    'row': 18,\n","    'task': 'Document Classification',\n","    'value': '90.93'},\n","   {'column': 3,\n","    'dataset': 'WOS-11967',\n","    'metric': 'Accuracy',\n","    'model': 'HDLTex',\n","    'row': 22,\n","    'task': 'Document Classification',\n","    'value': '86.07'},\n","   {'column': 6,\n","    'dataset': 'WOS-46985',\n","    'metric': 'Accuracy',\n","    'model': 'HDLTex',\n","    'row': 26,\n","    'task': 'Document Classification',\n","    'value': '76.58'}]}]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"EdnYpDprpvxb"},"source":[""],"execution_count":null,"outputs":[]}]}